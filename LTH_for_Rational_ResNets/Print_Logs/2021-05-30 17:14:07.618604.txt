Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e5c627d0
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e5c6a190
    (shortcut): Sequential()
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e5c6a5f0
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e5c6aa50
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e5c6a960
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e5c753c0
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e5c75820
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e5c75cd0
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e4a00230
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e4a00820
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e4a00cd0
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e4a0b1e0
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e4a0b5f0
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e4a0baa0
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e4a0bf50
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e4a18640
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e4a18af0
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f00e4a18f50
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4a24a50
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4a345a0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4a345f0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4a34500
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4a34eb0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4a34550
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4a344b0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4a34410
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4a34a00
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4a34dc0
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4a34c80
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49bf190
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49bf870
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49cd370
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00eefa3230
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49bf960
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49bf910
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49bfb40
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49cd0f0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49cd3c0
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49cd5f0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49cde10
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49cde60
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49db4b0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49db870
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49cdeb0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49cdf50
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e6581320
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49db780
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49db640
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49dbaa0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49e58c0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49e5910
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49e5820
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49e5cd0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49e5870
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49e57d0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49e5780
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49e5a50
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49e5e10
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49f3320
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49f3230
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49f3e60
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4980640
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4980690
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49f3be0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49f3b90
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4980410
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4980550
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4980460
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49802d0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4987370
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49873c0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49872d0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4987a00
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4987320
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4987280
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49871e0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49878c0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4987c80
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4987dc0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49950a0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4995d70
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4995d20
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49a40f0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4995c80
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4995b90
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4995730
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49a4370
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49a4280
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49a44b0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49a43c0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49b0050
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49b00a0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00ee8c35a0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49a4f00
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49b06e0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49b0730
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49b0140
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49b0c30
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49b0af0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49bc730
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49bc780
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49bcc80
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49462d0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49bc6e0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49bc640
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49bc5a0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e49bcdc0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f00e4946050
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2843 Acc: 0.1695
val Loss: 2.2367 Acc: 0.1876
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 2.1738 Acc: 0.2238
val Loss: 1.9948 Acc: 0.2822
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 1.7171 Acc: 0.3912
val Loss: 1.4441 Acc: 0.4880
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 1.0379 Acc: 0.6550
val Loss: 0.9072 Acc: 0.6989
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.6074 Acc: 0.8062
val Loss: 0.5813 Acc: 0.8106
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4796 Acc: 0.8498
val Loss: 0.5416 Acc: 0.8294
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4153 Acc: 0.8720
val Loss: 0.4263 Acc: 0.8651
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3804 Acc: 0.8826
val Loss: 0.4981 Acc: 0.8454
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3559 Acc: 0.8902
val Loss: 0.4196 Acc: 0.8693
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3382 Acc: 0.8957
val Loss: 0.4244 Acc: 0.8696
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3212 Acc: 0.9020
val Loss: 0.3551 Acc: 0.8910
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3056 Acc: 0.9076
val Loss: 0.3416 Acc: 0.8949
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3003 Acc: 0.9090
val Loss: 0.3733 Acc: 0.8830
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2882 Acc: 0.9136
val Loss: 0.3518 Acc: 0.8917
Epoch finished in 0m 8s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2832 Acc: 0.9137
val Loss: 0.4083 Acc: 0.8741
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2741 Acc: 0.9168
val Loss: 0.3010 Acc: 0.9102
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2680 Acc: 0.9190
val Loss: 0.2621 Acc: 0.9239
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2279 Acc: 0.9324
val Loss: 0.2463 Acc: 0.9282
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2204 Acc: 0.9352
val Loss: 0.2447 Acc: 0.9284
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2147 Acc: 0.9373
val Loss: 0.2383 Acc: 0.9304
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2110 Acc: 0.9382
val Loss: 0.2369 Acc: 0.9304
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2078 Acc: 0.9386
val Loss: 0.2388 Acc: 0.9303
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2100 Acc: 0.9384
val Loss: 0.2372 Acc: 0.9305
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2085 Acc: 0.9395
val Loss: 0.2362 Acc: 0.9316
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2104 Acc: 0.9383
val Loss: 0.2340 Acc: 0.9329
Epoch finished in 0m 9s
Best validation accuracy: 0.9328928688435077
Before Pruning
++++++++++++++++++
Model Test Accuracy:  0.9386908420405654
Pruning Epoch 1
++++++++++++++++++
number of weights to prune:  54052.0
Sparsity of Pruned Mask:  tensor(0.2000)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2162 Acc: 0.2053
val Loss: 1.9637 Acc: 0.3193
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.5424 Acc: 0.4774
val Loss: 1.0472 Acc: 0.6580
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.7117 Acc: 0.7792
val Loss: 0.5760 Acc: 0.8118
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4629 Acc: 0.8565
val Loss: 0.4407 Acc: 0.8634
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3947 Acc: 0.8786
val Loss: 0.4433 Acc: 0.8596
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3595 Acc: 0.8896
val Loss: 0.3985 Acc: 0.8751
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3342 Acc: 0.8985
val Loss: 0.3674 Acc: 0.8853
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3142 Acc: 0.9038
val Loss: 0.3280 Acc: 0.8997
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3034 Acc: 0.9074
val Loss: 0.3349 Acc: 0.8947
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2935 Acc: 0.9101
val Loss: 0.3303 Acc: 0.8997
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2857 Acc: 0.9131
val Loss: 0.3555 Acc: 0.8933
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2797 Acc: 0.9162
val Loss: 0.3547 Acc: 0.8888
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2637 Acc: 0.9205
val Loss: 0.2796 Acc: 0.9149
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2653 Acc: 0.9200
val Loss: 0.3495 Acc: 0.8928
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2569 Acc: 0.9234
val Loss: 0.3168 Acc: 0.9031
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2518 Acc: 0.9261
val Loss: 0.2767 Acc: 0.9148
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2400 Acc: 0.9300
val Loss: 0.2461 Acc: 0.9268
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2108 Acc: 0.9376
val Loss: 0.2310 Acc: 0.9333
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2022 Acc: 0.9414
val Loss: 0.2287 Acc: 0.9337
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1949 Acc: 0.9436
val Loss: 0.2231 Acc: 0.9346
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1945 Acc: 0.9439
val Loss: 0.2229 Acc: 0.9339
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1960 Acc: 0.9431
val Loss: 0.2240 Acc: 0.9340
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1926 Acc: 0.9436
val Loss: 0.2247 Acc: 0.9354
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1932 Acc: 0.9446
val Loss: 0.2212 Acc: 0.9361
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1952 Acc: 0.9433
val Loss: 0.2212 Acc: 0.9348
Epoch finished in 0m 9s
Best validation accuracy: 0.9348039751010156
Model Test Accuracy:  0.9421481253841425
Pruning Epoch 2
++++++++++++++++++
number of weights to prune:  43241.0
Sparsity of Pruned Mask:  tensor(0.3600)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.0320 Acc: 0.2919
val Loss: 1.5017 Acc: 0.5285
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.9023 Acc: 0.7386
val Loss: 0.5501 Acc: 0.8359
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4388 Acc: 0.8705
val Loss: 0.3817 Acc: 0.8821
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3571 Acc: 0.8902
val Loss: 0.3517 Acc: 0.8918
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3206 Acc: 0.9042
val Loss: 0.3449 Acc: 0.8945
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3019 Acc: 0.9084
val Loss: 0.3196 Acc: 0.9020
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2898 Acc: 0.9118
val Loss: 0.3001 Acc: 0.9094
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2784 Acc: 0.9164
val Loss: 0.3751 Acc: 0.8864
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2671 Acc: 0.9197
val Loss: 0.3345 Acc: 0.8960
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2608 Acc: 0.9214
val Loss: 0.3088 Acc: 0.9081
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2554 Acc: 0.9234
val Loss: 0.3284 Acc: 0.9020
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2527 Acc: 0.9244
val Loss: 0.2943 Acc: 0.9121
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2450 Acc: 0.9266
val Loss: 0.2898 Acc: 0.9123
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2439 Acc: 0.9265
val Loss: 0.3076 Acc: 0.9085
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2392 Acc: 0.9288
val Loss: 0.2826 Acc: 0.9171
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2330 Acc: 0.9309
val Loss: 0.2854 Acc: 0.9160
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2328 Acc: 0.9289
val Loss: 0.2443 Acc: 0.9269
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2021 Acc: 0.9410
val Loss: 0.2251 Acc: 0.9349
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1896 Acc: 0.9437
val Loss: 0.2229 Acc: 0.9353
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1862 Acc: 0.9460
val Loss: 0.2201 Acc: 0.9364
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1835 Acc: 0.9455
val Loss: 0.2198 Acc: 0.9360
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1835 Acc: 0.9470
val Loss: 0.2173 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1822 Acc: 0.9476
val Loss: 0.2168 Acc: 0.9378
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1835 Acc: 0.9470
val Loss: 0.2208 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1815 Acc: 0.9476
val Loss: 0.2161 Acc: 0.9385
Epoch finished in 0m 9s
Best validation accuracy: 0.9384623785082451
Model Test Accuracy:  0.943876767055931
Pruning Epoch 3
++++++++++++++++++
number of weights to prune:  34593.0
Sparsity of Pruned Mask:  tensor(0.4880)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.8219 Acc: 0.4034
val Loss: 1.0376 Acc: 0.7322
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.6246 Acc: 0.8386
val Loss: 0.4148 Acc: 0.8793
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3690 Acc: 0.8915
val Loss: 0.3316 Acc: 0.9019
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3078 Acc: 0.9082
val Loss: 0.3175 Acc: 0.9025
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2864 Acc: 0.9133
val Loss: 0.3268 Acc: 0.8970
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2708 Acc: 0.9180
val Loss: 0.3402 Acc: 0.8972
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2599 Acc: 0.9222
val Loss: 0.2887 Acc: 0.9133
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2541 Acc: 0.9239
val Loss: 0.2768 Acc: 0.9161
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2489 Acc: 0.9251
val Loss: 0.2880 Acc: 0.9119
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2452 Acc: 0.9269
val Loss: 0.2803 Acc: 0.9169
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2362 Acc: 0.9295
val Loss: 0.2835 Acc: 0.9169
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2358 Acc: 0.9298
val Loss: 0.2719 Acc: 0.9186
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2334 Acc: 0.9306
val Loss: 0.2744 Acc: 0.9167
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2276 Acc: 0.9325
val Loss: 0.2930 Acc: 0.9174
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2251 Acc: 0.9320
val Loss: 0.2507 Acc: 0.9253
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2250 Acc: 0.9333
val Loss: 0.2697 Acc: 0.9210
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2212 Acc: 0.9344
val Loss: 0.2308 Acc: 0.9333
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1924 Acc: 0.9428
val Loss: 0.2206 Acc: 0.9378
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1833 Acc: 0.9466
val Loss: 0.2151 Acc: 0.9384
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1774 Acc: 0.9486
val Loss: 0.2119 Acc: 0.9397
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1770 Acc: 0.9487
val Loss: 0.2100 Acc: 0.9394
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1766 Acc: 0.9480
val Loss: 0.2094 Acc: 0.9402
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1758 Acc: 0.9494
val Loss: 0.2113 Acc: 0.9381
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1741 Acc: 0.9498
val Loss: 0.2099 Acc: 0.9398
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1726 Acc: 0.9504
val Loss: 0.2122 Acc: 0.9403
Epoch finished in 0m 9s
Best validation accuracy: 0.9403188817298241
Model Test Accuracy:  0.945259680393362
Pruning Epoch 4
++++++++++++++++++
number of weights to prune:  27674.0
Sparsity of Pruned Mask:  tensor(0.5904)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.7054 Acc: 0.4657
val Loss: 0.8962 Acc: 0.7923
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5516 Acc: 0.8613
val Loss: 0.3858 Acc: 0.8884
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3336 Acc: 0.9032
val Loss: 0.3184 Acc: 0.9039
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2874 Acc: 0.9139
val Loss: 0.2977 Acc: 0.9098
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2652 Acc: 0.9208
val Loss: 0.2878 Acc: 0.9115
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2511 Acc: 0.9252
val Loss: 0.2703 Acc: 0.9195
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2432 Acc: 0.9267
val Loss: 0.2695 Acc: 0.9215
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2399 Acc: 0.9279
val Loss: 0.2611 Acc: 0.9228
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2323 Acc: 0.9309
val Loss: 0.2826 Acc: 0.9165
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2310 Acc: 0.9308
val Loss: 0.2878 Acc: 0.9159
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2284 Acc: 0.9317
val Loss: 0.2785 Acc: 0.9159
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2243 Acc: 0.9333
val Loss: 0.2771 Acc: 0.9178
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2234 Acc: 0.9331
val Loss: 0.2776 Acc: 0.9178
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2184 Acc: 0.9348
val Loss: 0.2681 Acc: 0.9214
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2182 Acc: 0.9341
val Loss: 0.2771 Acc: 0.9163
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2150 Acc: 0.9367
val Loss: 0.2511 Acc: 0.9258
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2128 Acc: 0.9368
val Loss: 0.2451 Acc: 0.9276
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1864 Acc: 0.9456
val Loss: 0.2207 Acc: 0.9362
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1744 Acc: 0.9496
val Loss: 0.2163 Acc: 0.9383
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1727 Acc: 0.9505
val Loss: 0.2116 Acc: 0.9381
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1699 Acc: 0.9509
val Loss: 0.2110 Acc: 0.9386
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1681 Acc: 0.9524
val Loss: 0.2144 Acc: 0.9384
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1666 Acc: 0.9523
val Loss: 0.2129 Acc: 0.9378
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1689 Acc: 0.9513
val Loss: 0.2109 Acc: 0.9396
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1672 Acc: 0.9524
val Loss: 0.2134 Acc: 0.9397
Epoch finished in 0m 9s
Best validation accuracy: 0.9397182483346074
Model Test Accuracy:  0.9464889366933005
Pruning Epoch 5
++++++++++++++++++
number of weights to prune:  22139.0
Sparsity of Pruned Mask:  tensor(0.6723)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6340 Acc: 0.5065
val Loss: 0.8081 Acc: 0.8224
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5163 Acc: 0.8717
val Loss: 0.3708 Acc: 0.8963
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3211 Acc: 0.9074
val Loss: 0.3276 Acc: 0.9017
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2745 Acc: 0.9188
val Loss: 0.2931 Acc: 0.9131
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2518 Acc: 0.9256
val Loss: 0.2639 Acc: 0.9202
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2414 Acc: 0.9277
val Loss: 0.2599 Acc: 0.9227
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2340 Acc: 0.9303
val Loss: 0.2857 Acc: 0.9156
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2301 Acc: 0.9307
val Loss: 0.2579 Acc: 0.9214
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2220 Acc: 0.9330
val Loss: 0.3010 Acc: 0.9120
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2203 Acc: 0.9333
val Loss: 0.2600 Acc: 0.9228
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2168 Acc: 0.9354
val Loss: 0.2483 Acc: 0.9262
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2144 Acc: 0.9358
val Loss: 0.2952 Acc: 0.9158
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2149 Acc: 0.9351
val Loss: 0.2529 Acc: 0.9262
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2159 Acc: 0.9362
val Loss: 0.2908 Acc: 0.9123
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2114 Acc: 0.9374
val Loss: 0.2434 Acc: 0.9305
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2107 Acc: 0.9368
val Loss: 0.2707 Acc: 0.9210
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2095 Acc: 0.9378
val Loss: 0.2328 Acc: 0.9333
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1832 Acc: 0.9462
val Loss: 0.2174 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1741 Acc: 0.9497
val Loss: 0.2138 Acc: 0.9402
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1694 Acc: 0.9509
val Loss: 0.2099 Acc: 0.9415
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1676 Acc: 0.9520
val Loss: 0.2112 Acc: 0.9393
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1666 Acc: 0.9517
val Loss: 0.2127 Acc: 0.9394
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1664 Acc: 0.9521
val Loss: 0.2081 Acc: 0.9415
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1669 Acc: 0.9518
val Loss: 0.2112 Acc: 0.9403
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1660 Acc: 0.9520
val Loss: 0.2087 Acc: 0.9406
Epoch finished in 0m 9s
Best validation accuracy: 0.940646499945397
Model Test Accuracy:  0.9453749231714812
Pruning Epoch 6
++++++++++++++++++
number of weights to prune:  17711.0
Sparsity of Pruned Mask:  tensor(0.7379)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6143 Acc: 0.5205
val Loss: 0.7916 Acc: 0.8266
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5056 Acc: 0.8753
val Loss: 0.3760 Acc: 0.8942
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3149 Acc: 0.9099
val Loss: 0.2896 Acc: 0.9143
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2652 Acc: 0.9216
val Loss: 0.2648 Acc: 0.9225
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2444 Acc: 0.9278
val Loss: 0.2872 Acc: 0.9149
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2335 Acc: 0.9299
val Loss: 0.2752 Acc: 0.9175
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2276 Acc: 0.9317
val Loss: 0.2734 Acc: 0.9184
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2214 Acc: 0.9347
val Loss: 0.2558 Acc: 0.9241
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2178 Acc: 0.9358
val Loss: 0.2584 Acc: 0.9235
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2159 Acc: 0.9352
val Loss: 0.2673 Acc: 0.9213
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2164 Acc: 0.9350
val Loss: 0.2528 Acc: 0.9270
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2129 Acc: 0.9360
val Loss: 0.3248 Acc: 0.9084
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2115 Acc: 0.9374
val Loss: 0.2731 Acc: 0.9219
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2131 Acc: 0.9355
val Loss: 0.2663 Acc: 0.9235
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2084 Acc: 0.9373
val Loss: 0.2676 Acc: 0.9224
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2095 Acc: 0.9372
val Loss: 0.2724 Acc: 0.9172
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2118 Acc: 0.9364
val Loss: 0.2362 Acc: 0.9309
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1823 Acc: 0.9455
val Loss: 0.2192 Acc: 0.9376
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1724 Acc: 0.9499
val Loss: 0.2163 Acc: 0.9377
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1675 Acc: 0.9511
val Loss: 0.2103 Acc: 0.9394
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1674 Acc: 0.9518
val Loss: 0.2101 Acc: 0.9395
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1663 Acc: 0.9523
val Loss: 0.2097 Acc: 0.9410
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1661 Acc: 0.9522
val Loss: 0.2067 Acc: 0.9409
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1653 Acc: 0.9529
val Loss: 0.2104 Acc: 0.9406
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1646 Acc: 0.9521
val Loss: 0.2091 Acc: 0.9403
Epoch finished in 0m 9s
Best validation accuracy: 0.9403188817298241
Model Test Accuracy:  0.9458358942839581
Pruning Epoch 7
++++++++++++++++++
number of weights to prune:  14168.0
Sparsity of Pruned Mask:  tensor(0.7903)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6367 Acc: 0.5170
val Loss: 0.7956 Acc: 0.8331
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5012 Acc: 0.8788
val Loss: 0.3554 Acc: 0.9000
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3094 Acc: 0.9119
val Loss: 0.3017 Acc: 0.9104
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2581 Acc: 0.9235
val Loss: 0.2743 Acc: 0.9176
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2426 Acc: 0.9276
val Loss: 0.2681 Acc: 0.9175
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2289 Acc: 0.9315
val Loss: 0.2605 Acc: 0.9229
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2218 Acc: 0.9343
val Loss: 0.2704 Acc: 0.9191
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2182 Acc: 0.9347
val Loss: 0.2775 Acc: 0.9166
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2157 Acc: 0.9360
val Loss: 0.2529 Acc: 0.9277
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2152 Acc: 0.9354
val Loss: 0.2580 Acc: 0.9245
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2107 Acc: 0.9363
val Loss: 0.2676 Acc: 0.9201
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2141 Acc: 0.9364
val Loss: 0.2490 Acc: 0.9245
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2102 Acc: 0.9370
val Loss: 0.2783 Acc: 0.9196
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2095 Acc: 0.9366
val Loss: 0.2621 Acc: 0.9218
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2099 Acc: 0.9377
val Loss: 0.2508 Acc: 0.9259
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2058 Acc: 0.9386
val Loss: 0.2597 Acc: 0.9239
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2041 Acc: 0.9390
val Loss: 0.2297 Acc: 0.9349
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1779 Acc: 0.9483
val Loss: 0.2179 Acc: 0.9365
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1700 Acc: 0.9506
val Loss: 0.2114 Acc: 0.9398
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1674 Acc: 0.9513
val Loss: 0.2098 Acc: 0.9420
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1652 Acc: 0.9518
val Loss: 0.2126 Acc: 0.9400
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1646 Acc: 0.9525
val Loss: 0.2086 Acc: 0.9405
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1642 Acc: 0.9527
val Loss: 0.2089 Acc: 0.9409
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1651 Acc: 0.9523
val Loss: 0.2086 Acc: 0.9404
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1640 Acc: 0.9528
val Loss: 0.2096 Acc: 0.9396
Epoch finished in 0m 9s
Best validation accuracy: 0.9396090422627498
Model Test Accuracy:  0.946757836508912
Pruning Epoch 8
++++++++++++++++++
number of weights to prune:  11335.0
Sparsity of Pruned Mask:  tensor(0.8323)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6486 Acc: 0.5107
val Loss: 0.8082 Acc: 0.8285
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5069 Acc: 0.8758
val Loss: 0.3820 Acc: 0.8935
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3092 Acc: 0.9128
val Loss: 0.2863 Acc: 0.9135
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2576 Acc: 0.9240
val Loss: 0.2926 Acc: 0.9114
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2419 Acc: 0.9271
val Loss: 0.2566 Acc: 0.9226
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2267 Acc: 0.9327
val Loss: 0.2988 Acc: 0.9119
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2220 Acc: 0.9329
val Loss: 0.2584 Acc: 0.9228
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2177 Acc: 0.9347
val Loss: 0.2563 Acc: 0.9240
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2207 Acc: 0.9350
val Loss: 0.2553 Acc: 0.9242
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2137 Acc: 0.9368
val Loss: 0.2568 Acc: 0.9248
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2150 Acc: 0.9358
val Loss: 0.2619 Acc: 0.9219
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2118 Acc: 0.9368
val Loss: 0.2566 Acc: 0.9231
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2102 Acc: 0.9374
val Loss: 0.2595 Acc: 0.9232
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2104 Acc: 0.9373
val Loss: 0.2944 Acc: 0.9118
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2107 Acc: 0.9364
val Loss: 0.2788 Acc: 0.9156
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2101 Acc: 0.9371
val Loss: 0.2656 Acc: 0.9231
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2092 Acc: 0.9375
val Loss: 0.2368 Acc: 0.9313
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1852 Acc: 0.9455
val Loss: 0.2239 Acc: 0.9374
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1741 Acc: 0.9495
val Loss: 0.2205 Acc: 0.9374
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1701 Acc: 0.9501
val Loss: 0.2151 Acc: 0.9387
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1679 Acc: 0.9519
val Loss: 0.2167 Acc: 0.9378
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1683 Acc: 0.9507
val Loss: 0.2167 Acc: 0.9386
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1714 Acc: 0.9501
val Loss: 0.2132 Acc: 0.9392
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1697 Acc: 0.9513
val Loss: 0.2164 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1661 Acc: 0.9517
val Loss: 0.2153 Acc: 0.9378
Epoch finished in 0m 9s
Best validation accuracy: 0.9377525390411707
Model Test Accuracy:  0.946258451137062
Pruning Epoch 9
++++++++++++++++++
number of weights to prune:  9067.0
Sparsity of Pruned Mask:  tensor(0.8658)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6593 Acc: 0.5010
val Loss: 0.8294 Acc: 0.8226
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5206 Acc: 0.8736
val Loss: 0.3680 Acc: 0.8984
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3131 Acc: 0.9107
val Loss: 0.2952 Acc: 0.9147
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2638 Acc: 0.9232
val Loss: 0.2782 Acc: 0.9155
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2413 Acc: 0.9283
val Loss: 0.2575 Acc: 0.9237
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2297 Acc: 0.9311
val Loss: 0.2513 Acc: 0.9251
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2252 Acc: 0.9330
val Loss: 0.2660 Acc: 0.9231
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2212 Acc: 0.9345
val Loss: 0.2626 Acc: 0.9219
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2172 Acc: 0.9350
val Loss: 0.2550 Acc: 0.9246
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2197 Acc: 0.9351
val Loss: 0.2436 Acc: 0.9258
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2181 Acc: 0.9351
val Loss: 0.2447 Acc: 0.9264
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2156 Acc: 0.9365
val Loss: 0.2486 Acc: 0.9271
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2150 Acc: 0.9356
val Loss: 0.2593 Acc: 0.9248
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2144 Acc: 0.9357
val Loss: 0.2792 Acc: 0.9165
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2133 Acc: 0.9365
val Loss: 0.2709 Acc: 0.9209
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2132 Acc: 0.9358
val Loss: 0.2784 Acc: 0.9165
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2088 Acc: 0.9382
val Loss: 0.2330 Acc: 0.9336
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1835 Acc: 0.9451
val Loss: 0.2225 Acc: 0.9362
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1770 Acc: 0.9485
val Loss: 0.2170 Acc: 0.9376
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1729 Acc: 0.9503
val Loss: 0.2134 Acc: 0.9381
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1697 Acc: 0.9509
val Loss: 0.2158 Acc: 0.9381
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1720 Acc: 0.9499
val Loss: 0.2154 Acc: 0.9384
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1715 Acc: 0.9501
val Loss: 0.2175 Acc: 0.9379
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1708 Acc: 0.9511
val Loss: 0.2177 Acc: 0.9400
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1711 Acc: 0.9497
val Loss: 0.2180 Acc: 0.9364
Epoch finished in 0m 9s
Best validation accuracy: 0.9363874631429507
Model Test Accuracy:  0.9452980946527351
Pruning Epoch 10
++++++++++++++++++
number of weights to prune:  7254.0
Sparsity of Pruned Mask:  tensor(0.8926)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6746 Acc: 0.4958
val Loss: 0.8647 Acc: 0.8183
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5342 Acc: 0.8736
val Loss: 0.3777 Acc: 0.8943
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3202 Acc: 0.9083
val Loss: 0.2969 Acc: 0.9107
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2700 Acc: 0.9204
val Loss: 0.2824 Acc: 0.9147
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2415 Acc: 0.9277
val Loss: 0.2663 Acc: 0.9212
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2359 Acc: 0.9299
val Loss: 0.2726 Acc: 0.9180
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2314 Acc: 0.9304
val Loss: 0.2604 Acc: 0.9233
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2269 Acc: 0.9325
val Loss: 0.2692 Acc: 0.9193
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2207 Acc: 0.9351
val Loss: 0.2753 Acc: 0.9198
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2207 Acc: 0.9339
val Loss: 0.2955 Acc: 0.9149
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2244 Acc: 0.9328
val Loss: 0.2921 Acc: 0.9130
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2198 Acc: 0.9339
val Loss: 0.2609 Acc: 0.9231
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2193 Acc: 0.9342
val Loss: 0.2651 Acc: 0.9219
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2199 Acc: 0.9342
val Loss: 0.2568 Acc: 0.9251
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2170 Acc: 0.9351
val Loss: 0.2623 Acc: 0.9212
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2198 Acc: 0.9346
val Loss: 0.2528 Acc: 0.9263
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2166 Acc: 0.9361
val Loss: 0.2386 Acc: 0.9313
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1915 Acc: 0.9434
val Loss: 0.2246 Acc: 0.9354
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1838 Acc: 0.9466
val Loss: 0.2214 Acc: 0.9360
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1806 Acc: 0.9477
val Loss: 0.2226 Acc: 0.9367
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1783 Acc: 0.9492
val Loss: 0.2200 Acc: 0.9372
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1777 Acc: 0.9483
val Loss: 0.2183 Acc: 0.9377
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1772 Acc: 0.9487
val Loss: 0.2152 Acc: 0.9383
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1788 Acc: 0.9478
val Loss: 0.2161 Acc: 0.9379
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1758 Acc: 0.9486
val Loss: 0.2163 Acc: 0.9377
Epoch finished in 0m 9s
Best validation accuracy: 0.9376979360052419
Model Test Accuracy:  0.9455669944683466
Pruning Epoch 11
++++++++++++++++++
number of weights to prune:  5803.0
Sparsity of Pruned Mask:  tensor(0.9141)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.7669 Acc: 0.4511
val Loss: 0.9571 Acc: 0.7948
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5826 Acc: 0.8617
val Loss: 0.3988 Acc: 0.8886
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3298 Acc: 0.9065
val Loss: 0.3117 Acc: 0.9056
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2735 Acc: 0.9201
val Loss: 0.2751 Acc: 0.9182
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2489 Acc: 0.9258
val Loss: 0.2801 Acc: 0.9146
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2425 Acc: 0.9282
val Loss: 0.2700 Acc: 0.9182
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2322 Acc: 0.9309
val Loss: 0.2665 Acc: 0.9198
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2307 Acc: 0.9313
val Loss: 0.2624 Acc: 0.9227
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2274 Acc: 0.9324
val Loss: 0.2808 Acc: 0.9153
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2302 Acc: 0.9307
val Loss: 0.2765 Acc: 0.9179
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2290 Acc: 0.9315
val Loss: 0.2825 Acc: 0.9141
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2268 Acc: 0.9315
val Loss: 0.2770 Acc: 0.9180
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2252 Acc: 0.9321
val Loss: 0.2581 Acc: 0.9244
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2242 Acc: 0.9327
val Loss: 0.2550 Acc: 0.9252
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2268 Acc: 0.9317
val Loss: 0.3008 Acc: 0.9100
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2235 Acc: 0.9343
val Loss: 0.2879 Acc: 0.9157
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2216 Acc: 0.9327
val Loss: 0.2425 Acc: 0.9292
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1990 Acc: 0.9413
val Loss: 0.2307 Acc: 0.9328
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1911 Acc: 0.9434
val Loss: 0.2221 Acc: 0.9361
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1879 Acc: 0.9441
val Loss: 0.2192 Acc: 0.9366
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1847 Acc: 0.9463
val Loss: 0.2204 Acc: 0.9350
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1860 Acc: 0.9457
val Loss: 0.2233 Acc: 0.9361
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1849 Acc: 0.9459
val Loss: 0.2233 Acc: 0.9341
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1868 Acc: 0.9452
val Loss: 0.2249 Acc: 0.9335
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1865 Acc: 0.9457
val Loss: 0.2208 Acc: 0.9364
Epoch finished in 0m 9s
Best validation accuracy: 0.9364420661788796
Model Test Accuracy:  0.9439535955746773
Pruning Epoch 12
++++++++++++++++++
number of weights to prune:  4642.0
Sparsity of Pruned Mask:  tensor(0.9313)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.7665 Acc: 0.4481
val Loss: 0.9630 Acc: 0.7944
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5834 Acc: 0.8608
val Loss: 0.3923 Acc: 0.8931
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3410 Acc: 0.9035
val Loss: 0.3204 Acc: 0.9063
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2826 Acc: 0.9168
val Loss: 0.2917 Acc: 0.9129
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2619 Acc: 0.9220
val Loss: 0.2835 Acc: 0.9159
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2476 Acc: 0.9257
val Loss: 0.2881 Acc: 0.9147
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2445 Acc: 0.9259
val Loss: 0.2887 Acc: 0.9135
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2382 Acc: 0.9297
val Loss: 0.2781 Acc: 0.9167
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2402 Acc: 0.9280
val Loss: 0.2652 Acc: 0.9211
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2376 Acc: 0.9289
val Loss: 0.2770 Acc: 0.9183
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2384 Acc: 0.9289
val Loss: 0.2713 Acc: 0.9195
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2363 Acc: 0.9294
val Loss: 0.2942 Acc: 0.9119
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2380 Acc: 0.9289
val Loss: 0.2779 Acc: 0.9159
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2359 Acc: 0.9293
val Loss: 0.3015 Acc: 0.9113
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2306 Acc: 0.9304
val Loss: 0.2588 Acc: 0.9254
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2331 Acc: 0.9300
val Loss: 0.2688 Acc: 0.9233
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2324 Acc: 0.9306
val Loss: 0.2465 Acc: 0.9285
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2098 Acc: 0.9381
val Loss: 0.2321 Acc: 0.9327
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2032 Acc: 0.9409
val Loss: 0.2277 Acc: 0.9341
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1972 Acc: 0.9418
val Loss: 0.2282 Acc: 0.9332
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1955 Acc: 0.9432
val Loss: 0.2265 Acc: 0.9355
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1946 Acc: 0.9436
val Loss: 0.2274 Acc: 0.9324
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1968 Acc: 0.9430
val Loss: 0.2260 Acc: 0.9328
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1961 Acc: 0.9427
val Loss: 0.2301 Acc: 0.9332
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1935 Acc: 0.9433
val Loss: 0.2255 Acc: 0.9333
Epoch finished in 0m 9s
Best validation accuracy: 0.9332750900950093
Model Test Accuracy:  0.9404963122311001
Pruning Epoch 13
++++++++++++++++++
number of weights to prune:  3713.0
Sparsity of Pruned Mask:  tensor(0.9450)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.8128 Acc: 0.4270
val Loss: 1.0522 Acc: 0.7747
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.6346 Acc: 0.8519
val Loss: 0.4248 Acc: 0.8825
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3624 Acc: 0.8979
val Loss: 0.3421 Acc: 0.8996
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2959 Acc: 0.9141
val Loss: 0.2962 Acc: 0.9113
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2747 Acc: 0.9187
val Loss: 0.2843 Acc: 0.9152
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2614 Acc: 0.9219
val Loss: 0.2884 Acc: 0.9133
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2572 Acc: 0.9230
val Loss: 0.2721 Acc: 0.9184
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2541 Acc: 0.9231
val Loss: 0.2839 Acc: 0.9137
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2484 Acc: 0.9259
val Loss: 0.2871 Acc: 0.9144
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2504 Acc: 0.9248
val Loss: 0.2961 Acc: 0.9118
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2466 Acc: 0.9270
val Loss: 0.3021 Acc: 0.9072
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2466 Acc: 0.9261
val Loss: 0.2928 Acc: 0.9113
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2491 Acc: 0.9253
val Loss: 0.3237 Acc: 0.9019
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2449 Acc: 0.9262
val Loss: 0.2891 Acc: 0.9158
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2451 Acc: 0.9280
val Loss: 0.2898 Acc: 0.9136
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2455 Acc: 0.9263
val Loss: 0.2896 Acc: 0.9138
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2412 Acc: 0.9268
val Loss: 0.2576 Acc: 0.9250
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2205 Acc: 0.9335
val Loss: 0.2453 Acc: 0.9292
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2118 Acc: 0.9376
val Loss: 0.2374 Acc: 0.9295
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2064 Acc: 0.9393
val Loss: 0.2340 Acc: 0.9314
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2036 Acc: 0.9402
val Loss: 0.2324 Acc: 0.9323
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2041 Acc: 0.9400
val Loss: 0.2327 Acc: 0.9322
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2041 Acc: 0.9396
val Loss: 0.2361 Acc: 0.9318
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2039 Acc: 0.9394
val Loss: 0.2338 Acc: 0.9331
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2038 Acc: 0.9401
val Loss: 0.2349 Acc: 0.9322
Epoch finished in 0m 9s
Best validation accuracy: 0.9322376324123621
Model Test Accuracy:  0.9355408727719728
Pruning Epoch 14
++++++++++++++++++
number of weights to prune:  2971.0
Sparsity of Pruned Mask:  tensor(0.9560)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.9385 Acc: 0.3626
val Loss: 1.2289 Acc: 0.7239
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.7356 Acc: 0.8301
val Loss: 0.4659 Acc: 0.8801
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3937 Acc: 0.8913
val Loss: 0.3477 Acc: 0.8978
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3235 Acc: 0.9062
val Loss: 0.3171 Acc: 0.9077
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2922 Acc: 0.9121
val Loss: 0.3005 Acc: 0.9087
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2791 Acc: 0.9170
val Loss: 0.3166 Acc: 0.9042
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2733 Acc: 0.9181
val Loss: 0.2915 Acc: 0.9123
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2672 Acc: 0.9199
val Loss: 0.2849 Acc: 0.9137
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2636 Acc: 0.9207
val Loss: 0.2895 Acc: 0.9134
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2629 Acc: 0.9201
val Loss: 0.3078 Acc: 0.9073
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2600 Acc: 0.9235
val Loss: 0.3053 Acc: 0.9094
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2621 Acc: 0.9220
val Loss: 0.2952 Acc: 0.9146
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2600 Acc: 0.9222
val Loss: 0.2830 Acc: 0.9157
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2601 Acc: 0.9221
val Loss: 0.3104 Acc: 0.9084
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2556 Acc: 0.9219
val Loss: 0.2996 Acc: 0.9096
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2565 Acc: 0.9228
val Loss: 0.3020 Acc: 0.9079
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2577 Acc: 0.9221
val Loss: 0.2638 Acc: 0.9197
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2347 Acc: 0.9302
val Loss: 0.2541 Acc: 0.9242
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2282 Acc: 0.9332
val Loss: 0.2520 Acc: 0.9257
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2221 Acc: 0.9344
val Loss: 0.2439 Acc: 0.9289
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2196 Acc: 0.9356
val Loss: 0.2470 Acc: 0.9270
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2186 Acc: 0.9356
val Loss: 0.2435 Acc: 0.9285
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2194 Acc: 0.9352
val Loss: 0.2452 Acc: 0.9269
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2194 Acc: 0.9348
val Loss: 0.2443 Acc: 0.9280
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2189 Acc: 0.9352
val Loss: 0.2459 Acc: 0.9266
Epoch finished in 0m 9s
Best validation accuracy: 0.9265589166757672
Model Test Accuracy:  0.933696988322065
Pruning Epoch 15
++++++++++++++++++
number of weights to prune:  2376.0
Sparsity of Pruned Mask:  tensor(0.9648)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.9390 Acc: 0.3501
val Loss: 1.3371 Acc: 0.6477
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.8386 Acc: 0.7950
val Loss: 0.5274 Acc: 0.8615
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4412 Acc: 0.8783
val Loss: 0.3858 Acc: 0.8864
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3525 Acc: 0.8984
val Loss: 0.3456 Acc: 0.8976
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3207 Acc: 0.9041
val Loss: 0.3247 Acc: 0.9031
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3025 Acc: 0.9089
val Loss: 0.3206 Acc: 0.9025
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2930 Acc: 0.9119
val Loss: 0.3037 Acc: 0.9079
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2880 Acc: 0.9144
val Loss: 0.3373 Acc: 0.8966
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2848 Acc: 0.9154
val Loss: 0.3353 Acc: 0.8982
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2804 Acc: 0.9159
val Loss: 0.3191 Acc: 0.9047
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2831 Acc: 0.9143
val Loss: 0.3004 Acc: 0.9096
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2806 Acc: 0.9158
val Loss: 0.3086 Acc: 0.9044
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2751 Acc: 0.9164
val Loss: 0.2865 Acc: 0.9137
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2744 Acc: 0.9178
val Loss: 0.3440 Acc: 0.8968
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2754 Acc: 0.9154
val Loss: 0.3157 Acc: 0.9044
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2735 Acc: 0.9171
val Loss: 0.3070 Acc: 0.9070
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2718 Acc: 0.9180
val Loss: 0.2746 Acc: 0.9164
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2482 Acc: 0.9265
val Loss: 0.2667 Acc: 0.9197
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2373 Acc: 0.9294
val Loss: 0.2636 Acc: 0.9220
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2360 Acc: 0.9309
val Loss: 0.2544 Acc: 0.9240
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2332 Acc: 0.9313
val Loss: 0.2513 Acc: 0.9260
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2329 Acc: 0.9317
val Loss: 0.2553 Acc: 0.9249
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2335 Acc: 0.9301
val Loss: 0.2537 Acc: 0.9258
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2355 Acc: 0.9292
val Loss: 0.2517 Acc: 0.9244
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2353 Acc: 0.9295
val Loss: 0.2531 Acc: 0.9252
Epoch finished in 0m 9s
Best validation accuracy: 0.9251938407775473
Model Test Accuracy:  0.9321604179471419
Pruning Epoch 16
++++++++++++++++++
number of weights to prune:  1901.0
Sparsity of Pruned Mask:  tensor(0.9719)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.0138 Acc: 0.3017
val Loss: 1.4896 Acc: 0.5441
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.9626 Acc: 0.7535
val Loss: 0.6050 Acc: 0.8382
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4939 Acc: 0.8665
val Loss: 0.4305 Acc: 0.8746
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3895 Acc: 0.8867
val Loss: 0.3736 Acc: 0.8894
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3486 Acc: 0.8969
val Loss: 0.3504 Acc: 0.8943
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3305 Acc: 0.9019
val Loss: 0.3402 Acc: 0.8967
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3159 Acc: 0.9035
val Loss: 0.3504 Acc: 0.8902
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3075 Acc: 0.9060
val Loss: 0.3358 Acc: 0.8984
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3030 Acc: 0.9093
val Loss: 0.3320 Acc: 0.8976
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2998 Acc: 0.9106
val Loss: 0.3294 Acc: 0.8999
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2986 Acc: 0.9091
val Loss: 0.3145 Acc: 0.9035
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2961 Acc: 0.9101
val Loss: 0.3262 Acc: 0.9023
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2924 Acc: 0.9130
val Loss: 0.3592 Acc: 0.8939
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2931 Acc: 0.9117
val Loss: 0.3388 Acc: 0.9005
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2949 Acc: 0.9101
val Loss: 0.3267 Acc: 0.8984
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2911 Acc: 0.9124
val Loss: 0.3105 Acc: 0.9078
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2842 Acc: 0.9140
val Loss: 0.2850 Acc: 0.9139
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2624 Acc: 0.9220
val Loss: 0.2708 Acc: 0.9183
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2549 Acc: 0.9243
val Loss: 0.2689 Acc: 0.9216
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2498 Acc: 0.9254
val Loss: 0.2675 Acc: 0.9209
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2505 Acc: 0.9257
val Loss: 0.2656 Acc: 0.9218
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2515 Acc: 0.9252
val Loss: 0.2627 Acc: 0.9230
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2481 Acc: 0.9274
val Loss: 0.2691 Acc: 0.9205
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2468 Acc: 0.9261
val Loss: 0.2642 Acc: 0.9213
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2484 Acc: 0.9261
val Loss: 0.2630 Acc: 0.9228
Epoch finished in 0m 9s
Best validation accuracy: 0.922845910232609
Model Test Accuracy:  0.9286647203441917
Pruning Epoch 17
++++++++++++++++++
number of weights to prune:  1520.0
Sparsity of Pruned Mask:  tensor(0.9775)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.1507 Acc: 0.2304
val Loss: 1.7920 Acc: 0.4013
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.2757 Acc: 0.6404
val Loss: 0.8121 Acc: 0.7991
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.6171 Acc: 0.8401
val Loss: 0.4958 Acc: 0.8557
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4458 Acc: 0.8731
val Loss: 0.4327 Acc: 0.8718
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3898 Acc: 0.8849
val Loss: 0.3661 Acc: 0.8901
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3635 Acc: 0.8905
val Loss: 0.3646 Acc: 0.8891
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3482 Acc: 0.8948
val Loss: 0.3559 Acc: 0.8927
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3405 Acc: 0.8957
val Loss: 0.3578 Acc: 0.8907
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3347 Acc: 0.8984
val Loss: 0.3742 Acc: 0.8845
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3266 Acc: 0.9011
val Loss: 0.3428 Acc: 0.8953
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3289 Acc: 0.9004
val Loss: 0.3364 Acc: 0.8970
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3215 Acc: 0.9018
val Loss: 0.3244 Acc: 0.9017
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3221 Acc: 0.9032
val Loss: 0.3940 Acc: 0.8757
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3233 Acc: 0.9006
val Loss: 0.3715 Acc: 0.8863
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3140 Acc: 0.9051
val Loss: 0.3321 Acc: 0.8978
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3141 Acc: 0.9047
val Loss: 0.3124 Acc: 0.9052
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3131 Acc: 0.9042
val Loss: 0.3098 Acc: 0.9057
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2888 Acc: 0.9133
val Loss: 0.2956 Acc: 0.9115
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2785 Acc: 0.9165
val Loss: 0.2884 Acc: 0.9130
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2780 Acc: 0.9164
val Loss: 0.2898 Acc: 0.9135
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2722 Acc: 0.9185
val Loss: 0.2845 Acc: 0.9136
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2755 Acc: 0.9180
val Loss: 0.2854 Acc: 0.9135
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2719 Acc: 0.9179
val Loss: 0.2880 Acc: 0.9133
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2728 Acc: 0.9176
val Loss: 0.2845 Acc: 0.9139
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2731 Acc: 0.9184
val Loss: 0.2846 Acc: 0.9156
Epoch finished in 0m 9s
Best validation accuracy: 0.9155837064540788
Model Test Accuracy:  0.921519668100799
Pruning Epoch 18
++++++++++++++++++
number of weights to prune:  1216.0
Sparsity of Pruned Mask:  tensor(0.9820)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.1959 Acc: 0.2135
val Loss: 1.9418 Acc: 0.3271
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.5343 Acc: 0.5131
val Loss: 1.1092 Acc: 0.7083
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.8383 Acc: 0.7810
val Loss: 0.6504 Acc: 0.8180
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5785 Acc: 0.8356
val Loss: 0.5257 Acc: 0.8408
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4847 Acc: 0.8565
val Loss: 0.4822 Acc: 0.8521
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4458 Acc: 0.8663
val Loss: 0.4481 Acc: 0.8638
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4222 Acc: 0.8731
val Loss: 0.4453 Acc: 0.8615
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4050 Acc: 0.8765
val Loss: 0.4522 Acc: 0.8624
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3863 Acc: 0.8832
val Loss: 0.4059 Acc: 0.8748
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3827 Acc: 0.8840
val Loss: 0.4411 Acc: 0.8621
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3732 Acc: 0.8873
val Loss: 0.4132 Acc: 0.8748
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3671 Acc: 0.8891
val Loss: 0.4322 Acc: 0.8642
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3634 Acc: 0.8894
val Loss: 0.4084 Acc: 0.8759
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3561 Acc: 0.8920
val Loss: 0.3571 Acc: 0.8907
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3503 Acc: 0.8942
val Loss: 0.3966 Acc: 0.8799
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3485 Acc: 0.8933
val Loss: 0.3904 Acc: 0.8788
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3450 Acc: 0.8953
val Loss: 0.3387 Acc: 0.8983
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3156 Acc: 0.9051
val Loss: 0.3249 Acc: 0.9010
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3120 Acc: 0.9059
val Loss: 0.3138 Acc: 0.9056
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3083 Acc: 0.9077
val Loss: 0.3139 Acc: 0.9073
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3050 Acc: 0.9090
val Loss: 0.3157 Acc: 0.9053
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3034 Acc: 0.9081
val Loss: 0.3134 Acc: 0.9053
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3047 Acc: 0.9086
val Loss: 0.3141 Acc: 0.9055
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3049 Acc: 0.9077
val Loss: 0.3191 Acc: 0.9040
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3058 Acc: 0.9081
val Loss: 0.3133 Acc: 0.9056
Epoch finished in 0m 9s
Best validation accuracy: 0.9055913508791089
Model Test Accuracy:  0.9100722188076213
Pruning Epoch 19
++++++++++++++++++
number of weights to prune:  973.0
Sparsity of Pruned Mask:  tensor(0.9856)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2129 Acc: 0.2039
val Loss: 2.0106 Acc: 0.2872
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.6787 Acc: 0.4390
val Loss: 1.2781 Acc: 0.6478
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.9982 Acc: 0.7358
val Loss: 0.7693 Acc: 0.7905
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.6555 Acc: 0.8201
val Loss: 0.6164 Acc: 0.8196
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5297 Acc: 0.8457
val Loss: 0.5295 Acc: 0.8376
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4809 Acc: 0.8569
val Loss: 0.4558 Acc: 0.8635
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4488 Acc: 0.8633
val Loss: 0.4399 Acc: 0.8641
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4316 Acc: 0.8694
val Loss: 0.4351 Acc: 0.8667
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4152 Acc: 0.8732
val Loss: 0.4494 Acc: 0.8598
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4055 Acc: 0.8758
val Loss: 0.4346 Acc: 0.8667
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3962 Acc: 0.8797
val Loss: 0.4045 Acc: 0.8747
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3884 Acc: 0.8813
val Loss: 0.4310 Acc: 0.8642
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3860 Acc: 0.8818
val Loss: 0.3980 Acc: 0.8756
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3768 Acc: 0.8844
val Loss: 0.4038 Acc: 0.8742
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3754 Acc: 0.8860
val Loss: 0.4035 Acc: 0.8760
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3775 Acc: 0.8843
val Loss: 0.4290 Acc: 0.8685
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3645 Acc: 0.8887
val Loss: 0.3519 Acc: 0.8921
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3405 Acc: 0.8967
val Loss: 0.3358 Acc: 0.8971
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3337 Acc: 0.8991
val Loss: 0.3347 Acc: 0.8974
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3289 Acc: 0.8997
val Loss: 0.3322 Acc: 0.8991
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3289 Acc: 0.9007
val Loss: 0.3321 Acc: 0.8972
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3291 Acc: 0.9005
val Loss: 0.3316 Acc: 0.8992
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3268 Acc: 0.9011
val Loss: 0.3335 Acc: 0.8989
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3303 Acc: 0.9000
val Loss: 0.3307 Acc: 0.8985
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3265 Acc: 0.9015
val Loss: 0.3333 Acc: 0.8978
Epoch finished in 0m 9s
Best validation accuracy: 0.8978377197772196
Model Test Accuracy:  0.904079594345421
Pruning Epoch 20
++++++++++++++++++
number of weights to prune:  778.0
Sparsity of Pruned Mask:  tensor(0.9885)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2279 Acc: 0.1926
val Loss: 2.0807 Acc: 0.2775
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.8294 Acc: 0.3706
val Loss: 1.5452 Acc: 0.5005
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 1.2347 Acc: 0.6248
val Loss: 0.9924 Acc: 0.7178
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.8439 Acc: 0.7574
val Loss: 0.7477 Acc: 0.7772
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.6678 Acc: 0.8035
val Loss: 0.6458 Acc: 0.8009
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.5830 Acc: 0.8244
val Loss: 0.5689 Acc: 0.8224
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.5413 Acc: 0.8342
val Loss: 0.6131 Acc: 0.8038
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.5101 Acc: 0.8430
val Loss: 0.5807 Acc: 0.8141
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4907 Acc: 0.8481
val Loss: 0.5442 Acc: 0.8271
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4739 Acc: 0.8540
val Loss: 0.5142 Acc: 0.8401
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.4537 Acc: 0.8599
val Loss: 0.4776 Acc: 0.8500
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.4512 Acc: 0.8607
val Loss: 0.4822 Acc: 0.8496
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.4374 Acc: 0.8662
val Loss: 0.4567 Acc: 0.8576
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.4323 Acc: 0.8664
val Loss: 0.4459 Acc: 0.8605
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.4286 Acc: 0.8676
val Loss: 0.4489 Acc: 0.8612
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.4206 Acc: 0.8726
val Loss: 0.4385 Acc: 0.8653
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.4154 Acc: 0.8722
val Loss: 0.4009 Acc: 0.8760
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3911 Acc: 0.8806
val Loss: 0.3831 Acc: 0.8821
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3829 Acc: 0.8832
val Loss: 0.3815 Acc: 0.8823
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3784 Acc: 0.8850
val Loss: 0.3777 Acc: 0.8855
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3785 Acc: 0.8857
val Loss: 0.3762 Acc: 0.8838
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3770 Acc: 0.8840
val Loss: 0.3753 Acc: 0.8846
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3777 Acc: 0.8856
val Loss: 0.3792 Acc: 0.8822
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3772 Acc: 0.8852
val Loss: 0.3775 Acc: 0.8834
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3762 Acc: 0.8850
val Loss: 0.3737 Acc: 0.8854
Epoch finished in 0m 9s
Best validation accuracy: 0.8853882275854538
Model Test Accuracy:  0.8876382913337431
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2569 Acc: 0.1737
val Loss: 2.2297 Acc: 0.1930
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.0819 Acc: 0.2565
val Loss: 1.8759 Acc: 0.3334
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 1.2783 Acc: 0.5621
val Loss: 0.9071 Acc: 0.7128
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5798 Acc: 0.8162
val Loss: 0.5317 Acc: 0.8372
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4413 Acc: 0.8632
val Loss: 0.4417 Acc: 0.8615
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3799 Acc: 0.8839
val Loss: 0.4175 Acc: 0.8726
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3511 Acc: 0.8935
val Loss: 0.3656 Acc: 0.8911
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3181 Acc: 0.9036
val Loss: 0.3709 Acc: 0.8914
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3031 Acc: 0.9090
val Loss: 0.3334 Acc: 0.9017
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2803 Acc: 0.9151
val Loss: 0.3273 Acc: 0.9025
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2714 Acc: 0.9184
val Loss: 0.3209 Acc: 0.9044
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2614 Acc: 0.9222
val Loss: 0.3056 Acc: 0.9088
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2529 Acc: 0.9247
val Loss: 0.2819 Acc: 0.9168
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2463 Acc: 0.9272
val Loss: 0.3082 Acc: 0.9087
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2362 Acc: 0.9295
val Loss: 0.2610 Acc: 0.9245
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2278 Acc: 0.9322
val Loss: 0.3124 Acc: 0.9115
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2272 Acc: 0.9317
val Loss: 0.2397 Acc: 0.9285
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1911 Acc: 0.9440
val Loss: 0.2218 Acc: 0.9357
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1815 Acc: 0.9467
val Loss: 0.2171 Acc: 0.9381
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1758 Acc: 0.9490
val Loss: 0.2172 Acc: 0.9372
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1736 Acc: 0.9495
val Loss: 0.2149 Acc: 0.9384
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1720 Acc: 0.9507
val Loss: 0.2149 Acc: 0.9384
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1733 Acc: 0.9491
val Loss: 0.2169 Acc: 0.9397
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1715 Acc: 0.9505
val Loss: 0.2183 Acc: 0.9384
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1708 Acc: 0.9503
val Loss: 0.2153 Acc: 0.9378
Epoch finished in 0m 12s
Best validation accuracy: 0.9378071420770995
Before Pruning
++++++++++++++++++
Model Test Accuracy:  0.9422633681622617
Pruning Epoch 1
++++++++++++++++++
number of weights to prune:  54052.0
Sparsity of Pruned Mask:  tensor(0.2000)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2025 Acc: 0.2064
val Loss: 1.9974 Acc: 0.2873
Epoch finished in 0m 40s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.1982 Acc: 0.5890
val Loss: 0.5729 Acc: 0.8243
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4677 Acc: 0.8555
val Loss: 0.4652 Acc: 0.8523
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3767 Acc: 0.8859
val Loss: 0.3758 Acc: 0.8965
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3263 Acc: 0.9017
val Loss: 0.3502 Acc: 0.8966
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3030 Acc: 0.9084
val Loss: 0.3434 Acc: 0.8961
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2837 Acc: 0.9159
val Loss: 0.3238 Acc: 0.9034
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2665 Acc: 0.9196
val Loss: 0.3364 Acc: 0.9107
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2564 Acc: 0.9246
val Loss: 0.2728 Acc: 0.9183
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2464 Acc: 0.9277
val Loss: 0.2913 Acc: 0.9179
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2365 Acc: 0.9297
val Loss: 0.2711 Acc: 0.9231
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2325 Acc: 0.9303
val Loss: 0.2562 Acc: 0.9271
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2241 Acc: 0.9333
val Loss: 0.2706 Acc: 0.9218
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2180 Acc: 0.9356
val Loss: 0.2700 Acc: 0.9221
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2155 Acc: 0.9355
val Loss: 0.2679 Acc: 0.9239
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2127 Acc: 0.9381
val Loss: 0.2485 Acc: 0.9301
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2035 Acc: 0.9395
val Loss: 0.2246 Acc: 0.9345
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1710 Acc: 0.9494
val Loss: 0.2123 Acc: 0.9399
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1613 Acc: 0.9530
val Loss: 0.2058 Acc: 0.9429
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1589 Acc: 0.9538
val Loss: 0.2000 Acc: 0.9427
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1551 Acc: 0.9551
val Loss: 0.2053 Acc: 0.9428
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1533 Acc: 0.9551
val Loss: 0.2062 Acc: 0.9418
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1543 Acc: 0.9548
val Loss: 0.2030 Acc: 0.9427
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1523 Acc: 0.9560
val Loss: 0.2061 Acc: 0.9414
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1526 Acc: 0.9554
val Loss: 0.2040 Acc: 0.9429
Epoch finished in 0m 12s
Best validation accuracy: 0.9428852244184777
Model Test Accuracy:  0.9466810079901659
Pruning Epoch 2
++++++++++++++++++
number of weights to prune:  43241.0
Sparsity of Pruned Mask:  tensor(0.3600)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.0074 Acc: 0.2852
val Loss: 0.9853 Acc: 0.6798
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5129 Acc: 0.8408
val Loss: 0.3867 Acc: 0.8808
Epoch finished in 0m 33s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3509 Acc: 0.8934
val Loss: 0.4098 Acc: 0.8953
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2994 Acc: 0.9105
val Loss: 0.3339 Acc: 0.8976
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2740 Acc: 0.9186
val Loss: 0.3045 Acc: 0.9086
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2575 Acc: 0.9231
val Loss: 0.2824 Acc: 0.9205
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2414 Acc: 0.9279
val Loss: 0.2815 Acc: 0.9222
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2308 Acc: 0.9317
val Loss: 0.2695 Acc: 0.9183
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2257 Acc: 0.9329
val Loss: 0.2743 Acc: 0.9216
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2192 Acc: 0.9341
val Loss: 0.2447 Acc: 0.9285
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2127 Acc: 0.9369
val Loss: 0.2976 Acc: 0.9191
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2098 Acc: 0.9385
val Loss: 0.2677 Acc: 0.9245
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2070 Acc: 0.9390
val Loss: 0.2457 Acc: 0.9289
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2016 Acc: 0.9400
val Loss: 0.2509 Acc: 0.9262
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2002 Acc: 0.9409
val Loss: 0.2439 Acc: 0.9280
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1985 Acc: 0.9411
val Loss: 0.2487 Acc: 0.9267
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1907 Acc: 0.9436
val Loss: 0.2199 Acc: 0.9385
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1586 Acc: 0.9528
val Loss: 0.2106 Acc: 0.9414
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1492 Acc: 0.9564
val Loss: 0.2055 Acc: 0.9415
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1447 Acc: 0.9564
val Loss: 0.2065 Acc: 0.9435
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1453 Acc: 0.9573
val Loss: 0.2056 Acc: 0.9444
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1441 Acc: 0.9574
val Loss: 0.2041 Acc: 0.9430
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1443 Acc: 0.9584
val Loss: 0.2035 Acc: 0.9417
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1419 Acc: 0.9584
val Loss: 0.1992 Acc: 0.9437
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1411 Acc: 0.9591
val Loss: 0.1993 Acc: 0.9441
Epoch finished in 0m 12s
Best validation accuracy: 0.9440864912089112
Model Test Accuracy:  0.9469114935464044
Pruning Epoch 3
++++++++++++++++++
number of weights to prune:  34593.0
Sparsity of Pruned Mask:  tensor(0.4880)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.7348 Acc: 0.3921
val Loss: 0.5776 Acc: 0.8162
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4063 Acc: 0.8742
val Loss: 0.3522 Acc: 0.8932
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3066 Acc: 0.9091
val Loss: 0.3093 Acc: 0.9091
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2645 Acc: 0.9217
val Loss: 0.2898 Acc: 0.9131
Epoch finished in 0m 13s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2444 Acc: 0.9275
val Loss: 0.3089 Acc: 0.9145
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2300 Acc: 0.9315
val Loss: 0.2761 Acc: 0.9190
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2187 Acc: 0.9358
val Loss: 0.2657 Acc: 0.9224
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2132 Acc: 0.9367
val Loss: 0.2897 Acc: 0.9161
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2103 Acc: 0.9376
val Loss: 0.2346 Acc: 0.9314
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2020 Acc: 0.9403
val Loss: 0.2498 Acc: 0.9253
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1973 Acc: 0.9409
val Loss: 0.2693 Acc: 0.9221
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1950 Acc: 0.9417
val Loss: 0.2544 Acc: 0.9251
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1927 Acc: 0.9427
val Loss: 0.2399 Acc: 0.9341
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1886 Acc: 0.9445
val Loss: 0.2393 Acc: 0.9326
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1908 Acc: 0.9436
val Loss: 0.2571 Acc: 0.9252
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1869 Acc: 0.9453
val Loss: 0.2460 Acc: 0.9323
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1825 Acc: 0.9457
val Loss: 0.2247 Acc: 0.9367
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1554 Acc: 0.9536
val Loss: 0.2141 Acc: 0.9425
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1441 Acc: 0.9573
val Loss: 0.2103 Acc: 0.9428
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1412 Acc: 0.9587
val Loss: 0.2054 Acc: 0.9437
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1376 Acc: 0.9600
val Loss: 0.2075 Acc: 0.9411
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1393 Acc: 0.9588
val Loss: 0.2061 Acc: 0.9434
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1384 Acc: 0.9589
val Loss: 0.1999 Acc: 0.9467
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1370 Acc: 0.9595
val Loss: 0.2062 Acc: 0.9444
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1358 Acc: 0.9609
val Loss: 0.2073 Acc: 0.9422
Epoch finished in 0m 12s
Best validation accuracy: 0.9421753849514033
Model Test Accuracy:  0.9479870928088505
Pruning Epoch 4
++++++++++++++++++
number of weights to prune:  27674.0
Sparsity of Pruned Mask:  tensor(0.5904)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6420 Acc: 0.4312
val Loss: 0.4993 Acc: 0.8426
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3678 Acc: 0.8858
val Loss: 0.3359 Acc: 0.9022
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2825 Acc: 0.9146
val Loss: 0.2768 Acc: 0.9180
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2469 Acc: 0.9268
val Loss: 0.2663 Acc: 0.9226
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2243 Acc: 0.9352
val Loss: 0.2549 Acc: 0.9252
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2137 Acc: 0.9378
val Loss: 0.2757 Acc: 0.9226
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2025 Acc: 0.9398
val Loss: 0.2720 Acc: 0.9240
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1991 Acc: 0.9406
val Loss: 0.2389 Acc: 0.9304
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1938 Acc: 0.9415
val Loss: 0.2726 Acc: 0.9229
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1924 Acc: 0.9436
val Loss: 0.2498 Acc: 0.9298
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1866 Acc: 0.9439
val Loss: 0.2540 Acc: 0.9249
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1838 Acc: 0.9455
val Loss: 0.2737 Acc: 0.9222
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1871 Acc: 0.9434
val Loss: 0.2518 Acc: 0.9285
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1797 Acc: 0.9457
val Loss: 0.2812 Acc: 0.9168
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1829 Acc: 0.9464
val Loss: 0.2645 Acc: 0.9255
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1795 Acc: 0.9472
val Loss: 0.2337 Acc: 0.9333
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1762 Acc: 0.9474
val Loss: 0.2196 Acc: 0.9374
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1484 Acc: 0.9563
val Loss: 0.2063 Acc: 0.9426
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1387 Acc: 0.9601
val Loss: 0.2064 Acc: 0.9446
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1356 Acc: 0.9609
val Loss: 0.2055 Acc: 0.9444
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1318 Acc: 0.9617
val Loss: 0.2051 Acc: 0.9436
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1300 Acc: 0.9629
val Loss: 0.2051 Acc: 0.9449
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1298 Acc: 0.9622
val Loss: 0.2044 Acc: 0.9440
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1308 Acc: 0.9621
val Loss: 0.2024 Acc: 0.9442
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1320 Acc: 0.9613
val Loss: 0.2065 Acc: 0.9424
Epoch finished in 0m 12s
Best validation accuracy: 0.9424484001310472
Model Test Accuracy:  0.9465273509526736
Pruning Epoch 5
++++++++++++++++++
number of weights to prune:  22139.0
Sparsity of Pruned Mask:  tensor(0.6723)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.5634 Acc: 0.4564
val Loss: 0.4667 Acc: 0.8546
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3523 Acc: 0.8935
val Loss: 0.4080 Acc: 0.8744
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2690 Acc: 0.9194
val Loss: 0.2981 Acc: 0.9119
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2303 Acc: 0.9316
val Loss: 0.2660 Acc: 0.9250
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2170 Acc: 0.9365
val Loss: 0.2719 Acc: 0.9204
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2038 Acc: 0.9400
val Loss: 0.2570 Acc: 0.9257
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1959 Acc: 0.9422
val Loss: 0.2373 Acc: 0.9315
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1910 Acc: 0.9431
val Loss: 0.2596 Acc: 0.9284
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1848 Acc: 0.9448
val Loss: 0.2815 Acc: 0.9246
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1838 Acc: 0.9444
val Loss: 0.2567 Acc: 0.9292
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1825 Acc: 0.9461
val Loss: 0.2441 Acc: 0.9306
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1795 Acc: 0.9474
val Loss: 0.2334 Acc: 0.9369
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1782 Acc: 0.9466
val Loss: 0.2585 Acc: 0.9258
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1768 Acc: 0.9469
val Loss: 0.2693 Acc: 0.9285
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1747 Acc: 0.9475
val Loss: 0.2955 Acc: 0.9111
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1752 Acc: 0.9476
val Loss: 0.2643 Acc: 0.9278
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1716 Acc: 0.9485
val Loss: 0.2240 Acc: 0.9394
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1422 Acc: 0.9580
val Loss: 0.2152 Acc: 0.9423
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1346 Acc: 0.9594
val Loss: 0.2115 Acc: 0.9424
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1298 Acc: 0.9615
val Loss: 0.2074 Acc: 0.9444
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1288 Acc: 0.9624
val Loss: 0.2077 Acc: 0.9438
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1280 Acc: 0.9620
val Loss: 0.2053 Acc: 0.9456
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1269 Acc: 0.9635
val Loss: 0.2064 Acc: 0.9447
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1274 Acc: 0.9638
val Loss: 0.2055 Acc: 0.9447
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1275 Acc: 0.9624
val Loss: 0.2031 Acc: 0.9451
Epoch finished in 0m 12s
Best validation accuracy: 0.9451239488915584
Model Test Accuracy:  0.948179164105716
Pruning Epoch 6
++++++++++++++++++
number of weights to prune:  17711.0
Sparsity of Pruned Mask:  tensor(0.7379)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.5828 Acc: 0.4500
val Loss: 0.4634 Acc: 0.8537
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3473 Acc: 0.8938
val Loss: 0.3284 Acc: 0.9080
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2626 Acc: 0.9211
val Loss: 0.2904 Acc: 0.9157
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2284 Acc: 0.9328
val Loss: 0.2611 Acc: 0.9220
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2105 Acc: 0.9387
val Loss: 0.2502 Acc: 0.9267
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1962 Acc: 0.9422
val Loss: 0.2696 Acc: 0.9226
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1926 Acc: 0.9419
val Loss: 0.2674 Acc: 0.9285
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1829 Acc: 0.9450
val Loss: 0.2881 Acc: 0.9190
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1809 Acc: 0.9457
val Loss: 0.2597 Acc: 0.9290
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1800 Acc: 0.9463
val Loss: 0.2756 Acc: 0.9219
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1771 Acc: 0.9473
val Loss: 0.2664 Acc: 0.9284
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1765 Acc: 0.9467
val Loss: 0.2691 Acc: 0.9266
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1742 Acc: 0.9478
val Loss: 0.2518 Acc: 0.9285
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1728 Acc: 0.9490
val Loss: 0.2438 Acc: 0.9343
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1740 Acc: 0.9477
val Loss: 0.2455 Acc: 0.9288
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1733 Acc: 0.9479
val Loss: 0.2492 Acc: 0.9318
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1707 Acc: 0.9488
val Loss: 0.2238 Acc: 0.9372
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1455 Acc: 0.9569
val Loss: 0.2125 Acc: 0.9410
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1367 Acc: 0.9600
val Loss: 0.2103 Acc: 0.9444
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1317 Acc: 0.9611
val Loss: 0.2026 Acc: 0.9444
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1293 Acc: 0.9621
val Loss: 0.2092 Acc: 0.9428
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1287 Acc: 0.9623
val Loss: 0.2078 Acc: 0.9450
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1268 Acc: 0.9634
val Loss: 0.2092 Acc: 0.9438
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1271 Acc: 0.9620
val Loss: 0.2057 Acc: 0.9446
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1269 Acc: 0.9622
val Loss: 0.2033 Acc: 0.9441
Epoch finished in 0m 12s
Best validation accuracy: 0.94414109424484
Model Test Accuracy:  0.9472572218807621
Pruning Epoch 7
++++++++++++++++++
number of weights to prune:  14168.0
Sparsity of Pruned Mask:  tensor(0.7903)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.5860 Acc: 0.4485
val Loss: 0.4832 Acc: 0.8478
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3471 Acc: 0.8943
val Loss: 0.3174 Acc: 0.9050
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2624 Acc: 0.9220
val Loss: 0.2877 Acc: 0.9169
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2251 Acc: 0.9345
val Loss: 0.3013 Acc: 0.9097
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2071 Acc: 0.9380
val Loss: 0.2637 Acc: 0.9311
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1947 Acc: 0.9426
val Loss: 0.2482 Acc: 0.9287
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1874 Acc: 0.9440
val Loss: 0.2429 Acc: 0.9292
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1837 Acc: 0.9457
val Loss: 0.2462 Acc: 0.9292
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1792 Acc: 0.9470
val Loss: 0.2480 Acc: 0.9315
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1793 Acc: 0.9464
val Loss: 0.2387 Acc: 0.9322
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1759 Acc: 0.9474
val Loss: 0.2534 Acc: 0.9295
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1758 Acc: 0.9477
val Loss: 0.2377 Acc: 0.9319
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1722 Acc: 0.9489
val Loss: 0.2603 Acc: 0.9297
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1719 Acc: 0.9487
val Loss: 0.2461 Acc: 0.9293
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1731 Acc: 0.9488
val Loss: 0.2576 Acc: 0.9283
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1724 Acc: 0.9481
val Loss: 0.2485 Acc: 0.9298
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1690 Acc: 0.9498
val Loss: 0.2256 Acc: 0.9366
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1420 Acc: 0.9580
val Loss: 0.2103 Acc: 0.9418
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1367 Acc: 0.9598
val Loss: 0.2122 Acc: 0.9423
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1312 Acc: 0.9613
val Loss: 0.2079 Acc: 0.9434
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1315 Acc: 0.9610
val Loss: 0.2083 Acc: 0.9435
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1303 Acc: 0.9610
val Loss: 0.2102 Acc: 0.9428
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1300 Acc: 0.9619
val Loss: 0.2051 Acc: 0.9450
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1290 Acc: 0.9627
val Loss: 0.2100 Acc: 0.9422
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1293 Acc: 0.9620
val Loss: 0.2083 Acc: 0.9421
Epoch finished in 0m 12s
Best validation accuracy: 0.9420661788795457
Model Test Accuracy:  0.948678549477566
Pruning Epoch 8
++++++++++++++++++
number of weights to prune:  11335.0
Sparsity of Pruned Mask:  tensor(0.8323)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6133 Acc: 0.4367
val Loss: 0.4798 Acc: 0.8540
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3564 Acc: 0.8919
val Loss: 0.3150 Acc: 0.9117
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2645 Acc: 0.9205
val Loss: 0.2708 Acc: 0.9188
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2295 Acc: 0.9326
val Loss: 0.3509 Acc: 0.9267
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2103 Acc: 0.9382
val Loss: 0.2673 Acc: 0.9214
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1960 Acc: 0.9421
val Loss: 0.2493 Acc: 0.9264
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1888 Acc: 0.9430
val Loss: 0.2586 Acc: 0.9251
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1852 Acc: 0.9455
val Loss: 0.2498 Acc: 0.9309
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1845 Acc: 0.9449
val Loss: 0.2453 Acc: 0.9297
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1812 Acc: 0.9462
val Loss: 0.2442 Acc: 0.9291
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1805 Acc: 0.9470
val Loss: 0.2395 Acc: 0.9320
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1766 Acc: 0.9479
val Loss: 0.2803 Acc: 0.9186
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1803 Acc: 0.9468
val Loss: 0.2541 Acc: 0.9282
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1792 Acc: 0.9457
val Loss: 0.2712 Acc: 0.9244
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1759 Acc: 0.9469
val Loss: 0.2348 Acc: 0.9333
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1760 Acc: 0.9470
val Loss: 0.2357 Acc: 0.9317
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1759 Acc: 0.9480
val Loss: 0.2296 Acc: 0.9377
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1462 Acc: 0.9559
val Loss: 0.2167 Acc: 0.9415
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1405 Acc: 0.9593
val Loss: 0.2136 Acc: 0.9410
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1372 Acc: 0.9596
val Loss: 0.2129 Acc: 0.9414
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1345 Acc: 0.9602
val Loss: 0.2145 Acc: 0.9418
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1338 Acc: 0.9608
val Loss: 0.2107 Acc: 0.9426
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1330 Acc: 0.9611
val Loss: 0.2116 Acc: 0.9426
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1349 Acc: 0.9604
val Loss: 0.2094 Acc: 0.9433
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1334 Acc: 0.9610
val Loss: 0.2125 Acc: 0.9430
Epoch finished in 0m 12s
Best validation accuracy: 0.9430490335262641
Model Test Accuracy:  0.9460663798401966
Pruning Epoch 9
++++++++++++++++++
number of weights to prune:  9067.0
Sparsity of Pruned Mask:  tensor(0.8658)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6406 Acc: 0.4273
val Loss: 0.4890 Acc: 0.8468
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3613 Acc: 0.8900
val Loss: 0.3216 Acc: 0.9060
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2657 Acc: 0.9212
val Loss: 0.2766 Acc: 0.9170
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2307 Acc: 0.9309
val Loss: 0.2617 Acc: 0.9220
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2072 Acc: 0.9384
val Loss: 0.2670 Acc: 0.9260
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2041 Acc: 0.9401
val Loss: 0.2448 Acc: 0.9299
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1932 Acc: 0.9431
val Loss: 0.2684 Acc: 0.9206
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1907 Acc: 0.9447
val Loss: 0.2530 Acc: 0.9283
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1878 Acc: 0.9445
val Loss: 0.2725 Acc: 0.9295
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1845 Acc: 0.9455
val Loss: 0.2510 Acc: 0.9266
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1857 Acc: 0.9447
val Loss: 0.2487 Acc: 0.9277
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1871 Acc: 0.9430
val Loss: 0.2503 Acc: 0.9287
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1848 Acc: 0.9448
val Loss: 0.2593 Acc: 0.9279
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1816 Acc: 0.9457
val Loss: 0.2545 Acc: 0.9271
Epoch finished in 0m 13s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1849 Acc: 0.9461
val Loss: 0.2496 Acc: 0.9270
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1831 Acc: 0.9459
val Loss: 0.2619 Acc: 0.9226
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1798 Acc: 0.9470
val Loss: 0.2257 Acc: 0.9339
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1565 Acc: 0.9534
val Loss: 0.2172 Acc: 0.9374
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1479 Acc: 0.9562
val Loss: 0.2150 Acc: 0.9387
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1423 Acc: 0.9580
val Loss: 0.2138 Acc: 0.9404
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1423 Acc: 0.9578
val Loss: 0.2105 Acc: 0.9403
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1398 Acc: 0.9592
val Loss: 0.2148 Acc: 0.9397
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1406 Acc: 0.9592
val Loss: 0.2127 Acc: 0.9416
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1397 Acc: 0.9589
val Loss: 0.2097 Acc: 0.9390
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1403 Acc: 0.9584
val Loss: 0.2153 Acc: 0.9403
Epoch finished in 0m 12s
Best validation accuracy: 0.9403188817298241
Model Test Accuracy:  0.9451444376152427
Pruning Epoch 10
++++++++++++++++++
number of weights to prune:  7254.0
Sparsity of Pruned Mask:  tensor(0.8926)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.7383 Acc: 0.3923
val Loss: 0.5091 Acc: 0.8438
Epoch finished in 0m 40s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3690 Acc: 0.8889
val Loss: 0.3285 Acc: 0.9056
Epoch finished in 0m 33s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2780 Acc: 0.9182
val Loss: 0.2768 Acc: 0.9179
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2367 Acc: 0.9300
val Loss: 0.2544 Acc: 0.9259
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2182 Acc: 0.9361
val Loss: 0.2894 Acc: 0.9165
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2073 Acc: 0.9374
val Loss: 0.2796 Acc: 0.9192
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2018 Acc: 0.9408
val Loss: 0.2589 Acc: 0.9281
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1952 Acc: 0.9422
val Loss: 0.2635 Acc: 0.9263
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1945 Acc: 0.9419
val Loss: 0.2346 Acc: 0.9324
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1960 Acc: 0.9423
val Loss: 0.2680 Acc: 0.9233
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1931 Acc: 0.9425
val Loss: 0.2705 Acc: 0.9230
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1907 Acc: 0.9435
val Loss: 0.2364 Acc: 0.9301
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1893 Acc: 0.9436
val Loss: 0.2295 Acc: 0.9351
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1892 Acc: 0.9444
val Loss: 0.2490 Acc: 0.9292
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1914 Acc: 0.9430
val Loss: 0.2670 Acc: 0.9226
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1936 Acc: 0.9428
val Loss: 0.2513 Acc: 0.9297
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1898 Acc: 0.9440
val Loss: 0.2238 Acc: 0.9347
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1667 Acc: 0.9504
val Loss: 0.2149 Acc: 0.9404
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1547 Acc: 0.9548
val Loss: 0.2115 Acc: 0.9410
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1515 Acc: 0.9558
val Loss: 0.2129 Acc: 0.9413
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1472 Acc: 0.9568
val Loss: 0.2154 Acc: 0.9405
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1478 Acc: 0.9566
val Loss: 0.2126 Acc: 0.9416
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1478 Acc: 0.9570
val Loss: 0.2137 Acc: 0.9419
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1484 Acc: 0.9565
val Loss: 0.2122 Acc: 0.9410
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1475 Acc: 0.9566
val Loss: 0.2148 Acc: 0.9403
Epoch finished in 0m 12s
Best validation accuracy: 0.9403188817298241
Model Test Accuracy:  0.947218807621389
Pruning Epoch 11
++++++++++++++++++
number of weights to prune:  5803.0
Sparsity of Pruned Mask:  tensor(0.9141)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.7749 Acc: 0.3784
val Loss: 0.5583 Acc: 0.8226
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3958 Acc: 0.8783
val Loss: 0.3260 Acc: 0.8998
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2965 Acc: 0.9134
val Loss: 0.3166 Acc: 0.9137
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2442 Acc: 0.9278
val Loss: 0.2653 Acc: 0.9232
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2252 Acc: 0.9335
val Loss: 0.2651 Acc: 0.9225
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2167 Acc: 0.9365
val Loss: 0.2506 Acc: 0.9280
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2128 Acc: 0.9378
val Loss: 0.2915 Acc: 0.9216
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2066 Acc: 0.9389
val Loss: 0.2480 Acc: 0.9304
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2027 Acc: 0.9407
val Loss: 0.2673 Acc: 0.9203
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2017 Acc: 0.9406
val Loss: 0.2672 Acc: 0.9274
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1997 Acc: 0.9420
val Loss: 0.2618 Acc: 0.9295
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2028 Acc: 0.9402
val Loss: 0.2816 Acc: 0.9181
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2001 Acc: 0.9408
val Loss: 0.2788 Acc: 0.9223
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1995 Acc: 0.9412
val Loss: 0.2562 Acc: 0.9255
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1991 Acc: 0.9419
val Loss: 0.2591 Acc: 0.9228
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1992 Acc: 0.9413
val Loss: 0.2561 Acc: 0.9260
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1985 Acc: 0.9405
val Loss: 0.2309 Acc: 0.9323
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1734 Acc: 0.9486
val Loss: 0.2194 Acc: 0.9382
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1663 Acc: 0.9507
val Loss: 0.2179 Acc: 0.9380
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1617 Acc: 0.9523
val Loss: 0.2110 Acc: 0.9407
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1594 Acc: 0.9534
val Loss: 0.2111 Acc: 0.9410
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1583 Acc: 0.9542
val Loss: 0.2142 Acc: 0.9405
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1581 Acc: 0.9543
val Loss: 0.2133 Acc: 0.9392
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1601 Acc: 0.9538
val Loss: 0.2162 Acc: 0.9393
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1591 Acc: 0.9539
val Loss: 0.2167 Acc: 0.9390
Epoch finished in 0m 12s
Best validation accuracy: 0.939008408867533
Model Test Accuracy:  0.9436846957590657
Pruning Epoch 12
++++++++++++++++++
number of weights to prune:  4642.0
Sparsity of Pruned Mask:  tensor(0.9313)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.9239 Acc: 0.3198
val Loss: 0.6877 Acc: 0.7852
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4234 Acc: 0.8688
val Loss: 0.3331 Acc: 0.8975
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2949 Acc: 0.9111
val Loss: 0.3193 Acc: 0.9025
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2571 Acc: 0.9247
val Loss: 0.2741 Acc: 0.9210
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2385 Acc: 0.9297
val Loss: 0.2694 Acc: 0.9240
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2262 Acc: 0.9336
val Loss: 0.2553 Acc: 0.9252
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2189 Acc: 0.9349
val Loss: 0.2551 Acc: 0.9295
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2147 Acc: 0.9373
val Loss: 0.2776 Acc: 0.9185
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2149 Acc: 0.9372
val Loss: 0.2600 Acc: 0.9248
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2103 Acc: 0.9385
val Loss: 0.2616 Acc: 0.9243
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2117 Acc: 0.9377
val Loss: 0.2536 Acc: 0.9284
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2095 Acc: 0.9384
val Loss: 0.2601 Acc: 0.9241
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2103 Acc: 0.9371
val Loss: 0.2769 Acc: 0.9250
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2095 Acc: 0.9376
val Loss: 0.2513 Acc: 0.9267
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2080 Acc: 0.9388
val Loss: 0.2621 Acc: 0.9255
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2083 Acc: 0.9384
val Loss: 0.2836 Acc: 0.9221
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2099 Acc: 0.9386
val Loss: 0.2361 Acc: 0.9308
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1876 Acc: 0.9451
val Loss: 0.2176 Acc: 0.9369
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1767 Acc: 0.9475
val Loss: 0.2187 Acc: 0.9382
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1711 Acc: 0.9507
val Loss: 0.2187 Acc: 0.9388
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1713 Acc: 0.9503
val Loss: 0.2152 Acc: 0.9381
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1685 Acc: 0.9514
val Loss: 0.2188 Acc: 0.9385
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1692 Acc: 0.9512
val Loss: 0.2160 Acc: 0.9381
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1696 Acc: 0.9509
val Loss: 0.2185 Acc: 0.9396
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1687 Acc: 0.9514
val Loss: 0.2203 Acc: 0.9384
Epoch finished in 0m 12s
Best validation accuracy: 0.9383531724363875
Model Test Accuracy:  0.9441456668715427
Pruning Epoch 13
++++++++++++++++++
number of weights to prune:  3713.0
Sparsity of Pruned Mask:  tensor(0.9450)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.8523 Acc: 0.3461
val Loss: 0.6402 Acc: 0.7931
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4232 Acc: 0.8713
val Loss: 0.3636 Acc: 0.8883
Epoch finished in 0m 33s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3054 Acc: 0.9090
val Loss: 0.2901 Acc: 0.9146
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2671 Acc: 0.9199
val Loss: 0.2963 Acc: 0.9100
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2488 Acc: 0.9261
val Loss: 0.2678 Acc: 0.9233
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2387 Acc: 0.9297
val Loss: 0.2811 Acc: 0.9177
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2322 Acc: 0.9317
val Loss: 0.2618 Acc: 0.9239
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2288 Acc: 0.9327
val Loss: 0.2620 Acc: 0.9234
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2272 Acc: 0.9335
val Loss: 0.3085 Acc: 0.9188
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2237 Acc: 0.9341
val Loss: 0.2805 Acc: 0.9221
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2283 Acc: 0.9329
val Loss: 0.3036 Acc: 0.9067
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2251 Acc: 0.9343
val Loss: 0.2539 Acc: 0.9268
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2219 Acc: 0.9341
val Loss: 0.2541 Acc: 0.9271
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2212 Acc: 0.9342
val Loss: 0.2700 Acc: 0.9208
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2214 Acc: 0.9352
val Loss: 0.2617 Acc: 0.9278
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2221 Acc: 0.9344
val Loss: 0.2750 Acc: 0.9167
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2235 Acc: 0.9330
val Loss: 0.2468 Acc: 0.9288
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1958 Acc: 0.9424
val Loss: 0.2374 Acc: 0.9344
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1863 Acc: 0.9455
val Loss: 0.2252 Acc: 0.9362
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1838 Acc: 0.9455
val Loss: 0.2233 Acc: 0.9362
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1832 Acc: 0.9470
val Loss: 0.2263 Acc: 0.9346
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1833 Acc: 0.9472
val Loss: 0.2225 Acc: 0.9355
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1818 Acc: 0.9467
val Loss: 0.2249 Acc: 0.9358
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1820 Acc: 0.9464
val Loss: 0.2228 Acc: 0.9368
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1813 Acc: 0.9474
val Loss: 0.2239 Acc: 0.9361
Epoch finished in 0m 12s
Best validation accuracy: 0.9361144479633068
Model Test Accuracy:  0.9424170251997541
Pruning Epoch 14
++++++++++++++++++
number of weights to prune:  2971.0
Sparsity of Pruned Mask:  tensor(0.9560)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.9237 Acc: 0.3232
val Loss: 0.6877 Acc: 0.7806
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4416 Acc: 0.8657
val Loss: 0.3635 Acc: 0.8881
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3136 Acc: 0.9064
val Loss: 0.3147 Acc: 0.9044
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2770 Acc: 0.9173
val Loss: 0.2903 Acc: 0.9157
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2607 Acc: 0.9223
val Loss: 0.2953 Acc: 0.9169
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2532 Acc: 0.9248
val Loss: 0.2820 Acc: 0.9167
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2469 Acc: 0.9266
val Loss: 0.2711 Acc: 0.9215
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2420 Acc: 0.9286
val Loss: 0.2645 Acc: 0.9224
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2406 Acc: 0.9289
val Loss: 0.2826 Acc: 0.9169
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2409 Acc: 0.9294
val Loss: 0.2913 Acc: 0.9150
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2354 Acc: 0.9307
val Loss: 0.2829 Acc: 0.9207
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2370 Acc: 0.9298
val Loss: 0.2780 Acc: 0.9183
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2338 Acc: 0.9295
val Loss: 0.2674 Acc: 0.9242
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2336 Acc: 0.9311
val Loss: 0.3030 Acc: 0.9113
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2359 Acc: 0.9317
val Loss: 0.3061 Acc: 0.9118
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2363 Acc: 0.9304
val Loss: 0.2702 Acc: 0.9222
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2319 Acc: 0.9310
val Loss: 0.2372 Acc: 0.9325
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2039 Acc: 0.9408
val Loss: 0.2311 Acc: 0.9331
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1985 Acc: 0.9419
val Loss: 0.2292 Acc: 0.9322
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1957 Acc: 0.9423
val Loss: 0.2227 Acc: 0.9352
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1960 Acc: 0.9440
val Loss: 0.2299 Acc: 0.9346
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1938 Acc: 0.9432
val Loss: 0.2235 Acc: 0.9368
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1926 Acc: 0.9446
val Loss: 0.2233 Acc: 0.9357
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1937 Acc: 0.9439
val Loss: 0.2208 Acc: 0.9357
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1920 Acc: 0.9438
val Loss: 0.2265 Acc: 0.9356
Epoch finished in 0m 12s
Best validation accuracy: 0.9356230206399476
Model Test Accuracy:  0.9409956976029501
Pruning Epoch 15
++++++++++++++++++
number of weights to prune:  2376.0
Sparsity of Pruned Mask:  tensor(0.9648)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.9984 Acc: 0.2927
val Loss: 0.8478 Acc: 0.7295
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5012 Acc: 0.8450
val Loss: 0.3770 Acc: 0.8833
Epoch finished in 0m 33s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3461 Acc: 0.8968
val Loss: 0.3421 Acc: 0.9056
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2996 Acc: 0.9104
val Loss: 0.3067 Acc: 0.9062
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2817 Acc: 0.9163
val Loss: 0.2821 Acc: 0.9153
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2677 Acc: 0.9205
val Loss: 0.2940 Acc: 0.9115
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2616 Acc: 0.9219
val Loss: 0.2872 Acc: 0.9143
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2570 Acc: 0.9242
val Loss: 0.2952 Acc: 0.9135
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2520 Acc: 0.9267
val Loss: 0.3005 Acc: 0.9111
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2543 Acc: 0.9245
val Loss: 0.2939 Acc: 0.9118
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2500 Acc: 0.9261
val Loss: 0.2888 Acc: 0.9159
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2514 Acc: 0.9257
val Loss: 0.2785 Acc: 0.9169
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2491 Acc: 0.9258
val Loss: 0.3057 Acc: 0.9103
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2526 Acc: 0.9249
val Loss: 0.2664 Acc: 0.9215
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2496 Acc: 0.9271
val Loss: 0.2943 Acc: 0.9170
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2468 Acc: 0.9275
val Loss: 0.3126 Acc: 0.9096
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2468 Acc: 0.9254
val Loss: 0.2569 Acc: 0.9249
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2226 Acc: 0.9342
val Loss: 0.2434 Acc: 0.9299
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2137 Acc: 0.9373
val Loss: 0.2369 Acc: 0.9324
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2109 Acc: 0.9375
val Loss: 0.2335 Acc: 0.9334
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2055 Acc: 0.9393
val Loss: 0.2367 Acc: 0.9324
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2091 Acc: 0.9378
val Loss: 0.2382 Acc: 0.9322
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2094 Acc: 0.9394
val Loss: 0.2363 Acc: 0.9317
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2080 Acc: 0.9389
val Loss: 0.2355 Acc: 0.9327
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2055 Acc: 0.9399
val Loss: 0.2337 Acc: 0.9332
Epoch finished in 0m 12s
Best validation accuracy: 0.9332204870590805
Model Test Accuracy:  0.9367701290719114
Pruning Epoch 16
++++++++++++++++++
number of weights to prune:  1901.0
Sparsity of Pruned Mask:  tensor(0.9719)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.0809 Acc: 0.2586
val Loss: 1.1737 Acc: 0.6069
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5560 Acc: 0.8271
val Loss: 0.4616 Acc: 0.8634
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3638 Acc: 0.8890
val Loss: 0.3598 Acc: 0.8964
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3195 Acc: 0.9038
val Loss: 0.3514 Acc: 0.8942
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2973 Acc: 0.9107
val Loss: 0.3369 Acc: 0.9044
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2901 Acc: 0.9147
val Loss: 0.3293 Acc: 0.9007
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2801 Acc: 0.9172
val Loss: 0.3101 Acc: 0.9114
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2768 Acc: 0.9182
val Loss: 0.2927 Acc: 0.9142
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2748 Acc: 0.9175
val Loss: 0.2929 Acc: 0.9138
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2710 Acc: 0.9187
val Loss: 0.3396 Acc: 0.9122
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2691 Acc: 0.9204
val Loss: 0.3175 Acc: 0.9066
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2715 Acc: 0.9204
val Loss: 0.2949 Acc: 0.9114
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2688 Acc: 0.9205
val Loss: 0.2797 Acc: 0.9162
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2658 Acc: 0.9204
val Loss: 0.3060 Acc: 0.9124
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2677 Acc: 0.9202
val Loss: 0.2905 Acc: 0.9137
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2653 Acc: 0.9207
val Loss: 0.3152 Acc: 0.9145
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2634 Acc: 0.9208
val Loss: 0.2681 Acc: 0.9222
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2379 Acc: 0.9294
val Loss: 0.2538 Acc: 0.9251
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2323 Acc: 0.9305
val Loss: 0.2469 Acc: 0.9299
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2268 Acc: 0.9329
val Loss: 0.2508 Acc: 0.9289
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2262 Acc: 0.9329
val Loss: 0.2485 Acc: 0.9297
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2255 Acc: 0.9337
val Loss: 0.2446 Acc: 0.9309
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2233 Acc: 0.9332
val Loss: 0.2430 Acc: 0.9300
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2242 Acc: 0.9329
val Loss: 0.2458 Acc: 0.9290
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2253 Acc: 0.9333
val Loss: 0.2480 Acc: 0.9287
Epoch finished in 0m 12s
Best validation accuracy: 0.9286884350769903
Model Test Accuracy:  0.9331591886908419
Pruning Epoch 17
++++++++++++++++++
number of weights to prune:  1520.0
Sparsity of Pruned Mask:  tensor(0.9775)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1212 Acc: 0.2428
val Loss: 1.3066 Acc: 0.5577
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.6112 Acc: 0.8056
val Loss: 0.4426 Acc: 0.8611
Epoch finished in 0m 33s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3795 Acc: 0.8846
val Loss: 0.3810 Acc: 0.8858
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3359 Acc: 0.8994
val Loss: 0.3607 Acc: 0.8954
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3178 Acc: 0.9045
val Loss: 0.3392 Acc: 0.8976
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3028 Acc: 0.9097
val Loss: 0.3269 Acc: 0.9031
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3020 Acc: 0.9102
val Loss: 0.3053 Acc: 0.9100
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2951 Acc: 0.9118
val Loss: 0.3490 Acc: 0.8914
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2923 Acc: 0.9139
val Loss: 0.3190 Acc: 0.9085
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2882 Acc: 0.9139
val Loss: 0.3121 Acc: 0.9089
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2855 Acc: 0.9154
val Loss: 0.3379 Acc: 0.9028
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2857 Acc: 0.9131
val Loss: 0.3033 Acc: 0.9096
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2844 Acc: 0.9150
val Loss: 0.3091 Acc: 0.9102
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2839 Acc: 0.9159
val Loss: 0.3434 Acc: 0.9107
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2780 Acc: 0.9182
val Loss: 0.3134 Acc: 0.9058
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2831 Acc: 0.9150
val Loss: 0.3241 Acc: 0.9031
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2758 Acc: 0.9171
val Loss: 0.2714 Acc: 0.9207
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2486 Acc: 0.9273
val Loss: 0.2625 Acc: 0.9239
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2420 Acc: 0.9287
val Loss: 0.2610 Acc: 0.9234
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2396 Acc: 0.9285
val Loss: 0.2557 Acc: 0.9260
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2376 Acc: 0.9295
val Loss: 0.2563 Acc: 0.9257
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2394 Acc: 0.9296
val Loss: 0.2563 Acc: 0.9263
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2385 Acc: 0.9291
val Loss: 0.2591 Acc: 0.9255
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2386 Acc: 0.9288
val Loss: 0.2560 Acc: 0.9243
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2358 Acc: 0.9297
val Loss: 0.2578 Acc: 0.9252
Epoch finished in 0m 12s
Best validation accuracy: 0.9251938407775473
Model Test Accuracy:  0.9328902888752304
Pruning Epoch 18
++++++++++++++++++
number of weights to prune:  1216.0
Sparsity of Pruned Mask:  tensor(0.9820)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2005 Acc: 0.2107
val Loss: 1.8539 Acc: 0.3498
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.7790 Acc: 0.7468
val Loss: 0.4548 Acc: 0.8584
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4143 Acc: 0.8743
val Loss: 0.3984 Acc: 0.8809
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3611 Acc: 0.8911
val Loss: 0.3567 Acc: 0.8939
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3424 Acc: 0.8973
val Loss: 0.3576 Acc: 0.8912
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3323 Acc: 0.9003
val Loss: 0.3295 Acc: 0.9010
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3271 Acc: 0.9022
val Loss: 0.3480 Acc: 0.8973
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3179 Acc: 0.9043
val Loss: 0.3439 Acc: 0.9019
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3073 Acc: 0.9074
val Loss: 0.3401 Acc: 0.8989
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3092 Acc: 0.9067
val Loss: 0.3485 Acc: 0.8954
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3073 Acc: 0.9086
val Loss: 0.3586 Acc: 0.8988
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3037 Acc: 0.9089
val Loss: 0.3433 Acc: 0.9000
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3035 Acc: 0.9090
val Loss: 0.3331 Acc: 0.9052
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3062 Acc: 0.9070
val Loss: 0.3241 Acc: 0.9040
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3009 Acc: 0.9087
val Loss: 0.3511 Acc: 0.8949
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3016 Acc: 0.9100
val Loss: 0.3425 Acc: 0.9014
Epoch finished in 0m 13s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2998 Acc: 0.9101
val Loss: 0.2847 Acc: 0.9139
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2716 Acc: 0.9179
val Loss: 0.2782 Acc: 0.9184
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2636 Acc: 0.9226
val Loss: 0.2771 Acc: 0.9184
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2587 Acc: 0.9224
val Loss: 0.2672 Acc: 0.9224
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2555 Acc: 0.9236
val Loss: 0.2701 Acc: 0.9211
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2563 Acc: 0.9236
val Loss: 0.2715 Acc: 0.9198
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2571 Acc: 0.9224
val Loss: 0.2690 Acc: 0.9218
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2546 Acc: 0.9232
val Loss: 0.2717 Acc: 0.9214
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2574 Acc: 0.9232
val Loss: 0.2661 Acc: 0.9218
Epoch finished in 0m 12s
Best validation accuracy: 0.9218084525499618
Model Test Accuracy:  0.926859250153657
Pruning Epoch 19
++++++++++++++++++
number of weights to prune:  973.0
Sparsity of Pruned Mask:  tensor(0.9856)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2330 Acc: 0.1901
val Loss: 2.1448 Acc: 0.2523
Epoch finished in 0m 42s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.1065 Acc: 0.6293
val Loss: 0.5566 Acc: 0.8324
Epoch finished in 0m 33s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4774 Acc: 0.8535
val Loss: 0.4422 Acc: 0.8644
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4086 Acc: 0.8770
val Loss: 0.4462 Acc: 0.8625
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3793 Acc: 0.8848
val Loss: 0.4126 Acc: 0.8771
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3718 Acc: 0.8884
val Loss: 0.4104 Acc: 0.8854
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3543 Acc: 0.8917
val Loss: 0.3588 Acc: 0.8916
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3481 Acc: 0.8956
val Loss: 0.3681 Acc: 0.8886
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3432 Acc: 0.8949
val Loss: 0.3896 Acc: 0.8936
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3422 Acc: 0.8976
val Loss: 0.3537 Acc: 0.8937
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3339 Acc: 0.8992
val Loss: 0.3949 Acc: 0.8807
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3272 Acc: 0.9016
val Loss: 0.3472 Acc: 0.8948
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3276 Acc: 0.9010
val Loss: 0.3488 Acc: 0.8983
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3259 Acc: 0.9016
val Loss: 0.3445 Acc: 0.8958
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3297 Acc: 0.9009
val Loss: 0.4224 Acc: 0.8894
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3283 Acc: 0.9014
val Loss: 0.3715 Acc: 0.8920
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3193 Acc: 0.9033
val Loss: 0.3129 Acc: 0.9071
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2961 Acc: 0.9098
val Loss: 0.2971 Acc: 0.9123
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2875 Acc: 0.9137
val Loss: 0.2928 Acc: 0.9147
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2835 Acc: 0.9149
val Loss: 0.2947 Acc: 0.9119
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2772 Acc: 0.9175
val Loss: 0.2876 Acc: 0.9153
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2815 Acc: 0.9156
val Loss: 0.2880 Acc: 0.9151
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2800 Acc: 0.9152
val Loss: 0.2885 Acc: 0.9139
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2806 Acc: 0.9158
val Loss: 0.2906 Acc: 0.9150
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2794 Acc: 0.9162
val Loss: 0.2945 Acc: 0.9122
Epoch finished in 0m 12s
Best validation accuracy: 0.9121983182264934
Model Test Accuracy:  0.9209818684695759
Pruning Epoch 20
++++++++++++++++++
number of weights to prune:  778.0
Sparsity of Pruned Mask:  tensor(0.9885)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2433 Acc: 0.1846
val Loss: 2.1942 Acc: 0.2385
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.4261 Acc: 0.5101
val Loss: 0.7388 Acc: 0.7580
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.5691 Acc: 0.8231
val Loss: 0.5558 Acc: 0.8245
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4712 Acc: 0.8573
val Loss: 0.5345 Acc: 0.8344
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4214 Acc: 0.8723
val Loss: 0.4179 Acc: 0.8710
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3976 Acc: 0.8792
val Loss: 0.4250 Acc: 0.8701
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3850 Acc: 0.8841
val Loss: 0.4265 Acc: 0.8668
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3827 Acc: 0.8840
val Loss: 0.4089 Acc: 0.8803
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3748 Acc: 0.8871
val Loss: 0.4143 Acc: 0.8800
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3671 Acc: 0.8887
val Loss: 0.4282 Acc: 0.8679
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3622 Acc: 0.8901
val Loss: 0.3746 Acc: 0.8901
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3630 Acc: 0.8904
val Loss: 0.3776 Acc: 0.8863
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3564 Acc: 0.8929
val Loss: 0.4630 Acc: 0.8726
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3557 Acc: 0.8918
val Loss: 0.3640 Acc: 0.8875
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3527 Acc: 0.8941
val Loss: 0.4383 Acc: 0.8640
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3520 Acc: 0.8931
val Loss: 0.3658 Acc: 0.8887
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3430 Acc: 0.8964
val Loss: 0.3239 Acc: 0.9020
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3138 Acc: 0.9058
val Loss: 0.3194 Acc: 0.9036
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3082 Acc: 0.9077
val Loss: 0.3189 Acc: 0.9042
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3052 Acc: 0.9078
val Loss: 0.3151 Acc: 0.9061
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3046 Acc: 0.9082
val Loss: 0.3150 Acc: 0.9060
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3024 Acc: 0.9094
val Loss: 0.3062 Acc: 0.9073
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3035 Acc: 0.9089
val Loss: 0.3101 Acc: 0.9086
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3020 Acc: 0.9091
val Loss: 0.3148 Acc: 0.9054
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3020 Acc: 0.9105
val Loss: 0.3144 Acc: 0.9049
Epoch finished in 0m 12s
Best validation accuracy: 0.9048815114120345
Model Test Accuracy:  0.9148740012292562
Pruning Epoch 21
++++++++++++++++++
number of weights to prune:  622.0
Sparsity of Pruned Mask:  tensor(0.9908)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2467 Acc: 0.1796
val Loss: 2.1971 Acc: 0.2220
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.5182 Acc: 0.4777
val Loss: 0.7824 Acc: 0.7446
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.6147 Acc: 0.8056
val Loss: 0.5587 Acc: 0.8261
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5134 Acc: 0.8423
val Loss: 0.5223 Acc: 0.8457
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4665 Acc: 0.8576
val Loss: 0.4879 Acc: 0.8517
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4378 Acc: 0.8652
val Loss: 0.5009 Acc: 0.8425
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4259 Acc: 0.8706
val Loss: 0.4921 Acc: 0.8628
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4086 Acc: 0.8747
val Loss: 0.4371 Acc: 0.8729
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4000 Acc: 0.8785
val Loss: 0.5304 Acc: 0.8519
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3919 Acc: 0.8816
val Loss: 0.4394 Acc: 0.8674
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3937 Acc: 0.8799
val Loss: 0.4053 Acc: 0.8782
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3887 Acc: 0.8823
val Loss: 0.4129 Acc: 0.8752
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3896 Acc: 0.8817
val Loss: 0.4379 Acc: 0.8732
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3857 Acc: 0.8830
val Loss: 0.4190 Acc: 0.8807
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3816 Acc: 0.8847
val Loss: 0.4397 Acc: 0.8638
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3844 Acc: 0.8839
val Loss: 0.3844 Acc: 0.8822
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3780 Acc: 0.8858
val Loss: 0.3682 Acc: 0.8886
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3434 Acc: 0.8951
val Loss: 0.3479 Acc: 0.8958
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3362 Acc: 0.8976
val Loss: 0.3407 Acc: 0.8984
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3299 Acc: 0.8994
val Loss: 0.3364 Acc: 0.8993
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3286 Acc: 0.9012
val Loss: 0.3300 Acc: 0.9007
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3285 Acc: 0.8999
val Loss: 0.3312 Acc: 0.9013
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3282 Acc: 0.9010
val Loss: 0.3320 Acc: 0.8995
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3268 Acc: 0.9012
val Loss: 0.3347 Acc: 0.8978
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3276 Acc: 0.9007
val Loss: 0.3349 Acc: 0.9004
Epoch finished in 0m 12s
Best validation accuracy: 0.9004040624658731
Model Test Accuracy:  0.907037492317148
Pruning Epoch 22
++++++++++++++++++
number of weights to prune:  498.0
Sparsity of Pruned Mask:  tensor(0.9926)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2513 Acc: 0.1819
val Loss: 2.2146 Acc: 0.2162
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.8566 Acc: 0.3454
val Loss: 1.3240 Acc: 0.5592
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.8159 Acc: 0.7369
val Loss: 0.6683 Acc: 0.7855
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.6102 Acc: 0.8084
val Loss: 0.6089 Acc: 0.8123
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5443 Acc: 0.8291
val Loss: 0.5680 Acc: 0.8210
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.5181 Acc: 0.8391
val Loss: 0.5236 Acc: 0.8438
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4982 Acc: 0.8463
val Loss: 0.5300 Acc: 0.8341
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4831 Acc: 0.8512
val Loss: 0.5820 Acc: 0.8162
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4723 Acc: 0.8541
val Loss: 0.5374 Acc: 0.8459
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4569 Acc: 0.8606
val Loss: 0.5145 Acc: 0.8396
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.4508 Acc: 0.8597
val Loss: 0.4612 Acc: 0.8566
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.4440 Acc: 0.8639
val Loss: 0.4919 Acc: 0.8548
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.4443 Acc: 0.8627
val Loss: 0.5108 Acc: 0.8386
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.4404 Acc: 0.8659
val Loss: 0.4886 Acc: 0.8513
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.4383 Acc: 0.8648
val Loss: 0.4584 Acc: 0.8552
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.4327 Acc: 0.8672
val Loss: 0.4604 Acc: 0.8599
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.4282 Acc: 0.8689
val Loss: 0.4061 Acc: 0.8765
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3939 Acc: 0.8794
val Loss: 0.3897 Acc: 0.8811
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3850 Acc: 0.8811
val Loss: 0.3849 Acc: 0.8804
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3809 Acc: 0.8815
val Loss: 0.3838 Acc: 0.8820
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3773 Acc: 0.8845
val Loss: 0.3795 Acc: 0.8836
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3772 Acc: 0.8844
val Loss: 0.3820 Acc: 0.8828
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3770 Acc: 0.8836
val Loss: 0.3829 Acc: 0.8812
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3786 Acc: 0.8844
val Loss: 0.3822 Acc: 0.8845
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3766 Acc: 0.8834
val Loss: 0.3804 Acc: 0.8835
Epoch finished in 0m 12s
Best validation accuracy: 0.8834771213279459
Model Test Accuracy:  0.8873693915181314
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2538 Acc: 0.1676
val Loss: 2.2394 Acc: 0.1826
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.1490 Acc: 0.2293
val Loss: 1.9147 Acc: 0.3238
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 1.3193 Acc: 0.5517
val Loss: 1.7099 Acc: 0.5085
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.6349 Acc: 0.8009
val Loss: 0.5668 Acc: 0.8204
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4627 Acc: 0.8586
val Loss: 0.6300 Acc: 0.8374
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3951 Acc: 0.8792
val Loss: 0.3850 Acc: 0.8834
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3597 Acc: 0.8903
val Loss: 0.3857 Acc: 0.8859
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3296 Acc: 0.8993
val Loss: 0.3544 Acc: 0.8976
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3111 Acc: 0.9058
val Loss: 0.3272 Acc: 0.9021
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2942 Acc: 0.9106
val Loss: 0.3561 Acc: 0.8958
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2744 Acc: 0.9167
val Loss: 0.2994 Acc: 0.9110
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2700 Acc: 0.9196
val Loss: 0.3289 Acc: 0.9119
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2558 Acc: 0.9243
val Loss: 0.3018 Acc: 0.9100
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2506 Acc: 0.9252
val Loss: 0.2974 Acc: 0.9170
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2392 Acc: 0.9276
val Loss: 0.2600 Acc: 0.9227
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2307 Acc: 0.9307
val Loss: 0.2924 Acc: 0.9165
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2259 Acc: 0.9313
val Loss: 0.2423 Acc: 0.9297
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1921 Acc: 0.9439
val Loss: 0.2316 Acc: 0.9351
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1804 Acc: 0.9467
val Loss: 0.2198 Acc: 0.9360
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1759 Acc: 0.9486
val Loss: 0.2180 Acc: 0.9368
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1740 Acc: 0.9496
val Loss: 0.2179 Acc: 0.9373
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1734 Acc: 0.9505
val Loss: 0.2168 Acc: 0.9377
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1725 Acc: 0.9500
val Loss: 0.2170 Acc: 0.9375
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1730 Acc: 0.9496
val Loss: 0.2130 Acc: 0.9391
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1734 Acc: 0.9495
val Loss: 0.2174 Acc: 0.9373
Epoch finished in 0m 39s
Best validation accuracy: 0.9373157147537403
Before Pruning
++++++++++++++++++
Model Test Accuracy:  0.9412645974185617
Pruning Epoch 1
++++++++++++++++++
number of weights to prune:  54052.0
Sparsity of Pruned Mask:  tensor(0.2000)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1226 Acc: 0.2374
val Loss: 1.7511 Acc: 0.4098
Epoch finished in 2m 58s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.0803 Acc: 0.6568
val Loss: 0.6745 Acc: 0.8022
Epoch finished in 2m 23s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4670 Acc: 0.8567
val Loss: 0.4464 Acc: 0.8687
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3759 Acc: 0.8867
val Loss: 0.3756 Acc: 0.8906
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3366 Acc: 0.8994
val Loss: 0.3716 Acc: 0.8839
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3050 Acc: 0.9083
val Loss: 0.4056 Acc: 0.8845
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2901 Acc: 0.9125
val Loss: 0.3274 Acc: 0.9019
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2724 Acc: 0.9190
val Loss: 0.2976 Acc: 0.9126
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2596 Acc: 0.9242
val Loss: 0.3200 Acc: 0.9089
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2494 Acc: 0.9250
val Loss: 0.3074 Acc: 0.9085
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2405 Acc: 0.9282
val Loss: 0.2973 Acc: 0.9190
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2361 Acc: 0.9300
val Loss: 0.2949 Acc: 0.9141
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2287 Acc: 0.9312
val Loss: 0.2933 Acc: 0.9133
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2244 Acc: 0.9336
val Loss: 0.2628 Acc: 0.9248
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2178 Acc: 0.9346
val Loss: 0.2610 Acc: 0.9252
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2139 Acc: 0.9364
val Loss: 0.2587 Acc: 0.9261
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2080 Acc: 0.9376
val Loss: 0.2281 Acc: 0.9323
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1778 Acc: 0.9475
val Loss: 0.2191 Acc: 0.9367
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1663 Acc: 0.9511
val Loss: 0.2103 Acc: 0.9409
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1596 Acc: 0.9537
val Loss: 0.2139 Acc: 0.9380
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1566 Acc: 0.9547
val Loss: 0.2075 Acc: 0.9415
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1582 Acc: 0.9543
val Loss: 0.2109 Acc: 0.9408
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1557 Acc: 0.9549
val Loss: 0.2085 Acc: 0.9410
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1580 Acc: 0.9543
val Loss: 0.2124 Acc: 0.9380
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1584 Acc: 0.9549
val Loss: 0.2083 Acc: 0.9407
Epoch finished in 0m 39s
Best validation accuracy: 0.9407011029813258
Model Test Accuracy:  0.9475261216963736
Pruning Epoch 2
++++++++++++++++++
number of weights to prune:  43241.0
Sparsity of Pruned Mask:  tensor(0.3600)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.0718 Acc: 0.2663
val Loss: 1.4186 Acc: 0.5193
Epoch finished in 2m 58s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.6740 Acc: 0.7956
val Loss: 0.4367 Acc: 0.8629
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3530 Acc: 0.8920
val Loss: 0.4039 Acc: 0.8878
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3005 Acc: 0.9106
val Loss: 0.3432 Acc: 0.9002
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2771 Acc: 0.9171
val Loss: 0.3562 Acc: 0.9090
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2584 Acc: 0.9225
val Loss: 0.2974 Acc: 0.9104
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2470 Acc: 0.9264
val Loss: 0.3037 Acc: 0.9120
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2342 Acc: 0.9304
val Loss: 0.3093 Acc: 0.9105
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2290 Acc: 0.9314
val Loss: 0.2805 Acc: 0.9176
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2246 Acc: 0.9325
val Loss: 0.2908 Acc: 0.9185
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2173 Acc: 0.9356
val Loss: 0.3251 Acc: 0.9097
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2121 Acc: 0.9376
val Loss: 0.2724 Acc: 0.9208
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2095 Acc: 0.9389
val Loss: 0.2558 Acc: 0.9251
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2033 Acc: 0.9396
val Loss: 0.2540 Acc: 0.9263
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2031 Acc: 0.9405
val Loss: 0.2544 Acc: 0.9297
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1971 Acc: 0.9414
val Loss: 0.2595 Acc: 0.9238
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1904 Acc: 0.9443
val Loss: 0.2180 Acc: 0.9386
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1611 Acc: 0.9524
val Loss: 0.2051 Acc: 0.9428
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1507 Acc: 0.9556
val Loss: 0.2056 Acc: 0.9421
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1466 Acc: 0.9566
val Loss: 0.2054 Acc: 0.9427
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1471 Acc: 0.9573
val Loss: 0.2031 Acc: 0.9434
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1464 Acc: 0.9574
val Loss: 0.2024 Acc: 0.9422
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1449 Acc: 0.9579
val Loss: 0.2019 Acc: 0.9428
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1440 Acc: 0.9582
val Loss: 0.2061 Acc: 0.9437
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1441 Acc: 0.9588
val Loss: 0.2030 Acc: 0.9427
Epoch finished in 0m 39s
Best validation accuracy: 0.9427214153106913
Model Test Accuracy:  0.9483328211432083
Pruning Epoch 3
++++++++++++++++++
number of weights to prune:  34593.0
Sparsity of Pruned Mask:  tensor(0.4880)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1705 Acc: 0.2152
val Loss: 1.9775 Acc: 0.2876
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.8188 Acc: 0.7451
val Loss: 0.3963 Acc: 0.8776
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3385 Acc: 0.8973
val Loss: 0.3319 Acc: 0.9005
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2855 Acc: 0.9142
val Loss: 0.3168 Acc: 0.9054
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2589 Acc: 0.9227
val Loss: 0.3425 Acc: 0.9150
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2426 Acc: 0.9274
val Loss: 0.3208 Acc: 0.9186
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2275 Acc: 0.9324
val Loss: 0.2707 Acc: 0.9190
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2188 Acc: 0.9344
val Loss: 0.2684 Acc: 0.9234
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2141 Acc: 0.9363
val Loss: 0.2552 Acc: 0.9269
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2082 Acc: 0.9390
val Loss: 0.2489 Acc: 0.9280
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2027 Acc: 0.9388
val Loss: 0.3207 Acc: 0.9054
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1985 Acc: 0.9409
val Loss: 0.2529 Acc: 0.9260
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1965 Acc: 0.9421
val Loss: 0.2597 Acc: 0.9234
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1921 Acc: 0.9432
val Loss: 0.2315 Acc: 0.9322
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1886 Acc: 0.9439
val Loss: 0.2619 Acc: 0.9303
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1883 Acc: 0.9435
val Loss: 0.2492 Acc: 0.9275
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1858 Acc: 0.9447
val Loss: 0.2234 Acc: 0.9364
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1578 Acc: 0.9527
val Loss: 0.2100 Acc: 0.9394
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1474 Acc: 0.9564
val Loss: 0.2051 Acc: 0.9421
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1441 Acc: 0.9578
val Loss: 0.2013 Acc: 0.9422
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1412 Acc: 0.9582
val Loss: 0.2053 Acc: 0.9412
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1407 Acc: 0.9595
val Loss: 0.1984 Acc: 0.9445
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1404 Acc: 0.9593
val Loss: 0.1996 Acc: 0.9433
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1392 Acc: 0.9600
val Loss: 0.2058 Acc: 0.9425
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1392 Acc: 0.9592
val Loss: 0.1995 Acc: 0.9435
Epoch finished in 0m 39s
Best validation accuracy: 0.9435404608496233
Model Test Accuracy:  0.9478718500307314
Pruning Epoch 4
++++++++++++++++++
number of weights to prune:  27674.0
Sparsity of Pruned Mask:  tensor(0.5904)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.5736 Acc: 0.4992
val Loss: 0.5375 Acc: 0.8621
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3684 Acc: 0.8908
val Loss: 0.3650 Acc: 0.9012
Epoch finished in 2m 23s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2783 Acc: 0.9161
val Loss: 0.3616 Acc: 0.9138
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2486 Acc: 0.9261
val Loss: 0.3336 Acc: 0.9192
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2248 Acc: 0.9341
val Loss: 0.2604 Acc: 0.9230
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2163 Acc: 0.9366
val Loss: 0.2595 Acc: 0.9246
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2057 Acc: 0.9390
val Loss: 0.2438 Acc: 0.9279
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2015 Acc: 0.9398
val Loss: 0.2530 Acc: 0.9274
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1975 Acc: 0.9424
val Loss: 0.2652 Acc: 0.9252
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1949 Acc: 0.9413
val Loss: 0.2645 Acc: 0.9214
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1906 Acc: 0.9430
val Loss: 0.2467 Acc: 0.9307
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1843 Acc: 0.9448
val Loss: 0.2447 Acc: 0.9310
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1882 Acc: 0.9434
val Loss: 0.2411 Acc: 0.9355
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1840 Acc: 0.9453
val Loss: 0.2590 Acc: 0.9265
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1823 Acc: 0.9460
val Loss: 0.2531 Acc: 0.9279
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1808 Acc: 0.9474
val Loss: 0.2529 Acc: 0.9271
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1792 Acc: 0.9474
val Loss: 0.2293 Acc: 0.9343
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1495 Acc: 0.9560
val Loss: 0.2134 Acc: 0.9403
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1406 Acc: 0.9583
val Loss: 0.2048 Acc: 0.9434
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1351 Acc: 0.9609
val Loss: 0.2065 Acc: 0.9429
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1342 Acc: 0.9606
val Loss: 0.2045 Acc: 0.9439
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1318 Acc: 0.9620
val Loss: 0.2030 Acc: 0.9447
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1326 Acc: 0.9614
val Loss: 0.2035 Acc: 0.9436
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1334 Acc: 0.9605
val Loss: 0.2047 Acc: 0.9432
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1333 Acc: 0.9610
val Loss: 0.2058 Acc: 0.9438
Epoch finished in 0m 39s
Best validation accuracy: 0.9437588729933385
Model Test Accuracy:  0.948678549477566
Pruning Epoch 5
++++++++++++++++++
number of weights to prune:  22139.0
Sparsity of Pruned Mask:  tensor(0.6723)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.2157 Acc: 0.6302
val Loss: 0.6488 Acc: 0.8243
Epoch finished in 2m 58s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3243 Acc: 0.9003
val Loss: 0.3591 Acc: 0.8909
Epoch finished in 2m 23s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2618 Acc: 0.9213
val Loss: 0.2875 Acc: 0.9185
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2340 Acc: 0.9310
val Loss: 0.2618 Acc: 0.9260
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2136 Acc: 0.9354
val Loss: 0.2527 Acc: 0.9275
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2041 Acc: 0.9406
val Loss: 0.2901 Acc: 0.9267
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1965 Acc: 0.9417
val Loss: 0.2477 Acc: 0.9298
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1922 Acc: 0.9430
val Loss: 0.2428 Acc: 0.9326
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1846 Acc: 0.9461
val Loss: 0.2464 Acc: 0.9301
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1833 Acc: 0.9449
val Loss: 0.2823 Acc: 0.9276
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1809 Acc: 0.9458
val Loss: 0.2381 Acc: 0.9322
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1804 Acc: 0.9461
val Loss: 0.2267 Acc: 0.9362
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1799 Acc: 0.9469
val Loss: 0.2332 Acc: 0.9357
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1759 Acc: 0.9479
val Loss: 0.2687 Acc: 0.9242
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1765 Acc: 0.9475
val Loss: 0.2414 Acc: 0.9312
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1786 Acc: 0.9462
val Loss: 0.2399 Acc: 0.9321
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1743 Acc: 0.9475
val Loss: 0.2248 Acc: 0.9372
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1540 Acc: 0.9547
val Loss: 0.2088 Acc: 0.9429
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1396 Acc: 0.9589
val Loss: 0.2088 Acc: 0.9426
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1369 Acc: 0.9603
val Loss: 0.2060 Acc: 0.9435
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1349 Acc: 0.9605
val Loss: 0.2054 Acc: 0.9435
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1323 Acc: 0.9614
val Loss: 0.2058 Acc: 0.9439
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1324 Acc: 0.9614
val Loss: 0.2041 Acc: 0.9429
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1359 Acc: 0.9594
val Loss: 0.2046 Acc: 0.9432
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1315 Acc: 0.9618
val Loss: 0.2049 Acc: 0.9428
Epoch finished in 0m 39s
Best validation accuracy: 0.9427760183466201
Model Test Accuracy:  0.9501767055931161
Pruning Epoch 6
++++++++++++++++++
number of weights to prune:  17711.0
Sparsity of Pruned Mask:  tensor(0.7379)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.4590 Acc: 0.5461
val Loss: 0.4477 Acc: 0.8652
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3871 Acc: 0.8954
val Loss: 0.3237 Acc: 0.9013
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2537 Acc: 0.9231
val Loss: 0.2712 Acc: 0.9231
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2278 Acc: 0.9331
val Loss: 0.2677 Acc: 0.9216
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2062 Acc: 0.9379
val Loss: 0.2469 Acc: 0.9284
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1958 Acc: 0.9417
val Loss: 0.2611 Acc: 0.9300
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1938 Acc: 0.9421
val Loss: 0.2620 Acc: 0.9278
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1883 Acc: 0.9445
val Loss: 0.2444 Acc: 0.9310
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1832 Acc: 0.9457
val Loss: 0.2401 Acc: 0.9302
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1839 Acc: 0.9451
val Loss: 0.2485 Acc: 0.9325
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1794 Acc: 0.9466
val Loss: 0.2371 Acc: 0.9322
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1782 Acc: 0.9465
val Loss: 0.2565 Acc: 0.9344
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1788 Acc: 0.9461
val Loss: 0.2874 Acc: 0.9187
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1777 Acc: 0.9467
val Loss: 0.3078 Acc: 0.9228
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1768 Acc: 0.9479
val Loss: 0.2336 Acc: 0.9327
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1744 Acc: 0.9475
val Loss: 0.2714 Acc: 0.9219
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1713 Acc: 0.9479
val Loss: 0.2256 Acc: 0.9368
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1444 Acc: 0.9572
val Loss: 0.2106 Acc: 0.9396
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1376 Acc: 0.9590
val Loss: 0.2098 Acc: 0.9424
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1333 Acc: 0.9609
val Loss: 0.2074 Acc: 0.9432
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1317 Acc: 0.9613
val Loss: 0.2064 Acc: 0.9439
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1306 Acc: 0.9612
val Loss: 0.2056 Acc: 0.9428
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1311 Acc: 0.9616
val Loss: 0.2057 Acc: 0.9426
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1295 Acc: 0.9615
val Loss: 0.2079 Acc: 0.9426
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1299 Acc: 0.9616
val Loss: 0.2051 Acc: 0.9439
Epoch finished in 0m 39s
Best validation accuracy: 0.9439226821011248
Model Test Accuracy:  0.9488706207744314
Pruning Epoch 7
++++++++++++++++++
number of weights to prune:  14168.0
Sparsity of Pruned Mask:  tensor(0.7903)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6990 Acc: 0.4699
val Loss: 0.5616 Acc: 0.8334
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3443 Acc: 0.8970
val Loss: 0.3188 Acc: 0.9037
Epoch finished in 2m 23s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2591 Acc: 0.9236
val Loss: 0.2732 Acc: 0.9217
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2291 Acc: 0.9320
val Loss: 0.3140 Acc: 0.9203
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2132 Acc: 0.9374
val Loss: 0.2485 Acc: 0.9291
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2009 Acc: 0.9410
val Loss: 0.2553 Acc: 0.9255
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1943 Acc: 0.9430
val Loss: 0.2392 Acc: 0.9323
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1850 Acc: 0.9449
val Loss: 0.2325 Acc: 0.9334
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1823 Acc: 0.9453
val Loss: 0.2325 Acc: 0.9322
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1821 Acc: 0.9457
val Loss: 0.2383 Acc: 0.9333
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1798 Acc: 0.9461
val Loss: 0.2453 Acc: 0.9290
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1785 Acc: 0.9466
val Loss: 0.2341 Acc: 0.9328
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1759 Acc: 0.9466
val Loss: 0.2503 Acc: 0.9287
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1783 Acc: 0.9476
val Loss: 0.2640 Acc: 0.9313
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1787 Acc: 0.9464
val Loss: 0.3796 Acc: 0.8906
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1753 Acc: 0.9480
val Loss: 0.2510 Acc: 0.9314
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1726 Acc: 0.9482
val Loss: 0.2244 Acc: 0.9372
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1491 Acc: 0.9550
val Loss: 0.2128 Acc: 0.9415
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1429 Acc: 0.9569
val Loss: 0.2043 Acc: 0.9445
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1342 Acc: 0.9600
val Loss: 0.2051 Acc: 0.9450
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1330 Acc: 0.9613
val Loss: 0.2049 Acc: 0.9440
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1330 Acc: 0.9611
val Loss: 0.2040 Acc: 0.9450
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1345 Acc: 0.9609
val Loss: 0.2034 Acc: 0.9444
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1343 Acc: 0.9601
val Loss: 0.2066 Acc: 0.9448
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1342 Acc: 0.9609
val Loss: 0.2042 Acc: 0.9447
Epoch finished in 0m 39s
Best validation accuracy: 0.944687124604128
Model Test Accuracy:  0.9492163491087892
Pruning Epoch 8
++++++++++++++++++
number of weights to prune:  11335.0
Sparsity of Pruned Mask:  tensor(0.8323)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.4272 Acc: 0.5925
val Loss: 1.0938 Acc: 0.8216
Epoch finished in 2m 58s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3913 Acc: 0.8911
val Loss: 0.3702 Acc: 0.9044
Epoch finished in 2m 23s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2461 Acc: 0.9260
val Loss: 0.2740 Acc: 0.9220
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2179 Acc: 0.9347
val Loss: 0.2652 Acc: 0.9220
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2070 Acc: 0.9388
val Loss: 0.3079 Acc: 0.9218
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1994 Acc: 0.9410
val Loss: 0.2696 Acc: 0.9215
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1911 Acc: 0.9433
val Loss: 0.2821 Acc: 0.9238
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1851 Acc: 0.9449
val Loss: 0.2442 Acc: 0.9313
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1865 Acc: 0.9443
val Loss: 0.2517 Acc: 0.9276
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1828 Acc: 0.9451
val Loss: 0.2427 Acc: 0.9313
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1838 Acc: 0.9458
val Loss: 0.2409 Acc: 0.9319
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1833 Acc: 0.9453
val Loss: 0.2256 Acc: 0.9357
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1834 Acc: 0.9448
val Loss: 0.2903 Acc: 0.9246
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1784 Acc: 0.9459
val Loss: 0.2798 Acc: 0.9251
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1795 Acc: 0.9460
val Loss: 0.2388 Acc: 0.9336
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1816 Acc: 0.9457
val Loss: 0.2692 Acc: 0.9263
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1820 Acc: 0.9462
val Loss: 0.2257 Acc: 0.9370
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1564 Acc: 0.9540
val Loss: 0.2142 Acc: 0.9411
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1452 Acc: 0.9579
val Loss: 0.2103 Acc: 0.9402
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1409 Acc: 0.9580
val Loss: 0.2094 Acc: 0.9426
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1394 Acc: 0.9586
val Loss: 0.2079 Acc: 0.9426
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1385 Acc: 0.9595
val Loss: 0.2078 Acc: 0.9414
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1365 Acc: 0.9601
val Loss: 0.2119 Acc: 0.9409
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1396 Acc: 0.9590
val Loss: 0.2084 Acc: 0.9416
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1385 Acc: 0.9590
val Loss: 0.2092 Acc: 0.9408
Epoch finished in 0m 39s
Best validation accuracy: 0.9408103090531834
Model Test Accuracy:  0.9497925629993853
Pruning Epoch 9
++++++++++++++++++
number of weights to prune:  9067.0
Sparsity of Pruned Mask:  tensor(0.8658)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.4519 Acc: 0.5557
val Loss: 0.4743 Acc: 0.8584
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3291 Acc: 0.9034
val Loss: 0.3066 Acc: 0.9111
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2577 Acc: 0.9237
val Loss: 0.2747 Acc: 0.9225
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2289 Acc: 0.9328
val Loss: 0.3449 Acc: 0.9114
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2092 Acc: 0.9379
val Loss: 0.2436 Acc: 0.9286
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1996 Acc: 0.9411
val Loss: 0.2459 Acc: 0.9285
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1971 Acc: 0.9418
val Loss: 0.2439 Acc: 0.9302
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1939 Acc: 0.9425
val Loss: 0.2416 Acc: 0.9290
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1904 Acc: 0.9438
val Loss: 0.2406 Acc: 0.9303
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1893 Acc: 0.9434
val Loss: 0.2568 Acc: 0.9254
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1880 Acc: 0.9440
val Loss: 0.2455 Acc: 0.9279
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1868 Acc: 0.9447
val Loss: 0.2263 Acc: 0.9352
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1852 Acc: 0.9440
val Loss: 0.2813 Acc: 0.9238
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1862 Acc: 0.9451
val Loss: 0.2646 Acc: 0.9289
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1846 Acc: 0.9447
val Loss: 0.2502 Acc: 0.9271
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1859 Acc: 0.9451
val Loss: 0.2525 Acc: 0.9299
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1832 Acc: 0.9458
val Loss: 0.2225 Acc: 0.9355
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1615 Acc: 0.9523
val Loss: 0.2184 Acc: 0.9398
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1497 Acc: 0.9560
val Loss: 0.2133 Acc: 0.9407
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1467 Acc: 0.9570
val Loss: 0.2067 Acc: 0.9423
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1439 Acc: 0.9576
val Loss: 0.2082 Acc: 0.9412
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1416 Acc: 0.9584
val Loss: 0.2101 Acc: 0.9416
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1444 Acc: 0.9577
val Loss: 0.2068 Acc: 0.9416
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1437 Acc: 0.9578
val Loss: 0.2111 Acc: 0.9412
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1433 Acc: 0.9576
val Loss: 0.2096 Acc: 0.9420
Epoch finished in 0m 39s
Best validation accuracy: 0.9420115758436169
Model Test Accuracy:  0.9487553779963122
Pruning Epoch 10
++++++++++++++++++
number of weights to prune:  7254.0
Sparsity of Pruned Mask:  tensor(0.8926)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6594 Acc: 0.4680
val Loss: 0.5758 Acc: 0.8293
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3499 Acc: 0.8933
val Loss: 0.3366 Acc: 0.8999
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2660 Acc: 0.9206
val Loss: 0.3277 Acc: 0.9212
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2383 Acc: 0.9298
val Loss: 0.2780 Acc: 0.9198
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2194 Acc: 0.9357
val Loss: 0.3087 Acc: 0.9222
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2044 Acc: 0.9380
val Loss: 0.2890 Acc: 0.9199
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2015 Acc: 0.9406
val Loss: 0.2422 Acc: 0.9307
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1962 Acc: 0.9433
val Loss: 0.2652 Acc: 0.9263
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1963 Acc: 0.9418
val Loss: 0.2537 Acc: 0.9266
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1947 Acc: 0.9422
val Loss: 0.2570 Acc: 0.9312
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1935 Acc: 0.9428
val Loss: 0.2428 Acc: 0.9303
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1918 Acc: 0.9435
val Loss: 0.2874 Acc: 0.9289
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1908 Acc: 0.9435
val Loss: 0.2346 Acc: 0.9326
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1912 Acc: 0.9436
val Loss: 0.2431 Acc: 0.9318
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1923 Acc: 0.9429
val Loss: 0.2530 Acc: 0.9285
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1939 Acc: 0.9419
val Loss: 0.2429 Acc: 0.9302
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1904 Acc: 0.9435
val Loss: 0.2253 Acc: 0.9350
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1680 Acc: 0.9523
val Loss: 0.2163 Acc: 0.9387
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1595 Acc: 0.9530
val Loss: 0.2099 Acc: 0.9403
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1550 Acc: 0.9547
val Loss: 0.2097 Acc: 0.9416
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1537 Acc: 0.9553
val Loss: 0.2113 Acc: 0.9399
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1505 Acc: 0.9570
val Loss: 0.2128 Acc: 0.9415
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1527 Acc: 0.9556
val Loss: 0.2114 Acc: 0.9409
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1535 Acc: 0.9556
val Loss: 0.2100 Acc: 0.9418
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1539 Acc: 0.9557
val Loss: 0.2109 Acc: 0.9416
Epoch finished in 0m 39s
Best validation accuracy: 0.9415747515561865
Model Test Accuracy:  0.9490626920712968
Pruning Epoch 11
++++++++++++++++++
number of weights to prune:  5803.0
Sparsity of Pruned Mask:  tensor(0.9141)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.5414 Acc: 0.5103
val Loss: 0.4775 Acc: 0.8539
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3580 Acc: 0.8939
val Loss: 0.3595 Acc: 0.9002
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2703 Acc: 0.9192
val Loss: 0.3629 Acc: 0.9150
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2411 Acc: 0.9289
val Loss: 0.2625 Acc: 0.9245
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2271 Acc: 0.9350
val Loss: 0.2522 Acc: 0.9271
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2170 Acc: 0.9367
val Loss: 0.2701 Acc: 0.9202
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2091 Acc: 0.9392
val Loss: 0.2519 Acc: 0.9285
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2077 Acc: 0.9396
val Loss: 0.2658 Acc: 0.9260
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2064 Acc: 0.9398
val Loss: 0.2518 Acc: 0.9278
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2053 Acc: 0.9394
val Loss: 0.2677 Acc: 0.9236
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2017 Acc: 0.9403
val Loss: 0.2664 Acc: 0.9283
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2029 Acc: 0.9393
val Loss: 0.2539 Acc: 0.9292
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1985 Acc: 0.9419
val Loss: 0.2523 Acc: 0.9277
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2013 Acc: 0.9401
val Loss: 0.2592 Acc: 0.9252
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2025 Acc: 0.9409
val Loss: 0.2720 Acc: 0.9232
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1993 Acc: 0.9414
val Loss: 0.2354 Acc: 0.9316
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2002 Acc: 0.9400
val Loss: 0.2264 Acc: 0.9358
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1750 Acc: 0.9483
val Loss: 0.2158 Acc: 0.9396
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1680 Acc: 0.9504
val Loss: 0.2125 Acc: 0.9399
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1651 Acc: 0.9520
val Loss: 0.2126 Acc: 0.9391
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1632 Acc: 0.9520
val Loss: 0.2138 Acc: 0.9392
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1598 Acc: 0.9530
val Loss: 0.2139 Acc: 0.9390
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1612 Acc: 0.9525
val Loss: 0.2107 Acc: 0.9412
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1609 Acc: 0.9524
val Loss: 0.2132 Acc: 0.9399
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1627 Acc: 0.9519
val Loss: 0.2074 Acc: 0.9411
Epoch finished in 0m 39s
Best validation accuracy: 0.9411379272687561
Model Test Accuracy:  0.9482944068838352
Pruning Epoch 12
++++++++++++++++++
number of weights to prune:  4642.0
Sparsity of Pruned Mask:  tensor(0.9313)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.9482 Acc: 0.3488
val Loss: 1.4459 Acc: 0.5799
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4382 Acc: 0.8757
val Loss: 0.4131 Acc: 0.8912
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2908 Acc: 0.9150
val Loss: 0.2999 Acc: 0.9149
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2522 Acc: 0.9254
val Loss: 0.2601 Acc: 0.9217
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2343 Acc: 0.9308
val Loss: 0.2884 Acc: 0.9228
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2270 Acc: 0.9328
val Loss: 0.2620 Acc: 0.9244
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2195 Acc: 0.9345
val Loss: 0.2800 Acc: 0.9228
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2180 Acc: 0.9364
val Loss: 0.2525 Acc: 0.9275
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2156 Acc: 0.9364
val Loss: 0.2964 Acc: 0.9208
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2139 Acc: 0.9368
val Loss: 0.2815 Acc: 0.9163
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2139 Acc: 0.9374
val Loss: 0.2515 Acc: 0.9271
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2103 Acc: 0.9377
val Loss: 0.2484 Acc: 0.9317
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2121 Acc: 0.9376
val Loss: 0.2453 Acc: 0.9282
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2102 Acc: 0.9367
val Loss: 0.2627 Acc: 0.9231
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2113 Acc: 0.9376
val Loss: 0.2868 Acc: 0.9237
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2127 Acc: 0.9376
val Loss: 0.2583 Acc: 0.9252
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2124 Acc: 0.9377
val Loss: 0.2393 Acc: 0.9314
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1897 Acc: 0.9447
val Loss: 0.2233 Acc: 0.9362
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1800 Acc: 0.9478
val Loss: 0.2228 Acc: 0.9356
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1743 Acc: 0.9487
val Loss: 0.2177 Acc: 0.9383
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1729 Acc: 0.9486
val Loss: 0.2174 Acc: 0.9384
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1722 Acc: 0.9490
val Loss: 0.2154 Acc: 0.9390
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1709 Acc: 0.9506
val Loss: 0.2173 Acc: 0.9366
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1728 Acc: 0.9503
val Loss: 0.2182 Acc: 0.9380
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1702 Acc: 0.9499
val Loss: 0.2168 Acc: 0.9402
Epoch finished in 0m 39s
Best validation accuracy: 0.9402096756579666
Model Test Accuracy:  0.9451444376152427
Pruning Epoch 13
++++++++++++++++++
number of weights to prune:  3713.0
Sparsity of Pruned Mask:  tensor(0.9450)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.9142 Acc: 0.3676
val Loss: 0.7778 Acc: 0.7885
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4447 Acc: 0.8723
val Loss: 0.3330 Acc: 0.9007
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2892 Acc: 0.9143
val Loss: 0.3330 Acc: 0.9117
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2558 Acc: 0.9246
val Loss: 0.2832 Acc: 0.9160
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2495 Acc: 0.9265
val Loss: 0.3022 Acc: 0.9192
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2336 Acc: 0.9305
val Loss: 0.3025 Acc: 0.9174
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2306 Acc: 0.9315
val Loss: 0.2635 Acc: 0.9264
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2259 Acc: 0.9338
val Loss: 0.3163 Acc: 0.9172
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2255 Acc: 0.9320
val Loss: 0.2590 Acc: 0.9231
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2264 Acc: 0.9323
val Loss: 0.2646 Acc: 0.9216
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2235 Acc: 0.9335
val Loss: 0.2758 Acc: 0.9217
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2205 Acc: 0.9337
val Loss: 0.2702 Acc: 0.9222
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2244 Acc: 0.9336
val Loss: 0.2749 Acc: 0.9204
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2226 Acc: 0.9338
val Loss: 0.2588 Acc: 0.9297
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2204 Acc: 0.9353
val Loss: 0.2758 Acc: 0.9183
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2208 Acc: 0.9338
val Loss: 0.2637 Acc: 0.9226
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2203 Acc: 0.9343
val Loss: 0.2449 Acc: 0.9315
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1945 Acc: 0.9426
val Loss: 0.2309 Acc: 0.9346
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1874 Acc: 0.9448
val Loss: 0.2235 Acc: 0.9358
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1820 Acc: 0.9460
val Loss: 0.2200 Acc: 0.9374
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1836 Acc: 0.9460
val Loss: 0.2240 Acc: 0.9357
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1831 Acc: 0.9471
val Loss: 0.2262 Acc: 0.9361
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1799 Acc: 0.9472
val Loss: 0.2239 Acc: 0.9361
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1792 Acc: 0.9475
val Loss: 0.2215 Acc: 0.9370
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1853 Acc: 0.9450
val Loss: 0.2207 Acc: 0.9368
Epoch finished in 0m 39s
Best validation accuracy: 0.9368242874303812
Model Test Accuracy:  0.9437231100184388
Pruning Epoch 14
++++++++++++++++++
number of weights to prune:  2971.0
Sparsity of Pruned Mask:  tensor(0.9560)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.9707 Acc: 0.3320
val Loss: 2.0807 Acc: 0.2885
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.6229 Acc: 0.8158
val Loss: 0.3497 Acc: 0.8940
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3089 Acc: 0.9085
val Loss: 0.3717 Acc: 0.9070
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2723 Acc: 0.9183
val Loss: 0.3270 Acc: 0.9090
Epoch finished in 0m 38s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2639 Acc: 0.9238
val Loss: 0.3223 Acc: 0.9079
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2551 Acc: 0.9253
val Loss: 0.3171 Acc: 0.9099
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2484 Acc: 0.9272
val Loss: 0.2697 Acc: 0.9214
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2435 Acc: 0.9267
val Loss: 0.2906 Acc: 0.9173
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2438 Acc: 0.9277
val Loss: 0.2904 Acc: 0.9136
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2421 Acc: 0.9294
val Loss: 0.2910 Acc: 0.9156
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2383 Acc: 0.9294
val Loss: 0.2689 Acc: 0.9210
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2397 Acc: 0.9289
val Loss: 0.2899 Acc: 0.9173
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2367 Acc: 0.9305
val Loss: 0.2572 Acc: 0.9254
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2333 Acc: 0.9309
val Loss: 0.2971 Acc: 0.9115
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2360 Acc: 0.9310
val Loss: 0.2939 Acc: 0.9226
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2329 Acc: 0.9311
val Loss: 0.2832 Acc: 0.9219
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2323 Acc: 0.9327
val Loss: 0.2413 Acc: 0.9309
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2109 Acc: 0.9377
val Loss: 0.2341 Acc: 0.9345
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2006 Acc: 0.9412
val Loss: 0.2269 Acc: 0.9352
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2003 Acc: 0.9409
val Loss: 0.2260 Acc: 0.9349
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1977 Acc: 0.9420
val Loss: 0.2249 Acc: 0.9368
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1950 Acc: 0.9426
val Loss: 0.2264 Acc: 0.9380
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1952 Acc: 0.9434
val Loss: 0.2277 Acc: 0.9364
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1940 Acc: 0.9432
val Loss: 0.2279 Acc: 0.9353
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1949 Acc: 0.9434
val Loss: 0.2281 Acc: 0.9349
Epoch finished in 0m 39s
Best validation accuracy: 0.9348585781369444
Model Test Accuracy:  0.9414950829748001
Pruning Epoch 15
++++++++++++++++++
number of weights to prune:  2376.0
Sparsity of Pruned Mask:  tensor(0.9648)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1235 Acc: 0.2575
val Loss: 1.8783 Acc: 0.3187
Epoch finished in 2m 58s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.8808 Acc: 0.3491
val Loss: 1.2282 Acc: 0.6598
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.5082 Acc: 0.8479
val Loss: 0.3643 Acc: 0.8893
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3229 Acc: 0.9033
val Loss: 0.4716 Acc: 0.8918
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2921 Acc: 0.9126
val Loss: 0.3151 Acc: 0.9135
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2724 Acc: 0.9188
val Loss: 0.3887 Acc: 0.9111
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2660 Acc: 0.9208
val Loss: 0.2806 Acc: 0.9183
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2594 Acc: 0.9234
val Loss: 0.3210 Acc: 0.9104
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2577 Acc: 0.9241
val Loss: 0.2860 Acc: 0.9141
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2554 Acc: 0.9249
val Loss: 0.2738 Acc: 0.9208
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2535 Acc: 0.9248
val Loss: 0.3392 Acc: 0.9085
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2529 Acc: 0.9247
val Loss: 0.3007 Acc: 0.9113
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2522 Acc: 0.9255
val Loss: 0.3177 Acc: 0.9089
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2490 Acc: 0.9260
val Loss: 0.2839 Acc: 0.9151
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2460 Acc: 0.9267
val Loss: 0.3107 Acc: 0.9112
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2475 Acc: 0.9262
val Loss: 0.2850 Acc: 0.9199
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2441 Acc: 0.9280
val Loss: 0.2556 Acc: 0.9275
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2231 Acc: 0.9354
val Loss: 0.2414 Acc: 0.9304
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2136 Acc: 0.9369
val Loss: 0.2392 Acc: 0.9320
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2140 Acc: 0.9368
val Loss: 0.2373 Acc: 0.9327
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2094 Acc: 0.9384
val Loss: 0.2380 Acc: 0.9316
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2094 Acc: 0.9374
val Loss: 0.2343 Acc: 0.9331
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2104 Acc: 0.9377
val Loss: 0.2371 Acc: 0.9323
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2079 Acc: 0.9391
val Loss: 0.2370 Acc: 0.9328
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2083 Acc: 0.9392
val Loss: 0.2342 Acc: 0.9335
Epoch finished in 0m 39s
Best validation accuracy: 0.9334935022387245
Model Test Accuracy:  0.9386140135218192
Pruning Epoch 16
++++++++++++++++++
number of weights to prune:  1901.0
Sparsity of Pruned Mask:  tensor(0.9719)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.0643 Acc: 0.2813
val Loss: 1.6179 Acc: 0.4862
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5958 Acc: 0.8237
val Loss: 0.3917 Acc: 0.8811
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3474 Acc: 0.8963
val Loss: 0.3373 Acc: 0.8976
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3099 Acc: 0.9083
val Loss: 0.3114 Acc: 0.9079
Epoch finished in 0m 38s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2941 Acc: 0.9129
val Loss: 0.3135 Acc: 0.9113
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2884 Acc: 0.9155
val Loss: 0.3002 Acc: 0.9123
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2796 Acc: 0.9166
val Loss: 0.3214 Acc: 0.9044
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2734 Acc: 0.9194
val Loss: 0.3729 Acc: 0.9086
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2714 Acc: 0.9204
val Loss: 0.2871 Acc: 0.9168
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2691 Acc: 0.9201
val Loss: 0.3316 Acc: 0.9130
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2681 Acc: 0.9198
val Loss: 0.3227 Acc: 0.9103
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2640 Acc: 0.9219
val Loss: 0.3267 Acc: 0.9123
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2631 Acc: 0.9218
val Loss: 0.2814 Acc: 0.9169
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2637 Acc: 0.9217
val Loss: 0.2988 Acc: 0.9151
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2617 Acc: 0.9228
val Loss: 0.2923 Acc: 0.9143
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2609 Acc: 0.9222
val Loss: 0.3040 Acc: 0.9151
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2596 Acc: 0.9215
val Loss: 0.2658 Acc: 0.9239
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2367 Acc: 0.9299
val Loss: 0.2535 Acc: 0.9253
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2270 Acc: 0.9337
val Loss: 0.2501 Acc: 0.9257
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2255 Acc: 0.9338
val Loss: 0.2488 Acc: 0.9262
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2245 Acc: 0.9349
val Loss: 0.2418 Acc: 0.9289
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2215 Acc: 0.9348
val Loss: 0.2425 Acc: 0.9289
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2208 Acc: 0.9347
val Loss: 0.2451 Acc: 0.9291
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2199 Acc: 0.9359
val Loss: 0.2431 Acc: 0.9283
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2209 Acc: 0.9357
val Loss: 0.2404 Acc: 0.9306
Epoch finished in 0m 38s
Best validation accuracy: 0.9305995413344982
Model Test Accuracy:  0.935118315918869
Pruning Epoch 17
++++++++++++++++++
number of weights to prune:  1520.0
Sparsity of Pruned Mask:  tensor(0.9775)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2531 Acc: 0.1758
val Loss: 2.2338 Acc: 0.1874
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.1634 Acc: 0.2258
val Loss: 1.9624 Acc: 0.3011
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 1.7131 Acc: 0.4042
val Loss: 1.3392 Acc: 0.5406
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.8815 Acc: 0.7139
val Loss: 0.6341 Acc: 0.8040
Epoch finished in 0m 38s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5503 Acc: 0.8289
val Loss: 0.5479 Acc: 0.8344
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4753 Acc: 0.8531
val Loss: 0.4719 Acc: 0.8588
Epoch finished in 0m 38s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4365 Acc: 0.8650
val Loss: 0.4466 Acc: 0.8603
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4110 Acc: 0.8742
val Loss: 0.4188 Acc: 0.8726
Epoch finished in 0m 38s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3971 Acc: 0.8784
val Loss: 0.3942 Acc: 0.8815
Epoch finished in 0m 38s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3910 Acc: 0.8796
val Loss: 0.4229 Acc: 0.8721
Epoch finished in 0m 38s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3770 Acc: 0.8842
val Loss: 0.3791 Acc: 0.8833
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3758 Acc: 0.8855
val Loss: 0.4051 Acc: 0.8761
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3638 Acc: 0.8889
val Loss: 0.3888 Acc: 0.8819
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3598 Acc: 0.8897
val Loss: 0.4039 Acc: 0.8789
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3536 Acc: 0.8920
val Loss: 0.3796 Acc: 0.8933
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3512 Acc: 0.8923
val Loss: 0.3958 Acc: 0.8896
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3424 Acc: 0.8958
val Loss: 0.3173 Acc: 0.9047
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3108 Acc: 0.9058
val Loss: 0.3047 Acc: 0.9084
Epoch finished in 0m 38s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3008 Acc: 0.9087
val Loss: 0.3003 Acc: 0.9097
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2986 Acc: 0.9100
val Loss: 0.3005 Acc: 0.9122
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2955 Acc: 0.9110
val Loss: 0.2942 Acc: 0.9125
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2950 Acc: 0.9113
val Loss: 0.2988 Acc: 0.9109
Epoch finished in 0m 38s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2957 Acc: 0.9116
val Loss: 0.3009 Acc: 0.9083
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2926 Acc: 0.9111
val Loss: 0.2995 Acc: 0.9111
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2955 Acc: 0.9115
val Loss: 0.3022 Acc: 0.9106
Epoch finished in 0m 38s
Best validation accuracy: 0.9106148301845582
Model Test Accuracy:  0.9178318992009833
Pruning Epoch 18
++++++++++++++++++
number of weights to prune:  1216.0
Sparsity of Pruned Mask:  tensor(0.9820)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2153 Acc: 0.2000
val Loss: 2.0749 Acc: 0.2786
Epoch finished in 2m 58s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.8847 Acc: 0.3487
val Loss: 1.9982 Acc: 0.3139
Epoch finished in 2m 23s
Training Epoch 2/24
********************
Warmup
train Loss: 0.9833 Acc: 0.6798
val Loss: 0.6789 Acc: 0.7974
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5295 Acc: 0.8364
val Loss: 0.6461 Acc: 0.8145
Epoch finished in 0m 38s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4639 Acc: 0.8565
val Loss: 0.4544 Acc: 0.8614
Epoch finished in 0m 38s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4290 Acc: 0.8684
val Loss: 0.4896 Acc: 0.8617
Epoch finished in 0m 38s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4127 Acc: 0.8736
val Loss: 0.5256 Acc: 0.8654
Epoch finished in 0m 38s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3969 Acc: 0.8793
val Loss: 0.4562 Acc: 0.8779
Epoch finished in 0m 38s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3886 Acc: 0.8816
val Loss: 0.5726 Acc: 0.8702
Epoch finished in 0m 38s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3796 Acc: 0.8838
val Loss: 0.4046 Acc: 0.8831
Epoch finished in 0m 38s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3732 Acc: 0.8846
val Loss: 0.3712 Acc: 0.8895
Epoch finished in 0m 38s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3653 Acc: 0.8888
val Loss: 0.3720 Acc: 0.8868
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3600 Acc: 0.8906
val Loss: 0.4233 Acc: 0.8909
Epoch finished in 0m 38s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3577 Acc: 0.8918
val Loss: 0.4929 Acc: 0.8746
Epoch finished in 0m 38s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3544 Acc: 0.8918
val Loss: 0.3976 Acc: 0.8821
Epoch finished in 0m 38s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3520 Acc: 0.8931
val Loss: 0.3428 Acc: 0.8965
Epoch finished in 0m 38s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3454 Acc: 0.8946
val Loss: 0.3324 Acc: 0.9005
Epoch finished in 0m 38s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3203 Acc: 0.9023
val Loss: 0.3174 Acc: 0.9034
Epoch finished in 0m 38s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3091 Acc: 0.9066
val Loss: 0.3155 Acc: 0.9072
Epoch finished in 0m 38s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3040 Acc: 0.9074
val Loss: 0.3093 Acc: 0.9083
Epoch finished in 0m 38s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3032 Acc: 0.9095
val Loss: 0.3115 Acc: 0.9078
Epoch finished in 0m 38s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3037 Acc: 0.9084
val Loss: 0.3089 Acc: 0.9061
Epoch finished in 0m 38s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3020 Acc: 0.9081
val Loss: 0.3108 Acc: 0.9076
Epoch finished in 0m 38s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3007 Acc: 0.9093
val Loss: 0.3101 Acc: 0.9092
Epoch finished in 0m 38s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3034 Acc: 0.9093
val Loss: 0.3095 Acc: 0.9085
Epoch finished in 0m 38s
Best validation accuracy: 0.908539914819264
Model Test Accuracy:  0.911877688998156
Pruning Epoch 19
++++++++++++++++++
number of weights to prune:  973.0
Sparsity of Pruned Mask:  tensor(0.9856)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2494 Acc: 0.1708
val Loss: 2.2177 Acc: 0.2048
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.0060 Acc: 0.2949
val Loss: 1.5995 Acc: 0.4670
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 1.1678 Acc: 0.6199
val Loss: 0.6920 Acc: 0.8075
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5020 Acc: 0.8461
val Loss: 0.4945 Acc: 0.8494
Epoch finished in 0m 38s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4410 Acc: 0.8649
val Loss: 0.4139 Acc: 0.8733
Epoch finished in 0m 38s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4118 Acc: 0.8735
val Loss: 0.4778 Acc: 0.8750
Epoch finished in 0m 38s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3969 Acc: 0.8802
val Loss: 0.4104 Acc: 0.8738
Epoch finished in 0m 38s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3864 Acc: 0.8830
val Loss: 0.4191 Acc: 0.8809
Epoch finished in 0m 38s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3738 Acc: 0.8867
val Loss: 0.3909 Acc: 0.8851
Epoch finished in 0m 38s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3687 Acc: 0.8881
val Loss: 0.3834 Acc: 0.8854
Epoch finished in 0m 38s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3683 Acc: 0.8875
val Loss: 0.3913 Acc: 0.8822
Epoch finished in 0m 38s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3673 Acc: 0.8883
val Loss: 0.3709 Acc: 0.8904
Epoch finished in 0m 38s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3598 Acc: 0.8919
val Loss: 0.3958 Acc: 0.8937
Epoch finished in 0m 38s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3560 Acc: 0.8927
val Loss: 0.3588 Acc: 0.8895
Epoch finished in 0m 38s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3560 Acc: 0.8923
val Loss: 0.3756 Acc: 0.8881
Epoch finished in 0m 38s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3531 Acc: 0.8931
val Loss: 0.3691 Acc: 0.8896
Epoch finished in 0m 38s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3453 Acc: 0.8953
val Loss: 0.3341 Acc: 0.9012
Epoch finished in 0m 38s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3210 Acc: 0.9031
val Loss: 0.3173 Acc: 0.9041
Epoch finished in 0m 38s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3097 Acc: 0.9062
val Loss: 0.3150 Acc: 0.9063
Epoch finished in 0m 38s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3083 Acc: 0.9069
val Loss: 0.3160 Acc: 0.9046
Epoch finished in 0m 38s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3032 Acc: 0.9081
val Loss: 0.3133 Acc: 0.9068
Epoch finished in 0m 38s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3053 Acc: 0.9078
val Loss: 0.3110 Acc: 0.9068
Epoch finished in 0m 38s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3056 Acc: 0.9077
val Loss: 0.3144 Acc: 0.9043
Epoch finished in 0m 38s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3061 Acc: 0.9084
val Loss: 0.3134 Acc: 0.9065
Epoch finished in 0m 38s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3042 Acc: 0.9082
val Loss: 0.3127 Acc: 0.9073
Epoch finished in 0m 38s
Best validation accuracy: 0.9072840449929016
Model Test Accuracy:  0.9111478180700675
Pruning Epoch 20
++++++++++++++++++
number of weights to prune:  778.0
Sparsity of Pruned Mask:  tensor(0.9885)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1774 Acc: 0.2085
val Loss: 2.0667 Acc: 0.2854
Epoch finished in 2m 58s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.8142 Acc: 0.3701
val Loss: 1.8478 Acc: 0.4948
Epoch finished in 2m 23s
Training Epoch 2/24
********************
Warmup
train Loss: 0.9245 Acc: 0.7052
val Loss: 0.6437 Acc: 0.7916
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5480 Acc: 0.8292
val Loss: 0.5628 Acc: 0.8240
Epoch finished in 0m 38s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4767 Acc: 0.8518
val Loss: 0.5663 Acc: 0.8552
Epoch finished in 0m 38s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4387 Acc: 0.8661
val Loss: 0.4731 Acc: 0.8569
Epoch finished in 0m 38s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4163 Acc: 0.8723
val Loss: 0.4327 Acc: 0.8647
Epoch finished in 0m 38s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4069 Acc: 0.8768
val Loss: 0.4414 Acc: 0.8728
Epoch finished in 0m 38s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3987 Acc: 0.8774
val Loss: 0.4266 Acc: 0.8715
Epoch finished in 0m 38s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3897 Acc: 0.8810
val Loss: 0.4760 Acc: 0.8773
Epoch finished in 0m 38s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3840 Acc: 0.8828
val Loss: 0.5243 Acc: 0.8798
Epoch finished in 0m 38s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3776 Acc: 0.8851
val Loss: 0.4267 Acc: 0.8794
Epoch finished in 0m 38s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3788 Acc: 0.8841
val Loss: 0.4479 Acc: 0.8861
Epoch finished in 0m 38s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3752 Acc: 0.8870
val Loss: 0.3791 Acc: 0.8854
Epoch finished in 0m 38s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3698 Acc: 0.8865
val Loss: 0.3910 Acc: 0.8821
Epoch finished in 0m 38s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3691 Acc: 0.8868
val Loss: 0.4567 Acc: 0.8654
Epoch finished in 0m 38s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3674 Acc: 0.8876
val Loss: 0.3509 Acc: 0.8946
Epoch finished in 0m 38s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3368 Acc: 0.8974
val Loss: 0.3331 Acc: 0.9007
Epoch finished in 0m 38s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3321 Acc: 0.8988
val Loss: 0.3328 Acc: 0.8982
Epoch finished in 0m 38s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3238 Acc: 0.9013
val Loss: 0.3291 Acc: 0.9020
Epoch finished in 0m 38s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3233 Acc: 0.9019
val Loss: 0.3306 Acc: 0.9002
Epoch finished in 0m 38s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3213 Acc: 0.9014
val Loss: 0.3251 Acc: 0.9022
Epoch finished in 0m 38s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3238 Acc: 0.9011
val Loss: 0.3284 Acc: 0.9012
Epoch finished in 0m 38s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3252 Acc: 0.9004
val Loss: 0.3284 Acc: 0.9002
Epoch finished in 0m 38s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3216 Acc: 0.9025
val Loss: 0.3282 Acc: 0.9010
Epoch finished in 0m 38s
Best validation accuracy: 0.9010046958610899
Model Test Accuracy:  0.9046173939766441
Pruning Epoch 21
++++++++++++++++++
number of weights to prune:  622.0
Sparsity of Pruned Mask:  tensor(0.9908)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2499 Acc: 0.1700
val Loss: 2.2010 Acc: 0.2058
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.1043 Acc: 0.2670
val Loss: 2.0080 Acc: 0.2868
Epoch finished in 2m 23s
Training Epoch 2/24
********************
Warmup
train Loss: 1.6104 Acc: 0.4389
val Loss: 1.0549 Acc: 0.6501
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.8911 Acc: 0.7199
val Loss: 0.6850 Acc: 0.7921
Epoch finished in 0m 38s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5709 Acc: 0.8223
val Loss: 0.7305 Acc: 0.8074
Epoch finished in 0m 38s
Training Epoch 5/24
********************
Warmup
train Loss: 0.5155 Acc: 0.8417
val Loss: 0.5529 Acc: 0.8309
Epoch finished in 0m 38s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4847 Acc: 0.8507
val Loss: 0.4838 Acc: 0.8502
Epoch finished in 0m 38s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4693 Acc: 0.8567
val Loss: 0.4726 Acc: 0.8530
Epoch finished in 0m 38s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4506 Acc: 0.8615
val Loss: 0.4903 Acc: 0.8503
Epoch finished in 0m 38s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4480 Acc: 0.8625
val Loss: 0.4916 Acc: 0.8451
Epoch finished in 0m 38s
Training Epoch 10/24
********************
Warmup
train Loss: 0.4405 Acc: 0.8646
val Loss: 0.4545 Acc: 0.8586
Epoch finished in 0m 38s
Training Epoch 11/24
********************
Warmup
train Loss: 0.4291 Acc: 0.8684
val Loss: 0.7090 Acc: 0.8224
Epoch finished in 0m 38s
Training Epoch 12/24
********************
Warmup
train Loss: 0.4216 Acc: 0.8690
val Loss: 0.4674 Acc: 0.8524
Epoch finished in 0m 38s
Training Epoch 13/24
********************
Warmup
train Loss: 0.4182 Acc: 0.8703
val Loss: 0.4799 Acc: 0.8612
Epoch finished in 0m 38s
Training Epoch 14/24
********************
Warmup
train Loss: 0.4176 Acc: 0.8724
val Loss: 0.4230 Acc: 0.8695
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.4156 Acc: 0.8727
val Loss: 0.4578 Acc: 0.8586
Epoch finished in 0m 38s
Training Epoch 16/24
********************
Warmup
train Loss: 0.4063 Acc: 0.8741
val Loss: 0.3873 Acc: 0.8801
Epoch finished in 0m 38s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3697 Acc: 0.8861
val Loss: 0.3672 Acc: 0.8855
Epoch finished in 0m 38s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3626 Acc: 0.8880
val Loss: 0.3638 Acc: 0.8864
Epoch finished in 0m 38s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3598 Acc: 0.8892
val Loss: 0.3621 Acc: 0.8859
Epoch finished in 0m 38s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3591 Acc: 0.8893
val Loss: 0.3636 Acc: 0.8862
Epoch finished in 0m 38s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3579 Acc: 0.8905
val Loss: 0.3582 Acc: 0.8900
Epoch finished in 0m 38s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3578 Acc: 0.8898
val Loss: 0.3564 Acc: 0.8908
Epoch finished in 0m 38s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3593 Acc: 0.8897
val Loss: 0.3606 Acc: 0.8887
Epoch finished in 0m 38s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3546 Acc: 0.8907
val Loss: 0.3592 Acc: 0.8900
Epoch finished in 0m 38s
Best validation accuracy: 0.8899748826034728
Model Test Accuracy:  0.8936309157959433
conv_layer_1.weight
x:  16
y:  3
layer1.0.conv_layer_1.weight
x:  16
y:  16
layer1.0.conv_layer_2.weight
x:  16
y:  16
layer1.1.conv_layer_1.weight
x:  16
y:  16
layer1.1.conv_layer_2.weight
x:  16
y:  16
layer1.2.conv_layer_1.weight
x:  16
y:  16
layer1.2.conv_layer_2.weight
x:  16
y:  16
layer2.0.conv_layer_1.weight
x:  32
y:  16
layer2.0.conv_layer_2.weight
x:  32
y:  32
layer2.0.shortcut.0.weight
x:  32
y:  16
layer2.1.conv_layer_1.weight
x:  32
y:  32
layer2.1.conv_layer_2.weight
x:  32
y:  32
layer2.2.conv_layer_1.weight
x:  32
y:  32
layer2.2.conv_layer_2.weight
x:  32
y:  32
layer3.0.conv_layer_1.weight
x:  64
y:  32
layer3.0.conv_layer_2.weight
x:  64
y:  64
layer3.0.shortcut.0.weight
x:  64
y:  32
layer3.1.conv_layer_1.weight
x:  64
y:  64
layer3.1.conv_layer_2.weight
x:  64
y:  64
layer3.2.conv_layer_1.weight
x:  64
y:  64
layer3.2.conv_layer_2.weight
x:  64
y:  64
conv_layer_1.weight
33.25581395348837
x:  15
y:  3
layer1.0.conv_layer_1.weight
8.079930495221546
x:  16
y:  16
layer1.0.conv_layer_2.weight
6.6463944396177235
x:  16
y:  16
layer1.1.conv_layer_1.weight
7.688966116420504
x:  16
y:  16
layer1.1.conv_layer_2.weight
7.080799304952215
x:  16
y:  16
layer1.2.conv_layer_1.weight
7.602085143353605
x:  16
y:  16
layer1.2.conv_layer_2.weight
6.038227628149436
x:  16
y:  16
layer2.0.conv_layer_1.weight
3.126356925749023
x:  30
y:  16
layer2.0.conv_layer_2.weight
2.2031690905144345
x:  32
y:  31
layer2.0.shortcut.0.weight
33.72549019607843
x:  32
y:  16
layer2.1.conv_layer_1.weight
2.3334056869980464
x:  32
y:  32
layer2.1.conv_layer_2.weight
2.2140221402214024
x:  31
y:  32
layer2.2.conv_layer_1.weight
1.7147818537008899
x:  31
y:  31
layer2.2.conv_layer_2.weight
1.584545257217278
x:  30
y:  30
layer3.0.conv_layer_1.weight
0.4991861096039067
x:  36
y:  29
layer3.0.conv_layer_2.weight
0.31468721176279096
x:  47
y:  44
layer3.0.shortcut.0.weight
12.072336265884653
x:  63
y:  32
layer3.1.conv_layer_1.weight
0.32825131571808364
x:  35
y:  51
layer3.1.conv_layer_2.weight
0.16276924746351257
x:  20
y:  32
layer3.2.conv_layer_1.weight
0.12207693559763443
x:  21
y:  32
layer3.2.conv_layer_2.weight
0.021702566328468342
x:  7
y:  6
conv_layer_1.weight
19.53488372093023
x:  16
y:  3
layer1.0.conv_layer_1.weight
7.167680278019114
x:  16
y:  16
layer1.0.conv_layer_2.weight
4.5178105994787146
x:  16
y:  16
layer1.1.conv_layer_1.weight
4.039965247610773
x:  16
y:  16
layer1.1.conv_layer_2.weight
4.170286707211121
x:  16
y:  16
layer1.2.conv_layer_1.weight
4.995655951346655
x:  16
y:  16
layer1.2.conv_layer_2.weight
3.649000868809731
x:  16
y:  16
layer2.0.conv_layer_1.weight
0.7815892314372558
x:  17
y:  16
layer2.0.conv_layer_2.weight
0.6294768830041242
x:  27
y:  24
layer2.0.shortcut.0.weight
21.96078431372549
x:  32
y:  16
layer2.1.conv_layer_1.weight
1.1070110701107012
x:  28
y:  30
layer2.1.conv_layer_2.weight
1.1070110701107012
x:  29
y:  28
layer2.2.conv_layer_1.weight
1.1395702192316042
x:  29
y:  29
layer2.2.conv_layer_2.weight
1.0635988712828304
x:  29
y:  30
layer3.0.conv_layer_1.weight
0.2333152468800868
x:  22
y:  25
layer3.0.conv_layer_2.weight
0.09223590689599045
x:  18
y:  24
layer3.0.shortcut.0.weight
8.895405669599217
x:  63
y:  32
layer3.1.conv_layer_1.weight
0.35266670283761054
x:  45
y:  57
layer3.1.conv_layer_2.weight
0.3716564483750203
x:  41
y:  49
layer3.2.conv_layer_1.weight
0.1139384732244588
x:  18
y:  28
layer3.2.conv_layer_2.weight
0.062394878194346484
x:  14
y:  17
conv_layer_1.weight
20.697674418604652
x:  16
y:  3
layer1.0.conv_layer_1.weight
12.250217202432667
x:  16
y:  16
layer1.0.conv_layer_2.weight
7.602085143353605
x:  16
y:  16
layer1.1.conv_layer_1.weight
6.472632493483927
x:  16
y:  16
layer1.1.conv_layer_2.weight
5.125977410947002
x:  16
y:  16
layer1.2.conv_layer_1.weight
4.083405734144223
x:  16
y:  16
layer1.2.conv_layer_2.weight
4.21372719374457
x:  16
y:  16
layer2.0.conv_layer_1.weight
1.6934433347807207
x:  31
y:  15
layer2.0.conv_layer_2.weight
1.041892771868895
x:  32
y:  31
layer2.0.shortcut.0.weight
28.03921568627451
x:  32
y:  16
layer2.1.conv_layer_1.weight
1.0527458215758627
x:  29
y:  30
layer2.1.conv_layer_2.weight
1.1178641198176689
x:  30
y:  29
layer2.2.conv_layer_1.weight
1.3891903624918602
x:  31
y:  32
layer2.2.conv_layer_2.weight
1.3566312133709573
x:  32
y:  31
layer3.0.conv_layer_1.weight
0.3364080303852415
x:  30
y:  26
layer3.0.conv_layer_2.weight
0.1844718137919809
x:  32
y:  39
layer3.0.shortcut.0.weight
11.925708699902248
x:  64
y:  32
layer3.1.conv_layer_1.weight
0.40421029786772283
x:  47
y:  56
layer3.1.conv_layer_2.weight
0.2875590038522055
x:  42
y:  47
layer3.2.conv_layer_1.weight
0.05154359503011231
x:  17
y:  17
layer3.2.conv_layer_2.weight
0.05968205740328794
x:  20
y:  22
                         Layer 0      Layer 1  ...                       
                                 BasicBlock 0  ... BasicBlock 2          
                          conv 0      conv. 0  ...      conv. 0   conv. 1
Original Model           [16, 3]     [16, 16]  ...     [64, 64]  [64, 64]
ReLU ResNet20            [15, 3]     [16, 16]  ...     [21, 32]    [7, 6]
univ. rational ResNet20  [16, 3]     [16, 16]  ...     [18, 28]  [14, 17]
mix. exp. ResNet20       [16, 3]     [16, 16]  ...     [17, 17]  [20, 22]

[4 rows x 21 columns]
                        Layer 0      Layer 1  ...                            
                                BasicBlock 0  ... Total weights Remained in %
                         conv 0      conv. 0  ...                            
Original Model              430         2302  ...        270214    100.000000
ReLU ResNet20               143          186  ...          3067      1.135026
univ. rational ResNet20      84          165  ...          1945      0.719800
mix. exp. ResNet20           89          282  ...          2444      0.904468

[4 rows x 23 columns]
                           Layer 0      Layer 1  ...                       
                                   BasicBlock 0  ... BasicBlock 2          
                            conv 0      conv. 0  ...      conv. 0   conv. 1
ReLU ResNet20            33.255814     8.079930  ...     0.122077  0.021703
univ. rational ResNet20  19.534884     7.167680  ...     0.113938  0.062395
mix. exp. ResNet20       20.697674    12.250217  ...     0.051544  0.059682

[3 rows x 21 columns]
time needed: 666m 9s
