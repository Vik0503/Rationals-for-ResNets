Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71e102f00
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71e0d3d20
    (shortcut): Sequential()
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71e0de230
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71e0c7aa0
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71e0deaa0
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71e0def00
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71e0e9410
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71e0e9870
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71e0e9d20
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71ce75410
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71ce758c0
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71ce75d20
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71ce81230
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71ce81690
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71ce81b40
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71ce8d230
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71ce8d6e0
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7fc71ce8db40
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce993c0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce99f00
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cea9050
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cea90a0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cea9640
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce99f50
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cea94b0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cea9500
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cea9140
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cea9780
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cea98c0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce32550
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce325a0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce324b0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce32fa0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce32500
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce32460
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce323c0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce32d20
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce32be0
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce32e10
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce40230
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce40910
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce4c370
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce4c280
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce40a00
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce409b0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce40b90
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce4c0f0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce4c500
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce4c5f0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce4ceb0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce59640
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce59690
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce59500
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce4cf50
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce4c640
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce59190
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce590a0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce59a50
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce59910
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce64780
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce647d0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce64d70
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce703c0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce64730
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce64690
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce64e60
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce646e0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce70190
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc7200fef50
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce70280
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce70be0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cdfc280
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cdfc640
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce70cd0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce70d70
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cdfc500
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cdfc410
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cdfc3c0
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71cdfc550
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce08370
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce083c0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce082d0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce089b0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce08320
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce08280
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce081e0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce08870
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce08e60
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce08d70
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce14aa0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce14910
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce1f0a0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce1f460
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce14a50
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce14af0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce1f320
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce1f230
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce1f1e0
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce1f370
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce2b190
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce2b0a0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce2b0f0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce2b780
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce1ffa0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce2b140
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce2b5f0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce2b230
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7fc71ce2b8c0
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2690 Acc: 0.1845
val Loss: 2.2316 Acc: 0.1889
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 2.1411 Acc: 0.2339
val Loss: 2.0196 Acc: 0.2852
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 1.7144 Acc: 0.3930
val Loss: 1.4171 Acc: 0.5103
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 1.0172 Acc: 0.6622
val Loss: 0.9984 Acc: 0.6836
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5864 Acc: 0.8125
val Loss: 0.6552 Acc: 0.7806
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4699 Acc: 0.8516
val Loss: 0.5628 Acc: 0.8157
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4137 Acc: 0.8718
val Loss: 0.4979 Acc: 0.8468
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3780 Acc: 0.8835
val Loss: 0.4250 Acc: 0.8674
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3519 Acc: 0.8925
val Loss: 0.3842 Acc: 0.8807
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3300 Acc: 0.8995
val Loss: 0.3554 Acc: 0.8922
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3184 Acc: 0.9020
val Loss: 0.4151 Acc: 0.8742
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3048 Acc: 0.9074
val Loss: 0.3862 Acc: 0.8788
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2936 Acc: 0.9103
val Loss: 0.3436 Acc: 0.8943
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2880 Acc: 0.9123
val Loss: 0.3574 Acc: 0.8907
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2777 Acc: 0.9155
val Loss: 0.3181 Acc: 0.9019
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2658 Acc: 0.9203
val Loss: 0.3356 Acc: 0.8954
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2599 Acc: 0.9234
val Loss: 0.2616 Acc: 0.9220
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2240 Acc: 0.9350
val Loss: 0.2456 Acc: 0.9280
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2133 Acc: 0.9380
val Loss: 0.2371 Acc: 0.9304
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2084 Acc: 0.9390
val Loss: 0.2360 Acc: 0.9309
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2086 Acc: 0.9392
val Loss: 0.2368 Acc: 0.9308
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2074 Acc: 0.9400
val Loss: 0.2353 Acc: 0.9322
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2075 Acc: 0.9395
val Loss: 0.2334 Acc: 0.9333
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2052 Acc: 0.9403
val Loss: 0.2357 Acc: 0.9317
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2064 Acc: 0.9387
val Loss: 0.2338 Acc: 0.9311
Epoch finished in 0m 9s
Best validation accuracy: 0.9311455716937862
Before Pruning
++++++++++++++++++
Model Test Accuracy:  0.9395359557467732
Pruning Epoch 1
++++++++++++++++++
number of weights to prune:  53540.0
Sparsity of Pruned Mask:  tensor(0.2000)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.1939 Acc: 0.2226
val Loss: 1.9658 Acc: 0.3060
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.5559 Acc: 0.4745
val Loss: 1.0401 Acc: 0.6712
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.6643 Acc: 0.7944
val Loss: 0.5295 Acc: 0.8361
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4524 Acc: 0.8586
val Loss: 0.4483 Acc: 0.8599
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3868 Acc: 0.8801
val Loss: 0.3834 Acc: 0.8801
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3444 Acc: 0.8942
val Loss: 0.3744 Acc: 0.8834
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3280 Acc: 0.8989
val Loss: 0.3611 Acc: 0.8895
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3121 Acc: 0.9054
val Loss: 0.3947 Acc: 0.8782
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2987 Acc: 0.9095
val Loss: 0.3381 Acc: 0.8973
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2886 Acc: 0.9133
val Loss: 0.3481 Acc: 0.8953
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2773 Acc: 0.9164
val Loss: 0.3331 Acc: 0.8947
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2702 Acc: 0.9181
val Loss: 0.3045 Acc: 0.9082
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2633 Acc: 0.9205
val Loss: 0.3213 Acc: 0.9021
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2590 Acc: 0.9221
val Loss: 0.3205 Acc: 0.9004
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2548 Acc: 0.9230
val Loss: 0.3135 Acc: 0.9051
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2492 Acc: 0.9259
val Loss: 0.3160 Acc: 0.9040
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2423 Acc: 0.9280
val Loss: 0.2519 Acc: 0.9255
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2118 Acc: 0.9375
val Loss: 0.2338 Acc: 0.9326
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2025 Acc: 0.9406
val Loss: 0.2316 Acc: 0.9310
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1972 Acc: 0.9427
val Loss: 0.2261 Acc: 0.9338
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1926 Acc: 0.9444
val Loss: 0.2285 Acc: 0.9344
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1935 Acc: 0.9444
val Loss: 0.2250 Acc: 0.9348
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1933 Acc: 0.9437
val Loss: 0.2243 Acc: 0.9344
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1945 Acc: 0.9440
val Loss: 0.2235 Acc: 0.9335
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1938 Acc: 0.9436
val Loss: 0.2244 Acc: 0.9345
Epoch finished in 0m 9s
Best validation accuracy: 0.9344763568854428
Model Test Accuracy:  0.9416487400122925
Pruning Epoch 2
++++++++++++++++++
number of weights to prune:  42831.0
Sparsity of Pruned Mask:  tensor(0.3600)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.9820 Acc: 0.3197
val Loss: 1.3921 Acc: 0.6024
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.8125 Acc: 0.7734
val Loss: 0.5083 Acc: 0.8525
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4269 Acc: 0.8716
val Loss: 0.3873 Acc: 0.8806
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3514 Acc: 0.8937
val Loss: 0.3439 Acc: 0.8963
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3148 Acc: 0.9035
val Loss: 0.3448 Acc: 0.8949
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2964 Acc: 0.9112
val Loss: 0.3490 Acc: 0.8943
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2895 Acc: 0.9123
val Loss: 0.3186 Acc: 0.9042
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2710 Acc: 0.9199
val Loss: 0.3101 Acc: 0.9048
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2661 Acc: 0.9197
val Loss: 0.3352 Acc: 0.8972
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2596 Acc: 0.9220
val Loss: 0.3009 Acc: 0.9093
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2537 Acc: 0.9245
val Loss: 0.3108 Acc: 0.9063
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2531 Acc: 0.9233
val Loss: 0.2849 Acc: 0.9154
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2428 Acc: 0.9278
val Loss: 0.2947 Acc: 0.9126
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2425 Acc: 0.9270
val Loss: 0.2842 Acc: 0.9135
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2383 Acc: 0.9292
val Loss: 0.3024 Acc: 0.9094
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2348 Acc: 0.9302
val Loss: 0.2871 Acc: 0.9159
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2286 Acc: 0.9316
val Loss: 0.2455 Acc: 0.9261
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2037 Acc: 0.9400
val Loss: 0.2282 Acc: 0.9349
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1912 Acc: 0.9443
val Loss: 0.2235 Acc: 0.9356
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1851 Acc: 0.9467
val Loss: 0.2184 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1836 Acc: 0.9469
val Loss: 0.2209 Acc: 0.9370
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1812 Acc: 0.9472
val Loss: 0.2209 Acc: 0.9366
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1827 Acc: 0.9478
val Loss: 0.2199 Acc: 0.9372
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1834 Acc: 0.9470
val Loss: 0.2182 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1818 Acc: 0.9478
val Loss: 0.2199 Acc: 0.9374
Epoch finished in 0m 9s
Best validation accuracy: 0.9374249208255979
Model Test Accuracy:  0.9449139520590042
Pruning Epoch 3
++++++++++++++++++
number of weights to prune:  34265.0
Sparsity of Pruned Mask:  tensor(0.4880)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.7051 Acc: 0.4630
val Loss: 0.9298 Acc: 0.7797
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5828 Acc: 0.8458
val Loss: 0.4155 Acc: 0.8788
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3637 Acc: 0.8926
val Loss: 0.3418 Acc: 0.8977
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3075 Acc: 0.9072
val Loss: 0.3131 Acc: 0.9053
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2823 Acc: 0.9147
val Loss: 0.3139 Acc: 0.9059
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2652 Acc: 0.9194
val Loss: 0.2767 Acc: 0.9167
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2613 Acc: 0.9209
val Loss: 0.3194 Acc: 0.9048
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2495 Acc: 0.9251
val Loss: 0.3023 Acc: 0.9079
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2468 Acc: 0.9249
val Loss: 0.3247 Acc: 0.9038
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2424 Acc: 0.9280
val Loss: 0.2740 Acc: 0.9180
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2381 Acc: 0.9289
val Loss: 0.2922 Acc: 0.9161
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2342 Acc: 0.9302
val Loss: 0.2679 Acc: 0.9203
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2311 Acc: 0.9311
val Loss: 0.2914 Acc: 0.9132
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2272 Acc: 0.9323
val Loss: 0.2780 Acc: 0.9164
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2259 Acc: 0.9329
val Loss: 0.2806 Acc: 0.9175
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2228 Acc: 0.9334
val Loss: 0.2753 Acc: 0.9183
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2204 Acc: 0.9356
val Loss: 0.2430 Acc: 0.9301
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1930 Acc: 0.9435
val Loss: 0.2254 Acc: 0.9340
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1816 Acc: 0.9468
val Loss: 0.2182 Acc: 0.9361
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1753 Acc: 0.9495
val Loss: 0.2140 Acc: 0.9382
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1751 Acc: 0.9506
val Loss: 0.2169 Acc: 0.9372
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1743 Acc: 0.9493
val Loss: 0.2167 Acc: 0.9370
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1726 Acc: 0.9510
val Loss: 0.2152 Acc: 0.9385
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1743 Acc: 0.9504
val Loss: 0.2158 Acc: 0.9363
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1739 Acc: 0.9500
val Loss: 0.2175 Acc: 0.9366
Epoch finished in 0m 9s
Best validation accuracy: 0.9365512722507372
Model Test Accuracy:  0.9447987092808849
Pruning Epoch 4
++++++++++++++++++
number of weights to prune:  27412.0
Sparsity of Pruned Mask:  tensor(0.5904)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.5931 Acc: 0.5214
val Loss: 0.7864 Acc: 0.8245
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5175 Acc: 0.8647
val Loss: 0.3902 Acc: 0.8869
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3356 Acc: 0.9016
val Loss: 0.3145 Acc: 0.9070
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2849 Acc: 0.9146
val Loss: 0.2926 Acc: 0.9103
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2660 Acc: 0.9203
val Loss: 0.3066 Acc: 0.9073
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2485 Acc: 0.9261
val Loss: 0.2753 Acc: 0.9168
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2406 Acc: 0.9275
val Loss: 0.3345 Acc: 0.8981
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2375 Acc: 0.9294
val Loss: 0.2848 Acc: 0.9156
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2334 Acc: 0.9305
val Loss: 0.2806 Acc: 0.9162
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2294 Acc: 0.9316
val Loss: 0.2766 Acc: 0.9186
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2238 Acc: 0.9327
val Loss: 0.2831 Acc: 0.9165
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2212 Acc: 0.9338
val Loss: 0.2753 Acc: 0.9202
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2227 Acc: 0.9334
val Loss: 0.2734 Acc: 0.9191
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2217 Acc: 0.9342
val Loss: 0.2664 Acc: 0.9201
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2169 Acc: 0.9360
val Loss: 0.2818 Acc: 0.9162
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2156 Acc: 0.9355
val Loss: 0.2506 Acc: 0.9252
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2112 Acc: 0.9374
val Loss: 0.2326 Acc: 0.9340
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1855 Acc: 0.9461
val Loss: 0.2219 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1787 Acc: 0.9487
val Loss: 0.2138 Acc: 0.9385
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1710 Acc: 0.9510
val Loss: 0.2126 Acc: 0.9396
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1699 Acc: 0.9518
val Loss: 0.2145 Acc: 0.9393
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1700 Acc: 0.9526
val Loss: 0.2142 Acc: 0.9381
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1705 Acc: 0.9516
val Loss: 0.2126 Acc: 0.9385
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1700 Acc: 0.9516
val Loss: 0.2124 Acc: 0.9386
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1685 Acc: 0.9518
val Loss: 0.2110 Acc: 0.9390
Epoch finished in 0m 9s
Best validation accuracy: 0.939008408867533
Model Test Accuracy:  0.946757836508912
Pruning Epoch 5
++++++++++++++++++
number of weights to prune:  21929.0
Sparsity of Pruned Mask:  tensor(0.6723)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.5186 Acc: 0.5567
val Loss: 0.7462 Acc: 0.8389
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.4903 Acc: 0.8763
val Loss: 0.3655 Acc: 0.8963
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3140 Acc: 0.9087
val Loss: 0.3046 Acc: 0.9088
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2711 Acc: 0.9193
val Loss: 0.3026 Acc: 0.9088
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2481 Acc: 0.9266
val Loss: 0.2629 Acc: 0.9215
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2394 Acc: 0.9285
val Loss: 0.2991 Acc: 0.9110
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2320 Acc: 0.9308
val Loss: 0.2703 Acc: 0.9204
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2282 Acc: 0.9318
val Loss: 0.2957 Acc: 0.9101
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2224 Acc: 0.9331
val Loss: 0.2753 Acc: 0.9202
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2217 Acc: 0.9337
val Loss: 0.2885 Acc: 0.9126
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2199 Acc: 0.9348
val Loss: 0.2714 Acc: 0.9208
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2170 Acc: 0.9358
val Loss: 0.2854 Acc: 0.9139
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2153 Acc: 0.9357
val Loss: 0.2811 Acc: 0.9153
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2128 Acc: 0.9371
val Loss: 0.2732 Acc: 0.9200
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2109 Acc: 0.9377
val Loss: 0.2641 Acc: 0.9231
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2095 Acc: 0.9368
val Loss: 0.2504 Acc: 0.9262
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2116 Acc: 0.9367
val Loss: 0.2368 Acc: 0.9291
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1855 Acc: 0.9456
val Loss: 0.2252 Acc: 0.9345
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1755 Acc: 0.9490
val Loss: 0.2194 Acc: 0.9358
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1718 Acc: 0.9506
val Loss: 0.2169 Acc: 0.9377
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1678 Acc: 0.9511
val Loss: 0.2169 Acc: 0.9359
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1663 Acc: 0.9526
val Loss: 0.2154 Acc: 0.9367
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1683 Acc: 0.9512
val Loss: 0.2155 Acc: 0.9374
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1672 Acc: 0.9519
val Loss: 0.2172 Acc: 0.9363
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1685 Acc: 0.9516
val Loss: 0.2123 Acc: 0.9387
Epoch finished in 0m 9s
Best validation accuracy: 0.9386807906519603
Model Test Accuracy:  0.9473340503995082
Pruning Epoch 6
++++++++++++++++++
number of weights to prune:  17543.0
Sparsity of Pruned Mask:  tensor(0.7379)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.5329 Acc: 0.5557
val Loss: 0.7318 Acc: 0.8456
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.4834 Acc: 0.8789
val Loss: 0.3586 Acc: 0.8973
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3103 Acc: 0.9100
val Loss: 0.2910 Acc: 0.9147
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2604 Acc: 0.9228
val Loss: 0.2853 Acc: 0.9138
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2412 Acc: 0.9283
val Loss: 0.2654 Acc: 0.9196
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2338 Acc: 0.9306
val Loss: 0.2567 Acc: 0.9214
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2247 Acc: 0.9341
val Loss: 0.2689 Acc: 0.9208
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2215 Acc: 0.9333
val Loss: 0.2804 Acc: 0.9162
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2167 Acc: 0.9357
val Loss: 0.2713 Acc: 0.9201
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2138 Acc: 0.9366
val Loss: 0.3203 Acc: 0.9054
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2140 Acc: 0.9375
val Loss: 0.2954 Acc: 0.9105
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2118 Acc: 0.9375
val Loss: 0.2731 Acc: 0.9189
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2110 Acc: 0.9364
val Loss: 0.2558 Acc: 0.9249
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2095 Acc: 0.9371
val Loss: 0.2558 Acc: 0.9244
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2090 Acc: 0.9381
val Loss: 0.2713 Acc: 0.9194
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2075 Acc: 0.9386
val Loss: 0.2805 Acc: 0.9192
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2020 Acc: 0.9396
val Loss: 0.2309 Acc: 0.9328
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1788 Acc: 0.9481
val Loss: 0.2184 Acc: 0.9352
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1714 Acc: 0.9507
val Loss: 0.2167 Acc: 0.9382
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1670 Acc: 0.9521
val Loss: 0.2139 Acc: 0.9392
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1645 Acc: 0.9533
val Loss: 0.2148 Acc: 0.9378
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1628 Acc: 0.9528
val Loss: 0.2135 Acc: 0.9389
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1633 Acc: 0.9529
val Loss: 0.2109 Acc: 0.9398
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1626 Acc: 0.9535
val Loss: 0.2121 Acc: 0.9390
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1617 Acc: 0.9536
val Loss: 0.2153 Acc: 0.9386
Epoch finished in 0m 9s
Best validation accuracy: 0.9386261876160314
Model Test Accuracy:  0.9448371235402581
Pruning Epoch 7
++++++++++++++++++
number of weights to prune:  14034.0
Sparsity of Pruned Mask:  tensor(0.7903)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.5577 Acc: 0.5505
val Loss: 0.7448 Acc: 0.8430
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.4885 Acc: 0.8787
val Loss: 0.3621 Acc: 0.9005
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3092 Acc: 0.9114
val Loss: 0.2911 Acc: 0.9145
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2590 Acc: 0.9238
val Loss: 0.2759 Acc: 0.9179
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2381 Acc: 0.9287
val Loss: 0.2692 Acc: 0.9205
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2274 Acc: 0.9327
val Loss: 0.2855 Acc: 0.9154
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2230 Acc: 0.9339
val Loss: 0.2583 Acc: 0.9236
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2182 Acc: 0.9350
val Loss: 0.2597 Acc: 0.9218
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2152 Acc: 0.9361
val Loss: 0.2479 Acc: 0.9271
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2142 Acc: 0.9367
val Loss: 0.2672 Acc: 0.9210
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2095 Acc: 0.9382
val Loss: 0.2494 Acc: 0.9261
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2088 Acc: 0.9382
val Loss: 0.2750 Acc: 0.9203
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2092 Acc: 0.9378
val Loss: 0.2486 Acc: 0.9249
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2086 Acc: 0.9373
val Loss: 0.2432 Acc: 0.9285
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2052 Acc: 0.9383
val Loss: 0.2883 Acc: 0.9151
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2090 Acc: 0.9377
val Loss: 0.2531 Acc: 0.9242
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2055 Acc: 0.9382
val Loss: 0.2307 Acc: 0.9315
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1796 Acc: 0.9486
val Loss: 0.2161 Acc: 0.9376
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1704 Acc: 0.9514
val Loss: 0.2127 Acc: 0.9370
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1670 Acc: 0.9527
val Loss: 0.2172 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1642 Acc: 0.9524
val Loss: 0.2099 Acc: 0.9394
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1650 Acc: 0.9528
val Loss: 0.2173 Acc: 0.9361
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1642 Acc: 0.9524
val Loss: 0.2154 Acc: 0.9373
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1629 Acc: 0.9539
val Loss: 0.2126 Acc: 0.9370
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1639 Acc: 0.9532
val Loss: 0.2107 Acc: 0.9388
Epoch finished in 0m 9s
Best validation accuracy: 0.9388445997597467
Model Test Accuracy:  0.9452212661339888
Pruning Epoch 8
++++++++++++++++++
number of weights to prune:  11227.0
Sparsity of Pruned Mask:  tensor(0.8322)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.5716 Acc: 0.5445
val Loss: 0.7605 Acc: 0.8445
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.4924 Acc: 0.8799
val Loss: 0.3610 Acc: 0.8996
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3056 Acc: 0.9130
val Loss: 0.2964 Acc: 0.9117
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2583 Acc: 0.9237
val Loss: 0.2705 Acc: 0.9214
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2362 Acc: 0.9307
val Loss: 0.2759 Acc: 0.9173
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2261 Acc: 0.9328
val Loss: 0.2679 Acc: 0.9195
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2195 Acc: 0.9350
val Loss: 0.2538 Acc: 0.9239
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2160 Acc: 0.9353
val Loss: 0.2610 Acc: 0.9221
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2144 Acc: 0.9360
val Loss: 0.2717 Acc: 0.9212
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2166 Acc: 0.9360
val Loss: 0.2944 Acc: 0.9124
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2126 Acc: 0.9380
val Loss: 0.2763 Acc: 0.9188
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2107 Acc: 0.9384
val Loss: 0.2557 Acc: 0.9243
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2072 Acc: 0.9389
val Loss: 0.2639 Acc: 0.9226
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2101 Acc: 0.9374
val Loss: 0.2694 Acc: 0.9219
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2074 Acc: 0.9391
val Loss: 0.2856 Acc: 0.9178
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2110 Acc: 0.9372
val Loss: 0.2650 Acc: 0.9214
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2083 Acc: 0.9375
val Loss: 0.2368 Acc: 0.9319
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1869 Acc: 0.9463
val Loss: 0.2266 Acc: 0.9356
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1790 Acc: 0.9476
val Loss: 0.2189 Acc: 0.9363
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1720 Acc: 0.9503
val Loss: 0.2164 Acc: 0.9369
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1697 Acc: 0.9505
val Loss: 0.2159 Acc: 0.9379
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1693 Acc: 0.9512
val Loss: 0.2163 Acc: 0.9387
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1678 Acc: 0.9515
val Loss: 0.2124 Acc: 0.9383
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1692 Acc: 0.9517
val Loss: 0.2155 Acc: 0.9382
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1687 Acc: 0.9513
val Loss: 0.2124 Acc: 0.9389
Epoch finished in 0m 9s
Best validation accuracy: 0.9388992027956754
Model Test Accuracy:  0.943838352796558
Pruning Epoch 9
++++++++++++++++++
number of weights to prune:  8982.0
Sparsity of Pruned Mask:  tensor(0.8658)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.5949 Acc: 0.5320
val Loss: 0.8164 Acc: 0.8288
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5131 Acc: 0.8763
val Loss: 0.3592 Acc: 0.9009
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3093 Acc: 0.9117
val Loss: 0.2982 Acc: 0.9131
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2561 Acc: 0.9244
val Loss: 0.2654 Acc: 0.9227
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2379 Acc: 0.9288
val Loss: 0.2705 Acc: 0.9188
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2296 Acc: 0.9327
val Loss: 0.2556 Acc: 0.9231
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2225 Acc: 0.9344
val Loss: 0.2594 Acc: 0.9243
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2219 Acc: 0.9331
val Loss: 0.2703 Acc: 0.9190
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2200 Acc: 0.9343
val Loss: 0.2795 Acc: 0.9171
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2165 Acc: 0.9361
val Loss: 0.2656 Acc: 0.9201
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2132 Acc: 0.9373
val Loss: 0.2533 Acc: 0.9266
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2150 Acc: 0.9364
val Loss: 0.2752 Acc: 0.9206
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2117 Acc: 0.9364
val Loss: 0.2487 Acc: 0.9272
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2100 Acc: 0.9373
val Loss: 0.2905 Acc: 0.9144
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2144 Acc: 0.9360
val Loss: 0.2840 Acc: 0.9156
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2123 Acc: 0.9366
val Loss: 0.2726 Acc: 0.9196
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2132 Acc: 0.9359
val Loss: 0.2403 Acc: 0.9315
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1888 Acc: 0.9445
val Loss: 0.2241 Acc: 0.9349
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1766 Acc: 0.9486
val Loss: 0.2222 Acc: 0.9347
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1738 Acc: 0.9495
val Loss: 0.2194 Acc: 0.9373
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1726 Acc: 0.9506
val Loss: 0.2175 Acc: 0.9373
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1728 Acc: 0.9498
val Loss: 0.2177 Acc: 0.9366
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1708 Acc: 0.9502
val Loss: 0.2172 Acc: 0.9379
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1698 Acc: 0.9508
val Loss: 0.2180 Acc: 0.9350
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1707 Acc: 0.9503
val Loss: 0.2185 Acc: 0.9376
Epoch finished in 0m 9s
Best validation accuracy: 0.9375887299333843
Model Test Accuracy:  0.945259680393362
Pruning Epoch 10
++++++++++++++++++
number of weights to prune:  7185.0
Sparsity of Pruned Mask:  tensor(0.8926)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6335 Acc: 0.5170
val Loss: 0.8618 Acc: 0.8177
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5358 Acc: 0.8725
val Loss: 0.3696 Acc: 0.8959
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3178 Acc: 0.9103
val Loss: 0.2962 Acc: 0.9123
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2660 Acc: 0.9222
val Loss: 0.2740 Acc: 0.9180
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2436 Acc: 0.9282
val Loss: 0.2931 Acc: 0.9118
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2323 Acc: 0.9310
val Loss: 0.2630 Acc: 0.9227
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2287 Acc: 0.9315
val Loss: 0.2698 Acc: 0.9204
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2242 Acc: 0.9339
val Loss: 0.2676 Acc: 0.9222
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2200 Acc: 0.9347
val Loss: 0.2686 Acc: 0.9184
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2236 Acc: 0.9326
val Loss: 0.2554 Acc: 0.9257
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2206 Acc: 0.9336
val Loss: 0.2619 Acc: 0.9228
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2184 Acc: 0.9344
val Loss: 0.2694 Acc: 0.9212
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2189 Acc: 0.9352
val Loss: 0.2860 Acc: 0.9145
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2207 Acc: 0.9334
val Loss: 0.2684 Acc: 0.9206
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2165 Acc: 0.9355
val Loss: 0.2754 Acc: 0.9192
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2189 Acc: 0.9353
val Loss: 0.2777 Acc: 0.9180
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2138 Acc: 0.9355
val Loss: 0.2422 Acc: 0.9292
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1902 Acc: 0.9444
val Loss: 0.2285 Acc: 0.9340
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1844 Acc: 0.9462
val Loss: 0.2255 Acc: 0.9344
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1817 Acc: 0.9475
val Loss: 0.2179 Acc: 0.9354
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1772 Acc: 0.9482
val Loss: 0.2205 Acc: 0.9355
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1759 Acc: 0.9498
val Loss: 0.2171 Acc: 0.9365
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1775 Acc: 0.9487
val Loss: 0.2238 Acc: 0.9337
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1760 Acc: 0.9490
val Loss: 0.2228 Acc: 0.9355
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1761 Acc: 0.9492
val Loss: 0.2230 Acc: 0.9349
Epoch finished in 0m 9s
Best validation accuracy: 0.9349131811728733
Model Test Accuracy:  0.9453365089121081
Pruning Epoch 11
++++++++++++++++++
number of weights to prune:  5748.0
Sparsity of Pruned Mask:  tensor(0.9141)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6707 Acc: 0.4946
val Loss: 0.9079 Acc: 0.8103
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5603 Acc: 0.8671
val Loss: 0.3782 Acc: 0.8954
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3224 Acc: 0.9091
val Loss: 0.3036 Acc: 0.9111
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2706 Acc: 0.9200
val Loss: 0.2799 Acc: 0.9169
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2502 Acc: 0.9260
val Loss: 0.2779 Acc: 0.9173
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2383 Acc: 0.9295
val Loss: 0.2615 Acc: 0.9205
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2348 Acc: 0.9293
val Loss: 0.2709 Acc: 0.9190
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2313 Acc: 0.9301
val Loss: 0.2726 Acc: 0.9174
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2287 Acc: 0.9307
val Loss: 0.2647 Acc: 0.9218
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2228 Acc: 0.9342
val Loss: 0.2898 Acc: 0.9142
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2250 Acc: 0.9332
val Loss: 0.2751 Acc: 0.9204
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2246 Acc: 0.9333
val Loss: 0.2874 Acc: 0.9153
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2246 Acc: 0.9329
val Loss: 0.2667 Acc: 0.9201
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2238 Acc: 0.9339
val Loss: 0.2784 Acc: 0.9173
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2269 Acc: 0.9323
val Loss: 0.2701 Acc: 0.9191
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2247 Acc: 0.9326
val Loss: 0.2718 Acc: 0.9194
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2230 Acc: 0.9336
val Loss: 0.2468 Acc: 0.9274
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2012 Acc: 0.9413
val Loss: 0.2377 Acc: 0.9320
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1919 Acc: 0.9442
val Loss: 0.2299 Acc: 0.9341
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1875 Acc: 0.9457
val Loss: 0.2246 Acc: 0.9352
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1859 Acc: 0.9456
val Loss: 0.2254 Acc: 0.9349
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1858 Acc: 0.9464
val Loss: 0.2247 Acc: 0.9335
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1842 Acc: 0.9464
val Loss: 0.2287 Acc: 0.9332
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1844 Acc: 0.9462
val Loss: 0.2248 Acc: 0.9345
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1837 Acc: 0.9466
val Loss: 0.2244 Acc: 0.9349
Epoch finished in 0m 9s
Best validation accuracy: 0.9349131811728733
Model Test Accuracy:  0.943338967424708
Pruning Epoch 12
++++++++++++++++++
number of weights to prune:  4598.0
Sparsity of Pruned Mask:  tensor(0.9313)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.7100 Acc: 0.4719
val Loss: 0.9517 Acc: 0.8025
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5858 Acc: 0.8621
val Loss: 0.3997 Acc: 0.8918
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3362 Acc: 0.9064
val Loss: 0.3063 Acc: 0.9103
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2773 Acc: 0.9193
val Loss: 0.2851 Acc: 0.9134
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2558 Acc: 0.9254
val Loss: 0.3498 Acc: 0.8933
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2477 Acc: 0.9261
val Loss: 0.3081 Acc: 0.9086
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2411 Acc: 0.9272
val Loss: 0.3016 Acc: 0.9067
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2397 Acc: 0.9290
val Loss: 0.2795 Acc: 0.9169
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2366 Acc: 0.9294
val Loss: 0.2747 Acc: 0.9180
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2384 Acc: 0.9284
val Loss: 0.2848 Acc: 0.9141
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2369 Acc: 0.9292
val Loss: 0.2657 Acc: 0.9215
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2336 Acc: 0.9296
val Loss: 0.2909 Acc: 0.9131
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2331 Acc: 0.9311
val Loss: 0.2819 Acc: 0.9155
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2356 Acc: 0.9293
val Loss: 0.2928 Acc: 0.9126
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2341 Acc: 0.9299
val Loss: 0.2739 Acc: 0.9193
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2337 Acc: 0.9303
val Loss: 0.2733 Acc: 0.9181
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2300 Acc: 0.9311
val Loss: 0.2441 Acc: 0.9277
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2063 Acc: 0.9399
val Loss: 0.2387 Acc: 0.9291
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2000 Acc: 0.9415
val Loss: 0.2343 Acc: 0.9307
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1953 Acc: 0.9422
val Loss: 0.2276 Acc: 0.9326
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1940 Acc: 0.9434
val Loss: 0.2294 Acc: 0.9322
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1933 Acc: 0.9436
val Loss: 0.2252 Acc: 0.9346
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1933 Acc: 0.9440
val Loss: 0.2301 Acc: 0.9331
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1938 Acc: 0.9432
val Loss: 0.2268 Acc: 0.9335
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1920 Acc: 0.9443
val Loss: 0.2304 Acc: 0.9331
Epoch finished in 0m 9s
Best validation accuracy: 0.9330566779512941
Model Test Accuracy:  0.9409572833435771
Pruning Epoch 13
++++++++++++++++++
number of weights to prune:  3678.0
Sparsity of Pruned Mask:  tensor(0.9450)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.8221 Acc: 0.4189
val Loss: 1.1229 Acc: 0.7378
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.6865 Acc: 0.8362
val Loss: 0.4449 Acc: 0.8803
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3703 Acc: 0.8959
val Loss: 0.3370 Acc: 0.9022
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3006 Acc: 0.9124
val Loss: 0.3101 Acc: 0.9084
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2731 Acc: 0.9187
val Loss: 0.3111 Acc: 0.9063
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2586 Acc: 0.9232
val Loss: 0.2911 Acc: 0.9125
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2522 Acc: 0.9250
val Loss: 0.2878 Acc: 0.9151
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2514 Acc: 0.9245
val Loss: 0.2883 Acc: 0.9141
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2502 Acc: 0.9261
val Loss: 0.2783 Acc: 0.9174
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2449 Acc: 0.9264
val Loss: 0.3254 Acc: 0.9018
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2434 Acc: 0.9276
val Loss: 0.2894 Acc: 0.9136
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2453 Acc: 0.9269
val Loss: 0.3635 Acc: 0.8866
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2430 Acc: 0.9266
val Loss: 0.2765 Acc: 0.9194
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2419 Acc: 0.9280
val Loss: 0.3583 Acc: 0.8895
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2441 Acc: 0.9268
val Loss: 0.2801 Acc: 0.9151
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2450 Acc: 0.9261
val Loss: 0.2718 Acc: 0.9198
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2397 Acc: 0.9275
val Loss: 0.2539 Acc: 0.9255
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2167 Acc: 0.9356
val Loss: 0.2407 Acc: 0.9302
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2061 Acc: 0.9406
val Loss: 0.2369 Acc: 0.9302
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2068 Acc: 0.9395
val Loss: 0.2388 Acc: 0.9314
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2028 Acc: 0.9415
val Loss: 0.2366 Acc: 0.9314
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2039 Acc: 0.9408
val Loss: 0.2354 Acc: 0.9318
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1998 Acc: 0.9418
val Loss: 0.2358 Acc: 0.9316
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2021 Acc: 0.9417
val Loss: 0.2374 Acc: 0.9322
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2011 Acc: 0.9416
val Loss: 0.2341 Acc: 0.9302
Epoch finished in 0m 9s
Best validation accuracy: 0.9302173200829966
Model Test Accuracy:  0.9383835279655808
Pruning Epoch 14
++++++++++++++++++
number of weights to prune:  2943.0
Sparsity of Pruned Mask:  tensor(0.9560)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.8742 Acc: 0.3876
val Loss: 1.1956 Acc: 0.7085
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.7379 Acc: 0.8223
val Loss: 0.4758 Acc: 0.8712
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3943 Acc: 0.8902
val Loss: 0.3426 Acc: 0.9010
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3153 Acc: 0.9086
val Loss: 0.3263 Acc: 0.9029
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2884 Acc: 0.9132
val Loss: 0.3076 Acc: 0.9074
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2743 Acc: 0.9188
val Loss: 0.3421 Acc: 0.8957
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2683 Acc: 0.9191
val Loss: 0.3266 Acc: 0.9027
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2626 Acc: 0.9221
val Loss: 0.2921 Acc: 0.9125
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2603 Acc: 0.9226
val Loss: 0.2797 Acc: 0.9179
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2610 Acc: 0.9218
val Loss: 0.2798 Acc: 0.9155
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2589 Acc: 0.9219
val Loss: 0.2821 Acc: 0.9157
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2589 Acc: 0.9224
val Loss: 0.3056 Acc: 0.9109
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2541 Acc: 0.9245
val Loss: 0.2996 Acc: 0.9121
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2526 Acc: 0.9246
val Loss: 0.2918 Acc: 0.9133
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2545 Acc: 0.9244
val Loss: 0.2967 Acc: 0.9101
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2502 Acc: 0.9259
val Loss: 0.3064 Acc: 0.9090
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2544 Acc: 0.9239
val Loss: 0.2670 Acc: 0.9206
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2310 Acc: 0.9315
val Loss: 0.2491 Acc: 0.9277
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2226 Acc: 0.9336
val Loss: 0.2465 Acc: 0.9273
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2189 Acc: 0.9354
val Loss: 0.2431 Acc: 0.9287
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2174 Acc: 0.9359
val Loss: 0.2431 Acc: 0.9307
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2161 Acc: 0.9373
val Loss: 0.2396 Acc: 0.9309
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2143 Acc: 0.9367
val Loss: 0.2437 Acc: 0.9287
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2157 Acc: 0.9368
val Loss: 0.2419 Acc: 0.9298
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2151 Acc: 0.9368
val Loss: 0.2397 Acc: 0.9313
Epoch finished in 0m 9s
Best validation accuracy: 0.9313093808015726
Model Test Accuracy:  0.937077443146896
Pruning Epoch 15
++++++++++++++++++
number of weights to prune:  2354.0
Sparsity of Pruned Mask:  tensor(0.9648)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.8857 Acc: 0.3810
val Loss: 1.2856 Acc: 0.6586
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.8179 Acc: 0.7996
val Loss: 0.5222 Acc: 0.8642
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4342 Acc: 0.8804
val Loss: 0.3793 Acc: 0.8906
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3464 Acc: 0.8996
val Loss: 0.3487 Acc: 0.8960
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3118 Acc: 0.9077
val Loss: 0.3373 Acc: 0.8969
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2973 Acc: 0.9101
val Loss: 0.3324 Acc: 0.8984
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2867 Acc: 0.9149
val Loss: 0.3191 Acc: 0.9032
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2838 Acc: 0.9142
val Loss: 0.3344 Acc: 0.9000
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2773 Acc: 0.9164
val Loss: 0.3480 Acc: 0.8958
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2781 Acc: 0.9170
val Loss: 0.3158 Acc: 0.9042
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2740 Acc: 0.9180
val Loss: 0.2943 Acc: 0.9114
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2758 Acc: 0.9175
val Loss: 0.3168 Acc: 0.9031
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2710 Acc: 0.9189
val Loss: 0.2915 Acc: 0.9114
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2671 Acc: 0.9190
val Loss: 0.3474 Acc: 0.8953
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2680 Acc: 0.9194
val Loss: 0.2835 Acc: 0.9157
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2660 Acc: 0.9208
val Loss: 0.2914 Acc: 0.9119
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2643 Acc: 0.9209
val Loss: 0.2689 Acc: 0.9209
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2405 Acc: 0.9275
val Loss: 0.2563 Acc: 0.9238
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2334 Acc: 0.9303
val Loss: 0.2517 Acc: 0.9265
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2284 Acc: 0.9326
val Loss: 0.2517 Acc: 0.9263
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2270 Acc: 0.9320
val Loss: 0.2493 Acc: 0.9269
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2278 Acc: 0.9323
val Loss: 0.2502 Acc: 0.9250
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2291 Acc: 0.9323
val Loss: 0.2472 Acc: 0.9267
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2274 Acc: 0.9328
val Loss: 0.2540 Acc: 0.9249
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2261 Acc: 0.9329
val Loss: 0.2534 Acc: 0.9260
Epoch finished in 0m 9s
Best validation accuracy: 0.9260128863164792
Model Test Accuracy:  0.9348878303626306
Pruning Epoch 16
++++++++++++++++++
number of weights to prune:  1883.0
Sparsity of Pruned Mask:  tensor(0.9719)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.9570 Acc: 0.3460
val Loss: 1.4748 Acc: 0.5873
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.9531 Acc: 0.7618
val Loss: 0.5960 Acc: 0.8495
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4841 Acc: 0.8686
val Loss: 0.4552 Acc: 0.8675
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3821 Acc: 0.8903
val Loss: 0.3694 Acc: 0.8894
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3398 Acc: 0.8984
val Loss: 0.3467 Acc: 0.8958
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3208 Acc: 0.9039
val Loss: 0.3525 Acc: 0.8934
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3115 Acc: 0.9050
val Loss: 0.3177 Acc: 0.9058
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3037 Acc: 0.9082
val Loss: 0.3649 Acc: 0.8919
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3012 Acc: 0.9085
val Loss: 0.3569 Acc: 0.8896
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2964 Acc: 0.9114
val Loss: 0.3160 Acc: 0.9043
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2928 Acc: 0.9110
val Loss: 0.3173 Acc: 0.9058
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2908 Acc: 0.9112
val Loss: 0.3299 Acc: 0.9010
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2866 Acc: 0.9128
val Loss: 0.3213 Acc: 0.9053
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2840 Acc: 0.9141
val Loss: 0.3267 Acc: 0.9018
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2870 Acc: 0.9134
val Loss: 0.3023 Acc: 0.9096
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2872 Acc: 0.9133
val Loss: 0.2995 Acc: 0.9101
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2850 Acc: 0.9126
val Loss: 0.2830 Acc: 0.9135
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2606 Acc: 0.9220
val Loss: 0.2664 Acc: 0.9213
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2516 Acc: 0.9252
val Loss: 0.2618 Acc: 0.9222
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2468 Acc: 0.9274
val Loss: 0.2606 Acc: 0.9243
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2437 Acc: 0.9273
val Loss: 0.2580 Acc: 0.9225
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2451 Acc: 0.9276
val Loss: 0.2591 Acc: 0.9243
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2461 Acc: 0.9276
val Loss: 0.2638 Acc: 0.9230
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2436 Acc: 0.9279
val Loss: 0.2634 Acc: 0.9223
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2429 Acc: 0.9282
val Loss: 0.2586 Acc: 0.9227
Epoch finished in 0m 9s
Best validation accuracy: 0.9226821011248225
Model Test Accuracy:  0.9303549477566072
Pruning Epoch 17
++++++++++++++++++
number of weights to prune:  1506.0
Sparsity of Pruned Mask:  tensor(0.9775)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.0387 Acc: 0.3023
val Loss: 1.6296 Acc: 0.4870
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.1056 Acc: 0.7050
val Loss: 0.6961 Acc: 0.8263
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.5542 Acc: 0.8485
val Loss: 0.4714 Acc: 0.8632
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4219 Acc: 0.8782
val Loss: 0.3986 Acc: 0.8824
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3729 Acc: 0.8892
val Loss: 0.3870 Acc: 0.8812
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3512 Acc: 0.8940
val Loss: 0.3759 Acc: 0.8866
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3370 Acc: 0.8984
val Loss: 0.3440 Acc: 0.8949
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3304 Acc: 0.8997
val Loss: 0.3447 Acc: 0.8942
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3222 Acc: 0.9032
val Loss: 0.3591 Acc: 0.8889
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3160 Acc: 0.9046
val Loss: 0.3338 Acc: 0.9012
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3158 Acc: 0.9037
val Loss: 0.3506 Acc: 0.8957
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3135 Acc: 0.9040
val Loss: 0.3723 Acc: 0.8863
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3092 Acc: 0.9057
val Loss: 0.3157 Acc: 0.9050
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3061 Acc: 0.9072
val Loss: 0.3274 Acc: 0.9013
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3045 Acc: 0.9078
val Loss: 0.3185 Acc: 0.9035
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3043 Acc: 0.9075
val Loss: 0.3619 Acc: 0.8921
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3017 Acc: 0.9084
val Loss: 0.2948 Acc: 0.9126
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2769 Acc: 0.9177
val Loss: 0.2753 Acc: 0.9182
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2652 Acc: 0.9204
val Loss: 0.2771 Acc: 0.9184
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2623 Acc: 0.9223
val Loss: 0.2684 Acc: 0.9212
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2600 Acc: 0.9229
val Loss: 0.2719 Acc: 0.9196
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2630 Acc: 0.9217
val Loss: 0.2733 Acc: 0.9189
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2615 Acc: 0.9214
val Loss: 0.2755 Acc: 0.9173
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2619 Acc: 0.9220
val Loss: 0.2700 Acc: 0.9203
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2596 Acc: 0.9241
val Loss: 0.2702 Acc: 0.9177
Epoch finished in 0m 9s
Best validation accuracy: 0.9176586218193732
Model Test Accuracy:  0.9238629379225568
Pruning Epoch 18
++++++++++++++++++
number of weights to prune:  1205.0
Sparsity of Pruned Mask:  tensor(0.9820)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.1450 Acc: 0.2428
val Loss: 1.8767 Acc: 0.3566
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.4352 Acc: 0.5582
val Loss: 0.9626 Acc: 0.7329
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.7308 Acc: 0.8031
val Loss: 0.5660 Acc: 0.8399
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5095 Acc: 0.8523
val Loss: 0.4819 Acc: 0.8542
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4389 Acc: 0.8684
val Loss: 0.4295 Acc: 0.8721
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4063 Acc: 0.8769
val Loss: 0.4180 Acc: 0.8709
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3796 Acc: 0.8835
val Loss: 0.4148 Acc: 0.8734
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3644 Acc: 0.8876
val Loss: 0.3736 Acc: 0.8870
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3576 Acc: 0.8907
val Loss: 0.4188 Acc: 0.8712
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3473 Acc: 0.8942
val Loss: 0.3896 Acc: 0.8807
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3444 Acc: 0.8946
val Loss: 0.3505 Acc: 0.8909
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3407 Acc: 0.8951
val Loss: 0.3422 Acc: 0.8970
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3385 Acc: 0.8962
val Loss: 0.3401 Acc: 0.8971
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3295 Acc: 0.8983
val Loss: 0.3495 Acc: 0.8947
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3312 Acc: 0.8983
val Loss: 0.3380 Acc: 0.8972
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3237 Acc: 0.9002
val Loss: 0.3393 Acc: 0.8963
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3230 Acc: 0.9028
val Loss: 0.3147 Acc: 0.9050
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3009 Acc: 0.9095
val Loss: 0.3005 Acc: 0.9084
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2936 Acc: 0.9116
val Loss: 0.2933 Acc: 0.9126
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2882 Acc: 0.9136
val Loss: 0.2945 Acc: 0.9114
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2864 Acc: 0.9150
val Loss: 0.2927 Acc: 0.9120
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2834 Acc: 0.9156
val Loss: 0.2914 Acc: 0.9117
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2838 Acc: 0.9141
val Loss: 0.2907 Acc: 0.9129
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2845 Acc: 0.9149
val Loss: 0.2891 Acc: 0.9130
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2844 Acc: 0.9148
val Loss: 0.2906 Acc: 0.9131
Epoch finished in 0m 9s
Best validation accuracy: 0.913126569837283
Model Test Accuracy:  0.9172940995697603
Pruning Epoch 19
++++++++++++++++++
number of weights to prune:  963.0
Sparsity of Pruned Mask:  tensor(0.9856)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.1851 Acc: 0.2281
val Loss: 1.9831 Acc: 0.3175
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.7222 Acc: 0.4230
val Loss: 1.3533 Acc: 0.6135
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 1.0405 Acc: 0.7090
val Loss: 0.8034 Acc: 0.7693
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.6640 Acc: 0.8155
val Loss: 0.5565 Acc: 0.8378
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5217 Acc: 0.8451
val Loss: 0.5053 Acc: 0.8445
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4596 Acc: 0.8601
val Loss: 0.4690 Acc: 0.8581
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4262 Acc: 0.8701
val Loss: 0.4250 Acc: 0.8696
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4052 Acc: 0.8754
val Loss: 0.4014 Acc: 0.8771
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3896 Acc: 0.8805
val Loss: 0.3805 Acc: 0.8838
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3820 Acc: 0.8828
val Loss: 0.3835 Acc: 0.8835
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3731 Acc: 0.8850
val Loss: 0.3846 Acc: 0.8814
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3648 Acc: 0.8874
val Loss: 0.3820 Acc: 0.8835
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3613 Acc: 0.8907
val Loss: 0.4303 Acc: 0.8697
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3555 Acc: 0.8916
val Loss: 0.3996 Acc: 0.8779
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3508 Acc: 0.8919
val Loss: 0.3635 Acc: 0.8918
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3500 Acc: 0.8938
val Loss: 0.3566 Acc: 0.8914
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3446 Acc: 0.8945
val Loss: 0.3277 Acc: 0.9001
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3258 Acc: 0.9016
val Loss: 0.3226 Acc: 0.9055
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3104 Acc: 0.9059
val Loss: 0.3139 Acc: 0.9076
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3076 Acc: 0.9077
val Loss: 0.3109 Acc: 0.9070
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3065 Acc: 0.9081
val Loss: 0.3100 Acc: 0.9070
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3077 Acc: 0.9076
val Loss: 0.3066 Acc: 0.9086
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3052 Acc: 0.9083
val Loss: 0.3059 Acc: 0.9086
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3049 Acc: 0.9082
val Loss: 0.3101 Acc: 0.9074
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3073 Acc: 0.9069
val Loss: 0.3106 Acc: 0.9079
Epoch finished in 0m 9s
Best validation accuracy: 0.9079392814240472
Model Test Accuracy:  0.9083435771358327
Pruning Epoch 20
++++++++++++++++++
number of weights to prune:  771.0
Sparsity of Pruned Mask:  tensor(0.9885)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2060 Acc: 0.2194
val Loss: 2.0259 Acc: 0.2909
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.8159 Acc: 0.3766
val Loss: 1.5453 Acc: 0.5241
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 1.2423 Acc: 0.6290
val Loss: 0.9549 Acc: 0.7253
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.8087 Acc: 0.7714
val Loss: 0.7484 Acc: 0.7798
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.6156 Acc: 0.8188
val Loss: 0.6318 Acc: 0.8017
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.5282 Acc: 0.8412
val Loss: 0.5554 Acc: 0.8268
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4800 Acc: 0.8539
val Loss: 0.4899 Acc: 0.8479
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4509 Acc: 0.8627
val Loss: 0.4449 Acc: 0.8660
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4313 Acc: 0.8668
val Loss: 0.4606 Acc: 0.8576
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4182 Acc: 0.8716
val Loss: 0.4496 Acc: 0.8628
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.4050 Acc: 0.8762
val Loss: 0.4296 Acc: 0.8688
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3980 Acc: 0.8779
val Loss: 0.4408 Acc: 0.8678
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3904 Acc: 0.8792
val Loss: 0.4462 Acc: 0.8623
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3834 Acc: 0.8813
val Loss: 0.3827 Acc: 0.8856
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3813 Acc: 0.8824
val Loss: 0.3969 Acc: 0.8770
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3778 Acc: 0.8835
val Loss: 0.3984 Acc: 0.8770
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3743 Acc: 0.8860
val Loss: 0.3596 Acc: 0.8923
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3471 Acc: 0.8946
val Loss: 0.3409 Acc: 0.9008
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3359 Acc: 0.8993
val Loss: 0.3359 Acc: 0.8986
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3315 Acc: 0.8998
val Loss: 0.3351 Acc: 0.8987
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3295 Acc: 0.9007
val Loss: 0.3364 Acc: 0.9000
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3331 Acc: 0.8993
val Loss: 0.3291 Acc: 0.9019
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3320 Acc: 0.8989
val Loss: 0.3393 Acc: 0.8991
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3295 Acc: 0.8998
val Loss: 0.3335 Acc: 0.9005
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3310 Acc: 0.9002
val Loss: 0.3318 Acc: 0.9012
Epoch finished in 0m 9s
Best validation accuracy: 0.9011685049688762
Model Test Accuracy:  0.8999692685925015
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2714 Acc: 0.1753
val Loss: 2.2377 Acc: 0.1819
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.1793 Acc: 0.2168
val Loss: 2.0397 Acc: 0.2769
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 1.5638 Acc: 0.4489
val Loss: 0.9779 Acc: 0.6793
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.6543 Acc: 0.7923
val Loss: 0.5693 Acc: 0.8214
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4573 Acc: 0.8579
val Loss: 0.5099 Acc: 0.8411
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3950 Acc: 0.8808
val Loss: 0.4141 Acc: 0.8718
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3524 Acc: 0.8931
val Loss: 0.3674 Acc: 0.8907
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3288 Acc: 0.9022
val Loss: 0.3689 Acc: 0.8960
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3053 Acc: 0.9085
val Loss: 0.3316 Acc: 0.9021
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2862 Acc: 0.9160
val Loss: 0.3204 Acc: 0.9042
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2767 Acc: 0.9175
val Loss: 0.3289 Acc: 0.9070
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2613 Acc: 0.9205
val Loss: 0.3026 Acc: 0.9092
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2516 Acc: 0.9246
val Loss: 0.3266 Acc: 0.9044
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2463 Acc: 0.9273
val Loss: 0.2887 Acc: 0.9153
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2339 Acc: 0.9317
val Loss: 0.2758 Acc: 0.9184
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2299 Acc: 0.9325
val Loss: 0.2728 Acc: 0.9215
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2192 Acc: 0.9351
val Loss: 0.2287 Acc: 0.9343
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1846 Acc: 0.9457
val Loss: 0.2230 Acc: 0.9363
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1771 Acc: 0.9484
val Loss: 0.2190 Acc: 0.9386
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1711 Acc: 0.9507
val Loss: 0.2154 Acc: 0.9384
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1708 Acc: 0.9507
val Loss: 0.2150 Acc: 0.9391
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1689 Acc: 0.9515
val Loss: 0.2136 Acc: 0.9408
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1688 Acc: 0.9518
val Loss: 0.2201 Acc: 0.9372
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1684 Acc: 0.9515
val Loss: 0.2164 Acc: 0.9397
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1689 Acc: 0.9510
val Loss: 0.2175 Acc: 0.9389
Epoch finished in 0m 12s
Best validation accuracy: 0.9388992027956754
Before Pruning
++++++++++++++++++
Model Test Accuracy:  0.9436846957590657
Pruning Epoch 1
++++++++++++++++++
number of weights to prune:  53540.0
Sparsity of Pruned Mask:  tensor(0.2000)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2346 Acc: 0.1919
val Loss: 2.0476 Acc: 0.2670
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.2462 Acc: 0.5726
val Loss: 0.6355 Acc: 0.8017
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4630 Acc: 0.8558
val Loss: 0.4732 Acc: 0.8519
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3712 Acc: 0.8878
val Loss: 0.3623 Acc: 0.8888
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3302 Acc: 0.8996
val Loss: 0.3274 Acc: 0.9022
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3025 Acc: 0.9101
val Loss: 0.3417 Acc: 0.9047
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2845 Acc: 0.9152
val Loss: 0.3315 Acc: 0.9011
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2690 Acc: 0.9197
val Loss: 0.3574 Acc: 0.8920
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2560 Acc: 0.9238
val Loss: 0.3224 Acc: 0.9175
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2434 Acc: 0.9289
val Loss: 0.2957 Acc: 0.9114
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2402 Acc: 0.9281
val Loss: 0.2810 Acc: 0.9165
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2327 Acc: 0.9310
val Loss: 0.3188 Acc: 0.9035
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2226 Acc: 0.9340
val Loss: 0.2790 Acc: 0.9185
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2165 Acc: 0.9370
val Loss: 0.3633 Acc: 0.8942
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2161 Acc: 0.9369
val Loss: 0.2660 Acc: 0.9238
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2101 Acc: 0.9377
val Loss: 0.3335 Acc: 0.9046
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2040 Acc: 0.9404
val Loss: 0.2325 Acc: 0.9321
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1746 Acc: 0.9496
val Loss: 0.2187 Acc: 0.9381
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1644 Acc: 0.9532
val Loss: 0.2181 Acc: 0.9378
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1582 Acc: 0.9558
val Loss: 0.2170 Acc: 0.9370
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1560 Acc: 0.9551
val Loss: 0.2113 Acc: 0.9385
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1548 Acc: 0.9569
val Loss: 0.2149 Acc: 0.9403
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1549 Acc: 0.9562
val Loss: 0.2122 Acc: 0.9387
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1549 Acc: 0.9561
val Loss: 0.2084 Acc: 0.9424
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1542 Acc: 0.9555
val Loss: 0.2125 Acc: 0.9409
Epoch finished in 0m 12s
Best validation accuracy: 0.9408649120891122
Model Test Accuracy:  0.9463736939151812
Pruning Epoch 2
++++++++++++++++++
number of weights to prune:  42831.0
Sparsity of Pruned Mask:  tensor(0.3600)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.0815 Acc: 0.2609
val Loss: 1.1767 Acc: 0.6131
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5441 Acc: 0.8289
val Loss: 0.4095 Acc: 0.8730
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3496 Acc: 0.8947
val Loss: 0.3428 Acc: 0.8951
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3010 Acc: 0.9103
val Loss: 0.3903 Acc: 0.8819
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2733 Acc: 0.9180
val Loss: 0.2844 Acc: 0.9151
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2549 Acc: 0.9252
val Loss: 0.3164 Acc: 0.9056
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2458 Acc: 0.9278
val Loss: 0.2793 Acc: 0.9162
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2336 Acc: 0.9306
val Loss: 0.2550 Acc: 0.9257
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2266 Acc: 0.9337
val Loss: 0.2693 Acc: 0.9220
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2186 Acc: 0.9357
val Loss: 0.2758 Acc: 0.9238
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2122 Acc: 0.9377
val Loss: 0.2715 Acc: 0.9238
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2090 Acc: 0.9384
val Loss: 0.2707 Acc: 0.9174
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2020 Acc: 0.9405
val Loss: 0.2478 Acc: 0.9295
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1995 Acc: 0.9413
val Loss: 0.2890 Acc: 0.9160
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1959 Acc: 0.9423
val Loss: 0.2679 Acc: 0.9262
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1929 Acc: 0.9435
val Loss: 0.2498 Acc: 0.9291
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1911 Acc: 0.9444
val Loss: 0.2275 Acc: 0.9349
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1598 Acc: 0.9537
val Loss: 0.2167 Acc: 0.9397
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1488 Acc: 0.9580
val Loss: 0.2154 Acc: 0.9409
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1438 Acc: 0.9586
val Loss: 0.2125 Acc: 0.9419
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1424 Acc: 0.9595
val Loss: 0.2165 Acc: 0.9404
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1409 Acc: 0.9597
val Loss: 0.2163 Acc: 0.9402
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1409 Acc: 0.9599
val Loss: 0.2108 Acc: 0.9422
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1406 Acc: 0.9605
val Loss: 0.2110 Acc: 0.9405
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1409 Acc: 0.9597
val Loss: 0.2181 Acc: 0.9407
Epoch finished in 0m 12s
Best validation accuracy: 0.9407011029813258
Model Test Accuracy:  0.9489474492931775
Pruning Epoch 3
++++++++++++++++++
number of weights to prune:  34265.0
Sparsity of Pruned Mask:  tensor(0.4880)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.8200 Acc: 0.3613
val Loss: 0.5970 Acc: 0.8164
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4083 Acc: 0.8736
val Loss: 0.3684 Acc: 0.8877
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2997 Acc: 0.9103
val Loss: 0.3148 Acc: 0.9062
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2633 Acc: 0.9227
val Loss: 0.2997 Acc: 0.9122
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2425 Acc: 0.9283
val Loss: 0.3161 Acc: 0.9078
Epoch finished in 0m 13s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2308 Acc: 0.9324
val Loss: 0.3140 Acc: 0.9096
Epoch finished in 0m 13s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2203 Acc: 0.9350
val Loss: 0.2820 Acc: 0.9145
Epoch finished in 0m 13s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2110 Acc: 0.9379
val Loss: 0.2638 Acc: 0.9253
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2066 Acc: 0.9395
val Loss: 0.2640 Acc: 0.9246
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2010 Acc: 0.9406
val Loss: 0.2524 Acc: 0.9245
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1977 Acc: 0.9421
val Loss: 0.2597 Acc: 0.9251
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1928 Acc: 0.9432
val Loss: 0.2446 Acc: 0.9287
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1927 Acc: 0.9437
val Loss: 0.2954 Acc: 0.9160
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1880 Acc: 0.9452
val Loss: 0.2649 Acc: 0.9263
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1849 Acc: 0.9454
val Loss: 0.2687 Acc: 0.9209
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1822 Acc: 0.9467
val Loss: 0.2504 Acc: 0.9274
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1792 Acc: 0.9469
val Loss: 0.2243 Acc: 0.9352
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1531 Acc: 0.9556
val Loss: 0.2196 Acc: 0.9408
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1455 Acc: 0.9582
val Loss: 0.2117 Acc: 0.9409
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1385 Acc: 0.9600
val Loss: 0.2177 Acc: 0.9385
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1341 Acc: 0.9607
val Loss: 0.2149 Acc: 0.9383
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1357 Acc: 0.9603
val Loss: 0.2139 Acc: 0.9420
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1323 Acc: 0.9622
val Loss: 0.2177 Acc: 0.9415
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1351 Acc: 0.9612
val Loss: 0.2110 Acc: 0.9415
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1353 Acc: 0.9612
val Loss: 0.2163 Acc: 0.9407
Epoch finished in 0m 12s
Best validation accuracy: 0.9407011029813258
Model Test Accuracy:  0.9469499078057775
Pruning Epoch 4
++++++++++++++++++
number of weights to prune:  27412.0
Sparsity of Pruned Mask:  tensor(0.5904)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6824 Acc: 0.4105
val Loss: 0.5100 Acc: 0.8407
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3676 Acc: 0.8880
val Loss: 0.3462 Acc: 0.8934
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2812 Acc: 0.9159
val Loss: 0.2945 Acc: 0.9103
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2440 Acc: 0.9273
val Loss: 0.2719 Acc: 0.9214
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2231 Acc: 0.9351
val Loss: 0.2697 Acc: 0.9196
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2123 Acc: 0.9376
val Loss: 0.2686 Acc: 0.9227
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2034 Acc: 0.9408
val Loss: 0.2905 Acc: 0.9219
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1950 Acc: 0.9431
val Loss: 0.2720 Acc: 0.9209
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1903 Acc: 0.9445
val Loss: 0.2557 Acc: 0.9256
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1896 Acc: 0.9443
val Loss: 0.2648 Acc: 0.9220
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1844 Acc: 0.9456
val Loss: 0.2621 Acc: 0.9232
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1820 Acc: 0.9468
val Loss: 0.2693 Acc: 0.9226
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1805 Acc: 0.9462
val Loss: 0.2674 Acc: 0.9211
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1786 Acc: 0.9479
val Loss: 0.2493 Acc: 0.9293
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1759 Acc: 0.9477
val Loss: 0.2610 Acc: 0.9250
Epoch finished in 0m 13s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1751 Acc: 0.9487
val Loss: 0.2701 Acc: 0.9219
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1738 Acc: 0.9477
val Loss: 0.2205 Acc: 0.9373
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1458 Acc: 0.9573
val Loss: 0.2180 Acc: 0.9394
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1365 Acc: 0.9602
val Loss: 0.2149 Acc: 0.9418
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1315 Acc: 0.9624
val Loss: 0.2104 Acc: 0.9421
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1298 Acc: 0.9629
val Loss: 0.2104 Acc: 0.9429
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1291 Acc: 0.9628
val Loss: 0.2151 Acc: 0.9414
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1274 Acc: 0.9625
val Loss: 0.2113 Acc: 0.9421
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1313 Acc: 0.9615
val Loss: 0.2114 Acc: 0.9421
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1276 Acc: 0.9629
val Loss: 0.2146 Acc: 0.9414
Epoch finished in 0m 12s
Best validation accuracy: 0.9414109424484002
Model Test Accuracy:  0.9486401352181929
Pruning Epoch 5
++++++++++++++++++
number of weights to prune:  21929.0
Sparsity of Pruned Mask:  tensor(0.6723)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.5840 Acc: 0.4515
val Loss: 0.4612 Acc: 0.8595
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3496 Acc: 0.8937
val Loss: 0.3133 Acc: 0.9080
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2733 Acc: 0.9196
val Loss: 0.2932 Acc: 0.9138
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2350 Acc: 0.9307
val Loss: 0.2679 Acc: 0.9203
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2119 Acc: 0.9380
val Loss: 0.2677 Acc: 0.9240
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2023 Acc: 0.9414
val Loss: 0.2593 Acc: 0.9256
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1958 Acc: 0.9425
val Loss: 0.2524 Acc: 0.9256
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1867 Acc: 0.9445
val Loss: 0.2712 Acc: 0.9266
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1833 Acc: 0.9461
val Loss: 0.2557 Acc: 0.9254
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1786 Acc: 0.9484
val Loss: 0.2647 Acc: 0.9221
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1755 Acc: 0.9481
val Loss: 0.2694 Acc: 0.9230
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1764 Acc: 0.9488
val Loss: 0.2797 Acc: 0.9213
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1736 Acc: 0.9490
val Loss: 0.2670 Acc: 0.9276
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1751 Acc: 0.9485
val Loss: 0.3121 Acc: 0.9129
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1717 Acc: 0.9488
val Loss: 0.2318 Acc: 0.9331
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1696 Acc: 0.9497
val Loss: 0.2529 Acc: 0.9285
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1671 Acc: 0.9503
val Loss: 0.2272 Acc: 0.9369
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1399 Acc: 0.9591
val Loss: 0.2207 Acc: 0.9406
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1318 Acc: 0.9609
val Loss: 0.2154 Acc: 0.9425
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1283 Acc: 0.9620
val Loss: 0.2115 Acc: 0.9419
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1233 Acc: 0.9647
val Loss: 0.2145 Acc: 0.9427
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1253 Acc: 0.9632
val Loss: 0.2139 Acc: 0.9415
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1251 Acc: 0.9637
val Loss: 0.2114 Acc: 0.9439
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1243 Acc: 0.9640
val Loss: 0.2147 Acc: 0.9414
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1230 Acc: 0.9643
val Loss: 0.2128 Acc: 0.9410
Epoch finished in 0m 12s
Best validation accuracy: 0.9409741181609698
Model Test Accuracy:  0.947718192993239
Pruning Epoch 6
++++++++++++++++++
number of weights to prune:  17543.0
Sparsity of Pruned Mask:  tensor(0.7379)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.5982 Acc: 0.4464
val Loss: 0.4736 Acc: 0.8526
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3409 Acc: 0.8961
val Loss: 0.3186 Acc: 0.9045
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2585 Acc: 0.9222
val Loss: 0.3125 Acc: 0.9042
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2258 Acc: 0.9335
val Loss: 0.2819 Acc: 0.9202
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2084 Acc: 0.9380
val Loss: 0.2761 Acc: 0.9166
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1986 Acc: 0.9421
val Loss: 0.2462 Acc: 0.9281
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1918 Acc: 0.9439
val Loss: 0.2661 Acc: 0.9237
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1841 Acc: 0.9467
val Loss: 0.2820 Acc: 0.9186
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1799 Acc: 0.9471
val Loss: 0.2570 Acc: 0.9266
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1765 Acc: 0.9486
val Loss: 0.2498 Acc: 0.9290
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1729 Acc: 0.9482
val Loss: 0.2732 Acc: 0.9180
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1755 Acc: 0.9480
val Loss: 0.2535 Acc: 0.9255
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1731 Acc: 0.9493
val Loss: 0.2580 Acc: 0.9267
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1718 Acc: 0.9491
val Loss: 0.2579 Acc: 0.9239
Epoch finished in 0m 13s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1704 Acc: 0.9497
val Loss: 0.2616 Acc: 0.9308
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1699 Acc: 0.9500
val Loss: 0.2860 Acc: 0.9295
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1666 Acc: 0.9515
val Loss: 0.2247 Acc: 0.9385
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1370 Acc: 0.9596
val Loss: 0.2193 Acc: 0.9394
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1292 Acc: 0.9623
val Loss: 0.2115 Acc: 0.9430
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1258 Acc: 0.9637
val Loss: 0.2150 Acc: 0.9422
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1260 Acc: 0.9635
val Loss: 0.2133 Acc: 0.9429
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1256 Acc: 0.9628
val Loss: 0.2140 Acc: 0.9417
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1227 Acc: 0.9647
val Loss: 0.2081 Acc: 0.9435
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1219 Acc: 0.9647
val Loss: 0.2112 Acc: 0.9424
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1241 Acc: 0.9642
val Loss: 0.2070 Acc: 0.9428
Epoch finished in 0m 12s
Best validation accuracy: 0.9427760183466201
Model Test Accuracy:  0.9492163491087892
Pruning Epoch 7
++++++++++++++++++
number of weights to prune:  14034.0
Sparsity of Pruned Mask:  tensor(0.7903)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.5473 Acc: 0.4619
val Loss: 0.4600 Acc: 0.8564
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3419 Acc: 0.8978
val Loss: 0.3254 Acc: 0.9031
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2587 Acc: 0.9222
val Loss: 0.2865 Acc: 0.9145
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2290 Acc: 0.9319
val Loss: 0.2867 Acc: 0.9181
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2068 Acc: 0.9388
val Loss: 0.2839 Acc: 0.9224
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1935 Acc: 0.9430
val Loss: 0.2763 Acc: 0.9232
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1889 Acc: 0.9444
val Loss: 0.2445 Acc: 0.9296
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1804 Acc: 0.9469
val Loss: 0.2487 Acc: 0.9311
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1805 Acc: 0.9465
val Loss: 0.2726 Acc: 0.9236
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1765 Acc: 0.9480
val Loss: 0.2798 Acc: 0.9182
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1763 Acc: 0.9477
val Loss: 0.3276 Acc: 0.9221
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1732 Acc: 0.9500
val Loss: 0.2672 Acc: 0.9251
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1726 Acc: 0.9487
val Loss: 0.2867 Acc: 0.9287
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1707 Acc: 0.9494
val Loss: 0.2909 Acc: 0.9147
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1700 Acc: 0.9496
val Loss: 0.2758 Acc: 0.9190
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1709 Acc: 0.9488
val Loss: 0.2551 Acc: 0.9269
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1644 Acc: 0.9511
val Loss: 0.2275 Acc: 0.9382
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1360 Acc: 0.9608
val Loss: 0.2173 Acc: 0.9408
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1306 Acc: 0.9618
val Loss: 0.2146 Acc: 0.9432
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1287 Acc: 0.9633
val Loss: 0.2131 Acc: 0.9423
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1254 Acc: 0.9626
val Loss: 0.2106 Acc: 0.9447
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1254 Acc: 0.9638
val Loss: 0.2140 Acc: 0.9429
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1258 Acc: 0.9640
val Loss: 0.2116 Acc: 0.9419
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1250 Acc: 0.9641
val Loss: 0.2094 Acc: 0.9432
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1255 Acc: 0.9631
val Loss: 0.2091 Acc: 0.9449
Epoch finished in 0m 12s
Best validation accuracy: 0.9448509337119144
Model Test Accuracy:  0.9497925629993853
Pruning Epoch 8
++++++++++++++++++
number of weights to prune:  11227.0
Sparsity of Pruned Mask:  tensor(0.8322)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6390 Acc: 0.4324
val Loss: 0.4597 Acc: 0.8564
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3552 Acc: 0.8921
val Loss: 0.3323 Acc: 0.8987
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2667 Acc: 0.9225
val Loss: 0.2758 Acc: 0.9211
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2269 Acc: 0.9337
val Loss: 0.2729 Acc: 0.9196
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2085 Acc: 0.9403
val Loss: 0.2553 Acc: 0.9257
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1973 Acc: 0.9432
val Loss: 0.2529 Acc: 0.9283
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1916 Acc: 0.9432
val Loss: 0.2563 Acc: 0.9286
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1846 Acc: 0.9467
val Loss: 0.2582 Acc: 0.9227
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1816 Acc: 0.9470
val Loss: 0.2693 Acc: 0.9279
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1769 Acc: 0.9475
val Loss: 0.2422 Acc: 0.9307
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1811 Acc: 0.9467
val Loss: 0.2512 Acc: 0.9301
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1762 Acc: 0.9482
val Loss: 0.2669 Acc: 0.9258
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1758 Acc: 0.9491
val Loss: 0.2531 Acc: 0.9289
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1756 Acc: 0.9479
val Loss: 0.2690 Acc: 0.9302
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1717 Acc: 0.9484
val Loss: 0.2898 Acc: 0.9258
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1763 Acc: 0.9476
val Loss: 0.2600 Acc: 0.9277
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1724 Acc: 0.9487
val Loss: 0.2373 Acc: 0.9344
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1454 Acc: 0.9570
val Loss: 0.2253 Acc: 0.9386
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1386 Acc: 0.9599
val Loss: 0.2186 Acc: 0.9397
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1342 Acc: 0.9612
val Loss: 0.2151 Acc: 0.9405
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1315 Acc: 0.9606
val Loss: 0.2150 Acc: 0.9422
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1314 Acc: 0.9620
val Loss: 0.2179 Acc: 0.9398
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1319 Acc: 0.9616
val Loss: 0.2159 Acc: 0.9415
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1318 Acc: 0.9617
val Loss: 0.2161 Acc: 0.9399
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1307 Acc: 0.9623
val Loss: 0.2199 Acc: 0.9410
Epoch finished in 0m 12s
Best validation accuracy: 0.9410287211968985
Model Test Accuracy:  0.9475261216963736
Pruning Epoch 9
++++++++++++++++++
number of weights to prune:  8982.0
Sparsity of Pruned Mask:  tensor(0.8658)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6471 Acc: 0.4286
val Loss: 0.5247 Acc: 0.8425
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3663 Acc: 0.8904
val Loss: 0.3131 Acc: 0.9107
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2659 Acc: 0.9210
val Loss: 0.2812 Acc: 0.9221
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2280 Acc: 0.9315
val Loss: 0.2760 Acc: 0.9208
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2141 Acc: 0.9371
val Loss: 0.2511 Acc: 0.9256
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2045 Acc: 0.9403
val Loss: 0.2527 Acc: 0.9249
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1943 Acc: 0.9427
val Loss: 0.2850 Acc: 0.9191
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1884 Acc: 0.9442
val Loss: 0.2368 Acc: 0.9317
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1855 Acc: 0.9458
val Loss: 0.2603 Acc: 0.9281
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1816 Acc: 0.9467
val Loss: 0.2763 Acc: 0.9233
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1845 Acc: 0.9458
val Loss: 0.2406 Acc: 0.9275
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1793 Acc: 0.9462
val Loss: 0.2852 Acc: 0.9229
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1819 Acc: 0.9464
val Loss: 0.2398 Acc: 0.9309
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1806 Acc: 0.9473
val Loss: 0.2653 Acc: 0.9266
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1823 Acc: 0.9449
val Loss: 0.2418 Acc: 0.9304
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1814 Acc: 0.9470
val Loss: 0.2578 Acc: 0.9284
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1797 Acc: 0.9467
val Loss: 0.2300 Acc: 0.9350
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1536 Acc: 0.9554
val Loss: 0.2201 Acc: 0.9391
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1472 Acc: 0.9578
val Loss: 0.2168 Acc: 0.9397
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1414 Acc: 0.9593
val Loss: 0.2125 Acc: 0.9408
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1419 Acc: 0.9594
val Loss: 0.2089 Acc: 0.9409
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1406 Acc: 0.9590
val Loss: 0.2178 Acc: 0.9403
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1396 Acc: 0.9601
val Loss: 0.2139 Acc: 0.9396
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1383 Acc: 0.9598
val Loss: 0.2122 Acc: 0.9421
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1386 Acc: 0.9591
val Loss: 0.2139 Acc: 0.9423
Epoch finished in 0m 12s
Best validation accuracy: 0.9422845910232609
Model Test Accuracy:  0.9470267363245236
Pruning Epoch 10
++++++++++++++++++
number of weights to prune:  7185.0
Sparsity of Pruned Mask:  tensor(0.8926)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6743 Acc: 0.4236
val Loss: 0.5201 Acc: 0.8363
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3695 Acc: 0.8868
val Loss: 0.3177 Acc: 0.9040
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2714 Acc: 0.9183
val Loss: 0.2784 Acc: 0.9183
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2373 Acc: 0.9300
val Loss: 0.2811 Acc: 0.9197
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2173 Acc: 0.9363
val Loss: 0.3004 Acc: 0.9275
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2107 Acc: 0.9378
val Loss: 0.2519 Acc: 0.9281
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1998 Acc: 0.9407
val Loss: 0.2689 Acc: 0.9281
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1957 Acc: 0.9420
val Loss: 0.2628 Acc: 0.9225
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1942 Acc: 0.9424
val Loss: 0.2538 Acc: 0.9297
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1906 Acc: 0.9442
val Loss: 0.2635 Acc: 0.9240
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1908 Acc: 0.9430
val Loss: 0.2870 Acc: 0.9164
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1881 Acc: 0.9451
val Loss: 0.2608 Acc: 0.9246
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1904 Acc: 0.9433
val Loss: 0.2579 Acc: 0.9264
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1866 Acc: 0.9442
val Loss: 0.2585 Acc: 0.9250
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1855 Acc: 0.9456
val Loss: 0.2809 Acc: 0.9240
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1875 Acc: 0.9453
val Loss: 0.2423 Acc: 0.9305
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1880 Acc: 0.9441
val Loss: 0.2327 Acc: 0.9348
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1622 Acc: 0.9514
val Loss: 0.2206 Acc: 0.9376
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1562 Acc: 0.9549
val Loss: 0.2167 Acc: 0.9373
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1532 Acc: 0.9564
val Loss: 0.2150 Acc: 0.9415
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1470 Acc: 0.9567
val Loss: 0.2176 Acc: 0.9372
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1489 Acc: 0.9567
val Loss: 0.2115 Acc: 0.9413
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1490 Acc: 0.9558
val Loss: 0.2126 Acc: 0.9402
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1458 Acc: 0.9578
val Loss: 0.2154 Acc: 0.9398
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1476 Acc: 0.9570
val Loss: 0.2155 Acc: 0.9411
Epoch finished in 0m 12s
Best validation accuracy: 0.9410833242328274
Model Test Accuracy:  0.9483712354025814
Pruning Epoch 11
++++++++++++++++++
number of weights to prune:  5748.0
Sparsity of Pruned Mask:  tensor(0.9141)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.7195 Acc: 0.4052
val Loss: 0.5219 Acc: 0.8313
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3782 Acc: 0.8838
val Loss: 0.3219 Acc: 0.9024
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2796 Acc: 0.9173
val Loss: 0.3092 Acc: 0.9114
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2467 Acc: 0.9268
val Loss: 0.2854 Acc: 0.9216
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2257 Acc: 0.9336
val Loss: 0.2942 Acc: 0.9155
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2147 Acc: 0.9371
val Loss: 0.2655 Acc: 0.9226
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2059 Acc: 0.9400
val Loss: 0.2684 Acc: 0.9237
Epoch finished in 0m 13s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2034 Acc: 0.9399
val Loss: 0.2607 Acc: 0.9277
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2015 Acc: 0.9405
val Loss: 0.2771 Acc: 0.9242
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2005 Acc: 0.9410
val Loss: 0.2605 Acc: 0.9289
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1997 Acc: 0.9415
val Loss: 0.3418 Acc: 0.9081
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1984 Acc: 0.9413
val Loss: 0.2529 Acc: 0.9283
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1986 Acc: 0.9415
val Loss: 0.3073 Acc: 0.9153
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1969 Acc: 0.9418
val Loss: 0.2500 Acc: 0.9275
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1931 Acc: 0.9439
val Loss: 0.2851 Acc: 0.9150
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1966 Acc: 0.9416
val Loss: 0.2656 Acc: 0.9259
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1934 Acc: 0.9418
val Loss: 0.2285 Acc: 0.9341
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1705 Acc: 0.9499
val Loss: 0.2219 Acc: 0.9372
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1613 Acc: 0.9528
val Loss: 0.2200 Acc: 0.9392
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1590 Acc: 0.9530
val Loss: 0.2127 Acc: 0.9391
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1563 Acc: 0.9545
val Loss: 0.2218 Acc: 0.9378
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1578 Acc: 0.9544
val Loss: 0.2181 Acc: 0.9402
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1582 Acc: 0.9534
val Loss: 0.2168 Acc: 0.9395
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1567 Acc: 0.9547
val Loss: 0.2154 Acc: 0.9386
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1561 Acc: 0.9542
val Loss: 0.2171 Acc: 0.9376
Epoch finished in 0m 12s
Best validation accuracy: 0.9375887299333843
Model Test Accuracy:  0.9449907805777504
Pruning Epoch 12
++++++++++++++++++
number of weights to prune:  4598.0
Sparsity of Pruned Mask:  tensor(0.9313)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.7973 Acc: 0.3718
val Loss: 0.5547 Acc: 0.8229
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4004 Acc: 0.8782
val Loss: 0.3391 Acc: 0.8975
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2983 Acc: 0.9098
val Loss: 0.3024 Acc: 0.9086
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2573 Acc: 0.9244
val Loss: 0.2868 Acc: 0.9162
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2376 Acc: 0.9289
val Loss: 0.2928 Acc: 0.9208
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2303 Acc: 0.9335
val Loss: 0.3087 Acc: 0.9188
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2208 Acc: 0.9355
val Loss: 0.2697 Acc: 0.9198
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2146 Acc: 0.9373
val Loss: 0.2842 Acc: 0.9167
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2137 Acc: 0.9377
val Loss: 0.2588 Acc: 0.9279
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2074 Acc: 0.9394
val Loss: 0.2775 Acc: 0.9253
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2086 Acc: 0.9379
val Loss: 0.2662 Acc: 0.9250
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2089 Acc: 0.9388
val Loss: 0.2983 Acc: 0.9163
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2062 Acc: 0.9396
val Loss: 0.2879 Acc: 0.9313
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2069 Acc: 0.9390
val Loss: 0.3042 Acc: 0.9080
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2061 Acc: 0.9382
val Loss: 0.2819 Acc: 0.9169
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2091 Acc: 0.9390
val Loss: 0.2625 Acc: 0.9263
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2043 Acc: 0.9404
val Loss: 0.2361 Acc: 0.9327
Epoch finished in 0m 13s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1802 Acc: 0.9472
val Loss: 0.2294 Acc: 0.9351
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1733 Acc: 0.9492
val Loss: 0.2223 Acc: 0.9376
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1697 Acc: 0.9506
val Loss: 0.2228 Acc: 0.9376
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1673 Acc: 0.9510
val Loss: 0.2196 Acc: 0.9386
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1677 Acc: 0.9515
val Loss: 0.2154 Acc: 0.9382
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1682 Acc: 0.9503
val Loss: 0.2220 Acc: 0.9381
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1658 Acc: 0.9511
val Loss: 0.2234 Acc: 0.9386
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1649 Acc: 0.9522
val Loss: 0.2236 Acc: 0.9375
Epoch finished in 0m 12s
Best validation accuracy: 0.9374795238615267
Model Test Accuracy:  0.9456822372464658
Pruning Epoch 13
++++++++++++++++++
number of weights to prune:  3678.0
Sparsity of Pruned Mask:  tensor(0.9450)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.8528 Acc: 0.3468
val Loss: 0.6169 Acc: 0.8014
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4205 Acc: 0.8712
val Loss: 0.3541 Acc: 0.8952
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3044 Acc: 0.9092
val Loss: 0.3501 Acc: 0.8946
Epoch finished in 0m 13s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2605 Acc: 0.9224
val Loss: 0.2697 Acc: 0.9210
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2469 Acc: 0.9263
val Loss: 0.2745 Acc: 0.9230
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2357 Acc: 0.9302
val Loss: 0.2869 Acc: 0.9200
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2300 Acc: 0.9328
val Loss: 0.2971 Acc: 0.9125
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2266 Acc: 0.9340
val Loss: 0.2663 Acc: 0.9250
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2237 Acc: 0.9346
val Loss: 0.2662 Acc: 0.9230
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2245 Acc: 0.9343
val Loss: 0.2847 Acc: 0.9192
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2210 Acc: 0.9348
val Loss: 0.2790 Acc: 0.9175
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2218 Acc: 0.9350
val Loss: 0.2571 Acc: 0.9269
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2188 Acc: 0.9358
val Loss: 0.2939 Acc: 0.9148
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2226 Acc: 0.9351
val Loss: 0.2713 Acc: 0.9208
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2202 Acc: 0.9337
val Loss: 0.2540 Acc: 0.9254
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2162 Acc: 0.9362
val Loss: 0.2874 Acc: 0.9156
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2157 Acc: 0.9353
val Loss: 0.2443 Acc: 0.9289
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1900 Acc: 0.9437
val Loss: 0.2305 Acc: 0.9329
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1832 Acc: 0.9467
val Loss: 0.2261 Acc: 0.9343
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1777 Acc: 0.9490
val Loss: 0.2254 Acc: 0.9353
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1768 Acc: 0.9482
val Loss: 0.2258 Acc: 0.9349
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1762 Acc: 0.9487
val Loss: 0.2220 Acc: 0.9374
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1751 Acc: 0.9495
val Loss: 0.2257 Acc: 0.9365
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1751 Acc: 0.9493
val Loss: 0.2234 Acc: 0.9351
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1755 Acc: 0.9494
val Loss: 0.2257 Acc: 0.9368
Epoch finished in 0m 12s
Best validation accuracy: 0.9367696843944523
Model Test Accuracy:  0.9441072526121695
Pruning Epoch 14
++++++++++++++++++
number of weights to prune:  2943.0
Sparsity of Pruned Mask:  tensor(0.9560)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.9414 Acc: 0.3174
val Loss: 0.7230 Acc: 0.7717
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4557 Acc: 0.8575
val Loss: 0.4050 Acc: 0.8773
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3209 Acc: 0.9035
val Loss: 0.3231 Acc: 0.9049
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2801 Acc: 0.9171
val Loss: 0.3104 Acc: 0.9072
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2608 Acc: 0.9213
val Loss: 0.3153 Acc: 0.9093
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2526 Acc: 0.9248
val Loss: 0.2804 Acc: 0.9194
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2429 Acc: 0.9282
val Loss: 0.2793 Acc: 0.9172
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2417 Acc: 0.9299
val Loss: 0.2741 Acc: 0.9212
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2369 Acc: 0.9293
val Loss: 0.2763 Acc: 0.9198
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2355 Acc: 0.9302
val Loss: 0.2727 Acc: 0.9202
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2343 Acc: 0.9308
val Loss: 0.2795 Acc: 0.9221
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2327 Acc: 0.9307
val Loss: 0.3221 Acc: 0.9086
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2339 Acc: 0.9306
val Loss: 0.2811 Acc: 0.9179
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2301 Acc: 0.9312
val Loss: 0.2859 Acc: 0.9198
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2334 Acc: 0.9305
val Loss: 0.2706 Acc: 0.9195
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2309 Acc: 0.9316
val Loss: 0.2906 Acc: 0.9173
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2296 Acc: 0.9322
val Loss: 0.2510 Acc: 0.9277
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2021 Acc: 0.9410
val Loss: 0.2337 Acc: 0.9320
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1926 Acc: 0.9434
val Loss: 0.2319 Acc: 0.9327
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1919 Acc: 0.9442
val Loss: 0.2266 Acc: 0.9333
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1874 Acc: 0.9449
val Loss: 0.2303 Acc: 0.9326
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1868 Acc: 0.9446
val Loss: 0.2305 Acc: 0.9336
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1870 Acc: 0.9460
val Loss: 0.2294 Acc: 0.9327
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1877 Acc: 0.9450
val Loss: 0.2277 Acc: 0.9362
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1876 Acc: 0.9455
val Loss: 0.2295 Acc: 0.9349
Epoch finished in 0m 12s
Best validation accuracy: 0.9348585781369444
Model Test Accuracy:  0.9415719114935464
Pruning Epoch 15
++++++++++++++++++
number of weights to prune:  2354.0
Sparsity of Pruned Mask:  tensor(0.9648)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.0061 Acc: 0.2885
val Loss: 0.8966 Acc: 0.7067
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5054 Acc: 0.8398
val Loss: 0.3766 Acc: 0.8829
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3435 Acc: 0.8955
val Loss: 0.3637 Acc: 0.8953
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2950 Acc: 0.9123
val Loss: 0.3446 Acc: 0.9080
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2816 Acc: 0.9164
val Loss: 0.3080 Acc: 0.9106
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2687 Acc: 0.9210
val Loss: 0.2786 Acc: 0.9181
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2591 Acc: 0.9234
val Loss: 0.2971 Acc: 0.9126
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2609 Acc: 0.9228
val Loss: 0.3004 Acc: 0.9125
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2542 Acc: 0.9249
val Loss: 0.3085 Acc: 0.9117
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2539 Acc: 0.9249
val Loss: 0.2919 Acc: 0.9174
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2536 Acc: 0.9238
val Loss: 0.3247 Acc: 0.9118
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2525 Acc: 0.9243
val Loss: 0.2957 Acc: 0.9124
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2506 Acc: 0.9256
val Loss: 0.2735 Acc: 0.9201
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2435 Acc: 0.9274
val Loss: 0.2844 Acc: 0.9157
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2447 Acc: 0.9281
val Loss: 0.3123 Acc: 0.9091
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2443 Acc: 0.9277
val Loss: 0.3040 Acc: 0.9091
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2452 Acc: 0.9278
val Loss: 0.2556 Acc: 0.9246
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2173 Acc: 0.9359
val Loss: 0.2424 Acc: 0.9297
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2079 Acc: 0.9392
val Loss: 0.2431 Acc: 0.9304
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2056 Acc: 0.9401
val Loss: 0.2374 Acc: 0.9316
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2038 Acc: 0.9406
val Loss: 0.2386 Acc: 0.9316
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2012 Acc: 0.9411
val Loss: 0.2367 Acc: 0.9323
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2035 Acc: 0.9402
val Loss: 0.2370 Acc: 0.9320
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2008 Acc: 0.9409
val Loss: 0.2370 Acc: 0.9323
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2011 Acc: 0.9416
val Loss: 0.2370 Acc: 0.9307
Epoch finished in 0m 12s
Best validation accuracy: 0.9307087474063558
Model Test Accuracy:  0.9402274124154886
Pruning Epoch 16
++++++++++++++++++
number of weights to prune:  1883.0
Sparsity of Pruned Mask:  tensor(0.9719)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1268 Acc: 0.2444
val Loss: 1.2383 Acc: 0.5852
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5703 Acc: 0.8214
val Loss: 0.3832 Acc: 0.8822
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3596 Acc: 0.8912
val Loss: 0.3424 Acc: 0.8952
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3147 Acc: 0.9045
val Loss: 0.3477 Acc: 0.9028
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2991 Acc: 0.9106
val Loss: 0.3675 Acc: 0.8932
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2899 Acc: 0.9146
val Loss: 0.3059 Acc: 0.9058
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2775 Acc: 0.9170
val Loss: 0.3350 Acc: 0.8989
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2722 Acc: 0.9189
val Loss: 0.3452 Acc: 0.8962
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2704 Acc: 0.9194
val Loss: 0.2930 Acc: 0.9116
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2678 Acc: 0.9198
val Loss: 0.3240 Acc: 0.9110
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2641 Acc: 0.9207
val Loss: 0.3021 Acc: 0.9131
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2614 Acc: 0.9225
val Loss: 0.3320 Acc: 0.8989
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2637 Acc: 0.9213
val Loss: 0.3214 Acc: 0.9072
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2589 Acc: 0.9227
val Loss: 0.3258 Acc: 0.9140
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2579 Acc: 0.9235
val Loss: 0.3020 Acc: 0.9120
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2571 Acc: 0.9235
val Loss: 0.3346 Acc: 0.8992
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2545 Acc: 0.9240
val Loss: 0.2708 Acc: 0.9224
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2276 Acc: 0.9322
val Loss: 0.2514 Acc: 0.9273
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2209 Acc: 0.9344
val Loss: 0.2484 Acc: 0.9279
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2200 Acc: 0.9352
val Loss: 0.2436 Acc: 0.9286
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2153 Acc: 0.9364
val Loss: 0.2484 Acc: 0.9274
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2156 Acc: 0.9364
val Loss: 0.2454 Acc: 0.9285
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2146 Acc: 0.9370
val Loss: 0.2463 Acc: 0.9289
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2173 Acc: 0.9362
val Loss: 0.2454 Acc: 0.9291
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2139 Acc: 0.9372
val Loss: 0.2451 Acc: 0.9275
Epoch finished in 0m 12s
Best validation accuracy: 0.9274871682865568
Model Test Accuracy:  0.9348110018438843
Pruning Epoch 17
++++++++++++++++++
number of weights to prune:  1506.0
Sparsity of Pruned Mask:  tensor(0.9775)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1652 Acc: 0.2363
val Loss: 1.6465 Acc: 0.4377
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.6729 Acc: 0.7833
val Loss: 0.4192 Acc: 0.8697
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3847 Acc: 0.8842
val Loss: 0.3775 Acc: 0.8834
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3409 Acc: 0.8974
val Loss: 0.3461 Acc: 0.8956
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3148 Acc: 0.9049
val Loss: 0.3389 Acc: 0.8975
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3051 Acc: 0.9083
val Loss: 0.3559 Acc: 0.8946
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2957 Acc: 0.9097
val Loss: 0.3818 Acc: 0.9041
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2926 Acc: 0.9123
val Loss: 0.3908 Acc: 0.8975
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2865 Acc: 0.9142
val Loss: 0.3078 Acc: 0.9077
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2854 Acc: 0.9149
val Loss: 0.3425 Acc: 0.9017
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2801 Acc: 0.9166
val Loss: 0.3353 Acc: 0.9040
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2801 Acc: 0.9155
val Loss: 0.3232 Acc: 0.9030
Epoch finished in 0m 13s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2753 Acc: 0.9193
val Loss: 0.3000 Acc: 0.9121
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2748 Acc: 0.9177
val Loss: 0.3039 Acc: 0.9092
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2726 Acc: 0.9188
val Loss: 0.3138 Acc: 0.9060
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2740 Acc: 0.9182
val Loss: 0.3181 Acc: 0.9112
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2717 Acc: 0.9200
val Loss: 0.2801 Acc: 0.9193
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2453 Acc: 0.9269
val Loss: 0.2592 Acc: 0.9248
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2344 Acc: 0.9307
val Loss: 0.2593 Acc: 0.9246
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2310 Acc: 0.9315
val Loss: 0.2570 Acc: 0.9245
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2307 Acc: 0.9317
val Loss: 0.2545 Acc: 0.9262
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2273 Acc: 0.9331
val Loss: 0.2541 Acc: 0.9268
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2296 Acc: 0.9317
val Loss: 0.2553 Acc: 0.9268
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2274 Acc: 0.9329
val Loss: 0.2568 Acc: 0.9246
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2284 Acc: 0.9325
val Loss: 0.2556 Acc: 0.9277
Epoch finished in 0m 12s
Best validation accuracy: 0.927705580430272
Model Test Accuracy:  0.9310079901659495
Pruning Epoch 18
++++++++++++++++++
number of weights to prune:  1205.0
Sparsity of Pruned Mask:  tensor(0.9820)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1893 Acc: 0.2212
val Loss: 1.7384 Acc: 0.3970
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.7407 Acc: 0.7598
val Loss: 0.4872 Acc: 0.8513
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4109 Acc: 0.8737
val Loss: 0.3975 Acc: 0.8871
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3581 Acc: 0.8910
val Loss: 0.3524 Acc: 0.8945
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3413 Acc: 0.8977
val Loss: 0.3666 Acc: 0.8901
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3302 Acc: 0.9018
val Loss: 0.3249 Acc: 0.9003
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3207 Acc: 0.9043
val Loss: 0.3485 Acc: 0.9002
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3080 Acc: 0.9071
val Loss: 0.3282 Acc: 0.9028
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3042 Acc: 0.9098
val Loss: 0.3514 Acc: 0.8961
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3045 Acc: 0.9082
val Loss: 0.3545 Acc: 0.9044
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2983 Acc: 0.9111
val Loss: 0.3189 Acc: 0.9071
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2976 Acc: 0.9114
val Loss: 0.3421 Acc: 0.8985
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2943 Acc: 0.9127
val Loss: 0.3244 Acc: 0.9052
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2923 Acc: 0.9119
val Loss: 0.3199 Acc: 0.9062
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2890 Acc: 0.9140
val Loss: 0.3128 Acc: 0.9135
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2886 Acc: 0.9145
val Loss: 0.3199 Acc: 0.9097
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2837 Acc: 0.9161
val Loss: 0.2794 Acc: 0.9185
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2606 Acc: 0.9224
val Loss: 0.2703 Acc: 0.9209
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2493 Acc: 0.9258
val Loss: 0.2647 Acc: 0.9231
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2460 Acc: 0.9275
val Loss: 0.2607 Acc: 0.9236
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2438 Acc: 0.9281
val Loss: 0.2629 Acc: 0.9232
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2429 Acc: 0.9281
val Loss: 0.2611 Acc: 0.9236
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2436 Acc: 0.9275
val Loss: 0.2643 Acc: 0.9222
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2441 Acc: 0.9272
val Loss: 0.2607 Acc: 0.9237
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2401 Acc: 0.9296
val Loss: 0.2661 Acc: 0.9230
Epoch finished in 0m 12s
Best validation accuracy: 0.9230097193403953
Model Test Accuracy:  0.9313537185003072
Pruning Epoch 19
++++++++++++++++++
number of weights to prune:  963.0
Sparsity of Pruned Mask:  tensor(0.9856)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2242 Acc: 0.2017
val Loss: 2.0016 Acc: 0.2961
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.0429 Acc: 0.6494
val Loss: 0.5517 Acc: 0.8230
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4903 Acc: 0.8494
val Loss: 0.4981 Acc: 0.8526
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4137 Acc: 0.8732
val Loss: 0.4047 Acc: 0.8728
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3805 Acc: 0.8835
val Loss: 0.3830 Acc: 0.8836
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3599 Acc: 0.8908
val Loss: 0.3831 Acc: 0.8823
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3452 Acc: 0.8961
val Loss: 0.3514 Acc: 0.8938
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3344 Acc: 0.9002
val Loss: 0.3620 Acc: 0.8923
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3302 Acc: 0.9008
val Loss: 0.3330 Acc: 0.9007
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3270 Acc: 0.9021
val Loss: 0.3361 Acc: 0.9000
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3180 Acc: 0.9037
val Loss: 0.3496 Acc: 0.8970
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3160 Acc: 0.9056
val Loss: 0.3441 Acc: 0.8977
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3117 Acc: 0.9064
val Loss: 0.4123 Acc: 0.8890
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3091 Acc: 0.9085
val Loss: 0.3530 Acc: 0.9012
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3079 Acc: 0.9077
val Loss: 0.3195 Acc: 0.9025
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3039 Acc: 0.9089
val Loss: 0.3221 Acc: 0.9062
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2999 Acc: 0.9107
val Loss: 0.2968 Acc: 0.9113
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2737 Acc: 0.9184
val Loss: 0.2815 Acc: 0.9157
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2625 Acc: 0.9228
val Loss: 0.2717 Acc: 0.9186
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2594 Acc: 0.9232
val Loss: 0.2776 Acc: 0.9176
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2602 Acc: 0.9230
val Loss: 0.2771 Acc: 0.9166
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2595 Acc: 0.9236
val Loss: 0.2741 Acc: 0.9195
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2588 Acc: 0.9234
val Loss: 0.2701 Acc: 0.9210
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2583 Acc: 0.9234
val Loss: 0.2727 Acc: 0.9182
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2556 Acc: 0.9237
val Loss: 0.2767 Acc: 0.9185
Epoch finished in 0m 12s
Best validation accuracy: 0.9184776673583052
Model Test Accuracy:  0.9250537799631222
Pruning Epoch 20
++++++++++++++++++
number of weights to prune:  771.0
Sparsity of Pruned Mask:  tensor(0.9885)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2467 Acc: 0.1831
val Loss: 2.1143 Acc: 0.2664
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.1965 Acc: 0.5942
val Loss: 0.6190 Acc: 0.8110
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.5238 Acc: 0.8379
val Loss: 0.4860 Acc: 0.8500
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4401 Acc: 0.8645
val Loss: 0.4984 Acc: 0.8413
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4117 Acc: 0.8749
val Loss: 0.4543 Acc: 0.8625
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3855 Acc: 0.8839
val Loss: 0.3938 Acc: 0.8788
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3794 Acc: 0.8860
val Loss: 0.3753 Acc: 0.8890
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3606 Acc: 0.8910
val Loss: 0.3974 Acc: 0.8844
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3551 Acc: 0.8945
val Loss: 0.3726 Acc: 0.8930
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3482 Acc: 0.8952
val Loss: 0.3809 Acc: 0.8838
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3406 Acc: 0.8966
val Loss: 0.3833 Acc: 0.8893
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3340 Acc: 0.9006
val Loss: 0.3490 Acc: 0.8947
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3328 Acc: 0.9003
val Loss: 0.3976 Acc: 0.8866
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3301 Acc: 0.9006
val Loss: 0.3931 Acc: 0.8798
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3278 Acc: 0.9015
val Loss: 0.3473 Acc: 0.8960
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3246 Acc: 0.9029
val Loss: 0.4073 Acc: 0.8757
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3148 Acc: 0.9055
val Loss: 0.3048 Acc: 0.9089
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2859 Acc: 0.9143
val Loss: 0.2960 Acc: 0.9143
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2790 Acc: 0.9158
val Loss: 0.2910 Acc: 0.9139
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2768 Acc: 0.9172
val Loss: 0.2942 Acc: 0.9129
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2725 Acc: 0.9177
val Loss: 0.2927 Acc: 0.9133
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2767 Acc: 0.9172
val Loss: 0.2868 Acc: 0.9139
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2737 Acc: 0.9178
val Loss: 0.2865 Acc: 0.9149
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2719 Acc: 0.9190
val Loss: 0.2860 Acc: 0.9163
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2732 Acc: 0.9186
val Loss: 0.2911 Acc: 0.9142
Epoch finished in 0m 12s
Best validation accuracy: 0.9141640275199301
Model Test Accuracy:  0.9214044253226797
Pruning Epoch 21
++++++++++++++++++
number of weights to prune:  616.0
Sparsity of Pruned Mask:  tensor(0.9908)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2362 Acc: 0.1919
val Loss: 2.0711 Acc: 0.2826
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.2853 Acc: 0.5590
val Loss: 0.6807 Acc: 0.7804
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.5770 Acc: 0.8191
val Loss: 0.5318 Acc: 0.8356
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4814 Acc: 0.8516
val Loss: 0.4512 Acc: 0.8588
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4471 Acc: 0.8649
val Loss: 0.4733 Acc: 0.8552
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4221 Acc: 0.8725
val Loss: 0.4378 Acc: 0.8685
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4039 Acc: 0.8775
val Loss: 0.3988 Acc: 0.8771
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3897 Acc: 0.8815
val Loss: 0.5450 Acc: 0.8668
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3793 Acc: 0.8855
val Loss: 0.3908 Acc: 0.8809
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3732 Acc: 0.8876
val Loss: 0.4563 Acc: 0.8600
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3665 Acc: 0.8890
val Loss: 0.4251 Acc: 0.8783
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3609 Acc: 0.8906
val Loss: 0.3868 Acc: 0.8784
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3582 Acc: 0.8911
val Loss: 0.4076 Acc: 0.8746
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3535 Acc: 0.8925
val Loss: 0.3640 Acc: 0.8899
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3513 Acc: 0.8934
val Loss: 0.3835 Acc: 0.8843
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3528 Acc: 0.8932
val Loss: 0.3485 Acc: 0.8948
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3410 Acc: 0.8970
val Loss: 0.3227 Acc: 0.9043
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3120 Acc: 0.9062
val Loss: 0.3166 Acc: 0.9058
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3019 Acc: 0.9097
val Loss: 0.3087 Acc: 0.9092
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2975 Acc: 0.9105
val Loss: 0.3081 Acc: 0.9085
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2994 Acc: 0.9103
val Loss: 0.3103 Acc: 0.9084
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2978 Acc: 0.9119
val Loss: 0.3086 Acc: 0.9084
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2989 Acc: 0.9097
val Loss: 0.3076 Acc: 0.9111
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2982 Acc: 0.9115
val Loss: 0.3069 Acc: 0.9090
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2971 Acc: 0.9123
val Loss: 0.3063 Acc: 0.9085
Epoch finished in 0m 12s
Best validation accuracy: 0.908539914819264
Model Test Accuracy:  0.9125691456668714
Pruning Epoch 22
++++++++++++++++++
number of weights to prune:  493.0
Sparsity of Pruned Mask:  tensor(0.9926)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2529 Acc: 0.1787
val Loss: 2.1836 Acc: 0.2441
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.6257 Acc: 0.4343
val Loss: 0.9125 Acc: 0.6979
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.6826 Acc: 0.7810
val Loss: 0.6076 Acc: 0.8064
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5551 Acc: 0.8265
val Loss: 0.5525 Acc: 0.8289
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5005 Acc: 0.8452
val Loss: 0.4791 Acc: 0.8524
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4652 Acc: 0.8570
val Loss: 0.4844 Acc: 0.8497
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4481 Acc: 0.8639
val Loss: 0.4419 Acc: 0.8631
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4308 Acc: 0.8690
val Loss: 0.4806 Acc: 0.8553
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4141 Acc: 0.8745
val Loss: 0.5166 Acc: 0.8637
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4109 Acc: 0.8747
val Loss: 0.4645 Acc: 0.8555
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3960 Acc: 0.8801
val Loss: 0.4171 Acc: 0.8740
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3888 Acc: 0.8831
val Loss: 0.4099 Acc: 0.8828
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3886 Acc: 0.8838
val Loss: 0.4407 Acc: 0.8686
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3797 Acc: 0.8845
val Loss: 0.4434 Acc: 0.8643
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3771 Acc: 0.8867
val Loss: 0.4189 Acc: 0.8756
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3774 Acc: 0.8856
val Loss: 0.4130 Acc: 0.8807
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3609 Acc: 0.8913
val Loss: 0.3427 Acc: 0.8949
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3314 Acc: 0.8999
val Loss: 0.3330 Acc: 0.9010
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3267 Acc: 0.9016
val Loss: 0.3296 Acc: 0.9013
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3210 Acc: 0.9028
val Loss: 0.3229 Acc: 0.9020
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3201 Acc: 0.9045
val Loss: 0.3300 Acc: 0.9013
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3182 Acc: 0.9045
val Loss: 0.3259 Acc: 0.9043
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3160 Acc: 0.9045
val Loss: 0.3254 Acc: 0.9035
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3162 Acc: 0.9053
val Loss: 0.3272 Acc: 0.9037
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3161 Acc: 0.9046
val Loss: 0.3304 Acc: 0.9016
Epoch finished in 0m 12s
Best validation accuracy: 0.9016053292563067
Model Test Accuracy:  0.9095344191763982
Pruning Epoch 23
++++++++++++++++++
number of weights to prune:  394.0
Sparsity of Pruned Mask:  tensor(0.9941)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2634 Acc: 0.1698
val Loss: 2.2221 Acc: 0.2031
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.9073 Acc: 0.3286
val Loss: 1.2497 Acc: 0.6028
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.7847 Acc: 0.7424
val Loss: 0.7115 Acc: 0.7727
Epoch finished in 0m 13s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5915 Acc: 0.8148
val Loss: 0.5592 Acc: 0.8292
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5390 Acc: 0.8306
val Loss: 0.5446 Acc: 0.8294
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4942 Acc: 0.8445
val Loss: 0.5216 Acc: 0.8392
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4793 Acc: 0.8506
val Loss: 0.5653 Acc: 0.8272
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4602 Acc: 0.8594
val Loss: 0.4804 Acc: 0.8504
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4471 Acc: 0.8633
val Loss: 0.5039 Acc: 0.8558
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4360 Acc: 0.8649
val Loss: 0.4809 Acc: 0.8484
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.4298 Acc: 0.8691
val Loss: 0.4574 Acc: 0.8610
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.4227 Acc: 0.8698
val Loss: 0.5005 Acc: 0.8556
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.4173 Acc: 0.8742
val Loss: 0.5049 Acc: 0.8475
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.4163 Acc: 0.8730
val Loss: 0.4245 Acc: 0.8729
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.4075 Acc: 0.8753
val Loss: 0.4900 Acc: 0.8596
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.4047 Acc: 0.8777
val Loss: 0.4309 Acc: 0.8680
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3941 Acc: 0.8798
val Loss: 0.3779 Acc: 0.8828
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3572 Acc: 0.8914
val Loss: 0.3605 Acc: 0.8908
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3487 Acc: 0.8940
val Loss: 0.3540 Acc: 0.8945
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3472 Acc: 0.8951
val Loss: 0.3512 Acc: 0.8954
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3455 Acc: 0.8953
val Loss: 0.3518 Acc: 0.8948
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3461 Acc: 0.8939
val Loss: 0.3491 Acc: 0.8965
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3441 Acc: 0.8957
val Loss: 0.3537 Acc: 0.8946
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3441 Acc: 0.8951
val Loss: 0.3543 Acc: 0.8919
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3451 Acc: 0.8951
val Loss: 0.3497 Acc: 0.8941
Epoch finished in 0m 12s
Best validation accuracy: 0.8941247133340614
Model Test Accuracy:  0.895858942839582
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2704 Acc: 0.1508
val Loss: 2.1643 Acc: 0.2331
Epoch finished in 3m 3s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.6324 Acc: 0.4314
val Loss: 1.5417 Acc: 0.5200
Epoch finished in 2m 28s
Training Epoch 2/24
********************
Warmup
train Loss: 0.6881 Acc: 0.7806
val Loss: 0.5600 Acc: 0.8204
Epoch finished in 0m 42s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4652 Acc: 0.8542
val Loss: 0.5633 Acc: 0.8577
Epoch finished in 0m 42s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3968 Acc: 0.8777
val Loss: 0.3921 Acc: 0.8783
Epoch finished in 0m 42s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3549 Acc: 0.8903
val Loss: 0.4632 Acc: 0.8842
Epoch finished in 0m 42s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3267 Acc: 0.9017
val Loss: 0.5010 Acc: 0.8965
Epoch finished in 0m 42s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3027 Acc: 0.9086
val Loss: 0.3067 Acc: 0.9096
Epoch finished in 0m 42s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2895 Acc: 0.9137
val Loss: 0.3011 Acc: 0.9125
Epoch finished in 0m 42s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2731 Acc: 0.9183
val Loss: 0.3441 Acc: 0.9003
Epoch finished in 0m 42s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2647 Acc: 0.9213
val Loss: 0.3222 Acc: 0.9105
Epoch finished in 0m 42s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2550 Acc: 0.9253
val Loss: 0.3605 Acc: 0.9116
Epoch finished in 0m 42s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2458 Acc: 0.9275
val Loss: 0.3191 Acc: 0.9077
Epoch finished in 0m 42s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2383 Acc: 0.9290
val Loss: 0.2939 Acc: 0.9141
Epoch finished in 0m 42s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2341 Acc: 0.9300
val Loss: 0.3262 Acc: 0.9165
Epoch finished in 0m 42s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2252 Acc: 0.9329
val Loss: 0.2856 Acc: 0.9251
Epoch finished in 0m 42s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2170 Acc: 0.9358
val Loss: 0.2371 Acc: 0.9334
Epoch finished in 0m 42s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1818 Acc: 0.9466
val Loss: 0.2280 Acc: 0.9360
Epoch finished in 0m 42s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1729 Acc: 0.9493
val Loss: 0.2226 Acc: 0.9373
Epoch finished in 0m 42s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1671 Acc: 0.9509
val Loss: 0.2219 Acc: 0.9376
Epoch finished in 0m 42s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1656 Acc: 0.9525
val Loss: 0.2203 Acc: 0.9380
Epoch finished in 0m 42s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1613 Acc: 0.9532
val Loss: 0.2207 Acc: 0.9384
Epoch finished in 0m 42s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1633 Acc: 0.9522
val Loss: 0.2182 Acc: 0.9390
Epoch finished in 0m 42s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1607 Acc: 0.9534
val Loss: 0.2214 Acc: 0.9383
Epoch finished in 0m 42s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1631 Acc: 0.9529
val Loss: 0.2220 Acc: 0.9391
Epoch finished in 0m 42s
Best validation accuracy: 0.9391176149393906
Before Pruning
++++++++++++++++++
Model Test Accuracy:  0.9442609096496619
Pruning Epoch 1
++++++++++++++++++
number of weights to prune:  53540.0
Sparsity of Pruned Mask:  tensor(0.2000)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.9090 Acc: 0.3058
val Loss: 1.2434 Acc: 0.5727
Epoch finished in 3m 4s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5670 Acc: 0.8213
val Loss: 0.4845 Acc: 0.8581
Epoch finished in 2m 28s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3902 Acc: 0.8805
val Loss: 0.3984 Acc: 0.8844
Epoch finished in 0m 42s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3372 Acc: 0.8980
val Loss: 0.3769 Acc: 0.8868
Epoch finished in 0m 42s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3080 Acc: 0.9072
val Loss: 0.3539 Acc: 0.9029
Epoch finished in 0m 42s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2810 Acc: 0.9166
val Loss: 0.3447 Acc: 0.9027
Epoch finished in 0m 42s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2730 Acc: 0.9188
val Loss: 0.3078 Acc: 0.9083
Epoch finished in 0m 42s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2550 Acc: 0.9241
val Loss: 0.4134 Acc: 0.9080
Epoch finished in 0m 42s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2478 Acc: 0.9252
val Loss: 0.2903 Acc: 0.9173
Epoch finished in 0m 42s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2350 Acc: 0.9313
val Loss: 0.2999 Acc: 0.9160
Epoch finished in 0m 42s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2306 Acc: 0.9313
val Loss: 0.2904 Acc: 0.9160
Epoch finished in 0m 42s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2257 Acc: 0.9343
val Loss: 0.2784 Acc: 0.9169
Epoch finished in 0m 42s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2210 Acc: 0.9352
val Loss: 0.3050 Acc: 0.9120
Epoch finished in 0m 42s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2133 Acc: 0.9381
val Loss: 0.2704 Acc: 0.9242
Epoch finished in 0m 42s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2077 Acc: 0.9389
val Loss: 0.2722 Acc: 0.9231
Epoch finished in 0m 42s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2059 Acc: 0.9389
val Loss: 0.2598 Acc: 0.9291
Epoch finished in 0m 42s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2011 Acc: 0.9401
val Loss: 0.2412 Acc: 0.9304
Epoch finished in 0m 42s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1711 Acc: 0.9498
val Loss: 0.2237 Acc: 0.9374
Epoch finished in 0m 42s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1603 Acc: 0.9535
val Loss: 0.2196 Acc: 0.9403
Epoch finished in 0m 42s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1543 Acc: 0.9561
val Loss: 0.2160 Acc: 0.9409
Epoch finished in 0m 42s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1489 Acc: 0.9571
val Loss: 0.2137 Acc: 0.9411
Epoch finished in 0m 42s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1508 Acc: 0.9568
val Loss: 0.2189 Acc: 0.9392
Epoch finished in 0m 42s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1494 Acc: 0.9562
val Loss: 0.2177 Acc: 0.9399
Epoch finished in 0m 42s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1495 Acc: 0.9566
val Loss: 0.2177 Acc: 0.9386
Epoch finished in 0m 42s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1484 Acc: 0.9570
val Loss: 0.2152 Acc: 0.9402
Epoch finished in 0m 42s
Best validation accuracy: 0.9401550726220378
Model Test Accuracy:  0.9451060233558696
Pruning Epoch 2
++++++++++++++++++
number of weights to prune:  42831.0
Sparsity of Pruned Mask:  tensor(0.3600)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.4981 Acc: 0.4777
val Loss: 0.5993 Acc: 0.8224
Epoch finished in 3m 3s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4058 Acc: 0.8770
val Loss: 0.4300 Acc: 0.8787
Epoch finished in 2m 28s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3092 Acc: 0.9069
val Loss: 0.4266 Acc: 0.9005
Epoch finished in 0m 42s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2763 Acc: 0.9178
val Loss: 0.2927 Acc: 0.9152
Epoch finished in 0m 42s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2571 Acc: 0.9240
val Loss: 0.3074 Acc: 0.9095
Epoch finished in 0m 42s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2453 Acc: 0.9286
val Loss: 0.2927 Acc: 0.9177
Epoch finished in 0m 42s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2331 Acc: 0.9315
val Loss: 0.3652 Acc: 0.9162
Epoch finished in 0m 42s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2236 Acc: 0.9332
val Loss: 0.3241 Acc: 0.9141
Epoch finished in 0m 42s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2191 Acc: 0.9358
val Loss: 0.2608 Acc: 0.9259
Epoch finished in 0m 42s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2130 Acc: 0.9376
val Loss: 0.2559 Acc: 0.9265
Epoch finished in 0m 42s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2059 Acc: 0.9382
val Loss: 0.2833 Acc: 0.9249
Epoch finished in 0m 42s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2034 Acc: 0.9392
val Loss: 0.2548 Acc: 0.9256
Epoch finished in 0m 42s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2011 Acc: 0.9416
val Loss: 0.2454 Acc: 0.9303
Epoch finished in 0m 42s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1954 Acc: 0.9424
val Loss: 0.2613 Acc: 0.9244
Epoch finished in 0m 42s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1940 Acc: 0.9438
val Loss: 0.2628 Acc: 0.9266
Epoch finished in 0m 42s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1879 Acc: 0.9443
val Loss: 0.2444 Acc: 0.9298
Epoch finished in 0m 42s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1858 Acc: 0.9457
val Loss: 0.2314 Acc: 0.9344
Epoch finished in 0m 42s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1563 Acc: 0.9535
val Loss: 0.2172 Acc: 0.9390
Epoch finished in 0m 42s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1470 Acc: 0.9562
val Loss: 0.2171 Acc: 0.9410
Epoch finished in 0m 42s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1388 Acc: 0.9596
val Loss: 0.2152 Acc: 0.9405
Epoch finished in 0m 42s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1365 Acc: 0.9597
val Loss: 0.2181 Acc: 0.9407
Epoch finished in 0m 42s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1376 Acc: 0.9602
val Loss: 0.2157 Acc: 0.9399
Epoch finished in 0m 42s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1371 Acc: 0.9601
val Loss: 0.2154 Acc: 0.9406
Epoch finished in 0m 42s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1365 Acc: 0.9603
val Loss: 0.2153 Acc: 0.9409
Epoch finished in 0m 42s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1381 Acc: 0.9600
val Loss: 0.2129 Acc: 0.9410
Epoch finished in 0m 42s
Best validation accuracy: 0.9409741181609698
Model Test Accuracy:  0.9500230485556238
Pruning Epoch 3
++++++++++++++++++
number of weights to prune:  34265.0
Sparsity of Pruned Mask:  tensor(0.4880)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.2856 Acc: 0.5648
val Loss: 0.5655 Acc: 0.8375
Epoch finished in 3m 4s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3515 Acc: 0.8943
val Loss: 0.4311 Acc: 0.9006
Epoch finished in 2m 27s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2763 Acc: 0.9172
val Loss: 0.3102 Acc: 0.9072
Epoch finished in 0m 42s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2450 Acc: 0.9261
val Loss: 0.2989 Acc: 0.9175
Epoch finished in 0m 42s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2274 Acc: 0.9326
val Loss: 0.4126 Acc: 0.9129
Epoch finished in 0m 42s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2194 Acc: 0.9353
val Loss: 0.2656 Acc: 0.9233
Epoch finished in 0m 42s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2090 Acc: 0.9379
val Loss: 0.3020 Acc: 0.9222
Epoch finished in 0m 42s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2016 Acc: 0.9408
val Loss: 0.2629 Acc: 0.9243
Epoch finished in 0m 42s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1953 Acc: 0.9433
val Loss: 0.2642 Acc: 0.9233
Epoch finished in 0m 42s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1922 Acc: 0.9429
val Loss: 0.2617 Acc: 0.9301
Epoch finished in 0m 42s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1915 Acc: 0.9428
val Loss: 0.2779 Acc: 0.9273
Epoch finished in 0m 42s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1874 Acc: 0.9440
val Loss: 0.2446 Acc: 0.9296
Epoch finished in 0m 42s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1852 Acc: 0.9446
val Loss: 0.2423 Acc: 0.9290
Epoch finished in 0m 42s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1825 Acc: 0.9459
val Loss: 0.2540 Acc: 0.9256
Epoch finished in 0m 42s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1830 Acc: 0.9455
val Loss: 0.2773 Acc: 0.9240
Epoch finished in 0m 42s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1838 Acc: 0.9461
val Loss: 0.2478 Acc: 0.9321
Epoch finished in 0m 42s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1748 Acc: 0.9489
val Loss: 0.2330 Acc: 0.9343
Epoch finished in 0m 42s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1509 Acc: 0.9556
val Loss: 0.2196 Acc: 0.9397
Epoch finished in 0m 42s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1374 Acc: 0.9598
val Loss: 0.2167 Acc: 0.9412
Epoch finished in 0m 42s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1352 Acc: 0.9605
val Loss: 0.2150 Acc: 0.9410
Epoch finished in 0m 42s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1306 Acc: 0.9615
val Loss: 0.2165 Acc: 0.9395
Epoch finished in 0m 42s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1323 Acc: 0.9619
val Loss: 0.2141 Acc: 0.9422
Epoch finished in 0m 42s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1321 Acc: 0.9611
val Loss: 0.2173 Acc: 0.9415
Epoch finished in 0m 42s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1298 Acc: 0.9615
val Loss: 0.2182 Acc: 0.9415
Epoch finished in 0m 42s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1322 Acc: 0.9617
val Loss: 0.2127 Acc: 0.9438
Epoch finished in 0m 42s
Best validation accuracy: 0.9438134760292672
Model Test Accuracy:  0.9466041794714197
Pruning Epoch 4
++++++++++++++++++
number of weights to prune:  27412.0
Sparsity of Pruned Mask:  tensor(0.5904)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.1028 Acc: 0.6284
val Loss: 0.4096 Acc: 0.8740
Epoch finished in 3m 3s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3182 Acc: 0.9035
val Loss: 0.2963 Acc: 0.9121
Epoch finished in 2m 28s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2504 Acc: 0.9258
val Loss: 0.3271 Acc: 0.9154
Epoch finished in 0m 42s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2268 Acc: 0.9334
val Loss: 0.3155 Acc: 0.9244
Epoch finished in 0m 42s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2114 Acc: 0.9380
val Loss: 0.2686 Acc: 0.9218
Epoch finished in 0m 42s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2030 Acc: 0.9382
val Loss: 0.2600 Acc: 0.9289
Epoch finished in 0m 42s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1940 Acc: 0.9425
val Loss: 0.2606 Acc: 0.9271
Epoch finished in 0m 42s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1913 Acc: 0.9430
val Loss: 0.2732 Acc: 0.9226
Epoch finished in 0m 42s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1834 Acc: 0.9457
val Loss: 0.2667 Acc: 0.9298
Epoch finished in 0m 42s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1836 Acc: 0.9460
val Loss: 0.2507 Acc: 0.9279
Epoch finished in 0m 42s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1804 Acc: 0.9470
val Loss: 0.2846 Acc: 0.9284
Epoch finished in 0m 42s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1770 Acc: 0.9473
val Loss: 0.2697 Acc: 0.9211
Epoch finished in 0m 42s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1793 Acc: 0.9460
val Loss: 0.2609 Acc: 0.9271
Epoch finished in 0m 42s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1777 Acc: 0.9459
val Loss: 0.2699 Acc: 0.9247
Epoch finished in 0m 42s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1724 Acc: 0.9486
val Loss: 0.2526 Acc: 0.9281
Epoch finished in 0m 42s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1750 Acc: 0.9486
val Loss: 0.2534 Acc: 0.9292
Epoch finished in 0m 42s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1674 Acc: 0.9501
val Loss: 0.2269 Acc: 0.9360
Epoch finished in 0m 42s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1449 Acc: 0.9577
val Loss: 0.2250 Acc: 0.9387
Epoch finished in 0m 42s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1344 Acc: 0.9606
val Loss: 0.2196 Acc: 0.9405
Epoch finished in 0m 42s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1304 Acc: 0.9621
val Loss: 0.2191 Acc: 0.9401
Epoch finished in 0m 42s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1274 Acc: 0.9630
val Loss: 0.2182 Acc: 0.9417
Epoch finished in 0m 42s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1261 Acc: 0.9629
val Loss: 0.2169 Acc: 0.9416
Epoch finished in 0m 42s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1242 Acc: 0.9628
val Loss: 0.2205 Acc: 0.9408
Epoch finished in 0m 42s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1247 Acc: 0.9636
val Loss: 0.2162 Acc: 0.9432
Epoch finished in 0m 42s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1241 Acc: 0.9633
val Loss: 0.2187 Acc: 0.9410
Epoch finished in 0m 42s
Best validation accuracy: 0.9410287211968985
Model Test Accuracy:  0.9460663798401966
Pruning Epoch 5
++++++++++++++++++
number of weights to prune:  21929.0
Sparsity of Pruned Mask:  tensor(0.6723)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.0017 Acc: 0.6574
val Loss: 0.4829 Acc: 0.8841
Epoch finished in 3m 3s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3038 Acc: 0.9109
val Loss: 0.3723 Acc: 0.9125
Epoch finished in 2m 29s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2401 Acc: 0.9293
val Loss: 0.4052 Acc: 0.8892
Epoch finished in 0m 42s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2144 Acc: 0.9364
val Loss: 0.2828 Acc: 0.9169
Epoch finished in 0m 42s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2018 Acc: 0.9399
val Loss: 0.2638 Acc: 0.9270
Epoch finished in 0m 42s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1920 Acc: 0.9428
val Loss: 0.2716 Acc: 0.9285
Epoch finished in 0m 42s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1832 Acc: 0.9455
val Loss: 0.3077 Acc: 0.9145
Epoch finished in 0m 42s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1801 Acc: 0.9461
val Loss: 0.2563 Acc: 0.9280
Epoch finished in 0m 42s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1745 Acc: 0.9475
val Loss: 0.2694 Acc: 0.9232
Epoch finished in 0m 42s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1760 Acc: 0.9481
val Loss: 0.2907 Acc: 0.9227
Epoch finished in 0m 42s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1741 Acc: 0.9488
val Loss: 0.2532 Acc: 0.9298
Epoch finished in 0m 42s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1727 Acc: 0.9479
val Loss: 0.3150 Acc: 0.9217
Epoch finished in 0m 42s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1713 Acc: 0.9495
val Loss: 0.2949 Acc: 0.9190
Epoch finished in 0m 42s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1713 Acc: 0.9496
val Loss: 0.2328 Acc: 0.9365
Epoch finished in 0m 42s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1706 Acc: 0.9490
val Loss: 0.2682 Acc: 0.9277
Epoch finished in 0m 42s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1703 Acc: 0.9490
val Loss: 0.2457 Acc: 0.9322
Epoch finished in 0m 42s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1650 Acc: 0.9512
val Loss: 0.2343 Acc: 0.9351
Epoch finished in 0m 42s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1363 Acc: 0.9589
val Loss: 0.2209 Acc: 0.9406
Epoch finished in 0m 42s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1274 Acc: 0.9617
val Loss: 0.2187 Acc: 0.9441
Epoch finished in 0m 42s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1235 Acc: 0.9642
val Loss: 0.2168 Acc: 0.9426
Epoch finished in 0m 42s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1199 Acc: 0.9651
val Loss: 0.2218 Acc: 0.9409
Epoch finished in 0m 42s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1213 Acc: 0.9647
val Loss: 0.2199 Acc: 0.9435
Epoch finished in 0m 42s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1221 Acc: 0.9649
val Loss: 0.2186 Acc: 0.9429
Epoch finished in 0m 42s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1196 Acc: 0.9653
val Loss: 0.2162 Acc: 0.9433
Epoch finished in 0m 42s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1202 Acc: 0.9644
val Loss: 0.2178 Acc: 0.9421
Epoch finished in 0m 42s
Best validation accuracy: 0.9420661788795457
Model Test Accuracy:  0.9471035648432697
Pruning Epoch 6
++++++++++++++++++
number of weights to prune:  17543.0
Sparsity of Pruned Mask:  tensor(0.7379)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.0943 Acc: 0.6516
val Loss: 0.3718 Acc: 0.8883
Epoch finished in 3m 3s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.2976 Acc: 0.9099
val Loss: 0.3023 Acc: 0.9134
Epoch finished in 2m 27s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2361 Acc: 0.9297
val Loss: 0.3360 Acc: 0.9141
Epoch finished in 0m 42s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2108 Acc: 0.9362
val Loss: 0.3577 Acc: 0.9222
Epoch finished in 0m 42s
Training Epoch 4/24
********************
Warmup
train Loss: 0.1959 Acc: 0.9414
val Loss: 0.4034 Acc: 0.9262
Epoch finished in 0m 42s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1851 Acc: 0.9459
val Loss: 0.2481 Acc: 0.9277
Epoch finished in 0m 42s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1842 Acc: 0.9454
val Loss: 0.3281 Acc: 0.9188
Epoch finished in 0m 42s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1787 Acc: 0.9464
val Loss: 0.2779 Acc: 0.9271
Epoch finished in 0m 42s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1747 Acc: 0.9489
val Loss: 0.2745 Acc: 0.9300
Epoch finished in 0m 42s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1721 Acc: 0.9487
val Loss: 0.2330 Acc: 0.9331
Epoch finished in 0m 42s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1692 Acc: 0.9506
val Loss: 0.2583 Acc: 0.9297
Epoch finished in 0m 42s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1691 Acc: 0.9496
val Loss: 0.2632 Acc: 0.9323
Epoch finished in 0m 42s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1682 Acc: 0.9502
val Loss: 0.2575 Acc: 0.9289
Epoch finished in 0m 42s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1684 Acc: 0.9495
val Loss: 0.2578 Acc: 0.9304
Epoch finished in 0m 42s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1700 Acc: 0.9490
val Loss: 0.2854 Acc: 0.9248
Epoch finished in 0m 42s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1689 Acc: 0.9491
val Loss: 0.2566 Acc: 0.9300
Epoch finished in 0m 42s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1678 Acc: 0.9497
val Loss: 0.2386 Acc: 0.9320
Epoch finished in 0m 42s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1429 Acc: 0.9579
val Loss: 0.2205 Acc: 0.9394
Epoch finished in 0m 42s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1313 Acc: 0.9612
val Loss: 0.2255 Acc: 0.9416
Epoch finished in 0m 42s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1271 Acc: 0.9627
val Loss: 0.2249 Acc: 0.9409
Epoch finished in 0m 42s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1260 Acc: 0.9630
val Loss: 0.2269 Acc: 0.9398
Epoch finished in 0m 42s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1241 Acc: 0.9633
val Loss: 0.2203 Acc: 0.9405
Epoch finished in 0m 42s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1210 Acc: 0.9638
val Loss: 0.2242 Acc: 0.9413
Epoch finished in 0m 43s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1228 Acc: 0.9643
val Loss: 0.2219 Acc: 0.9417
Epoch finished in 0m 42s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1217 Acc: 0.9641
val Loss: 0.2220 Acc: 0.9415
Epoch finished in 0m 42s
Best validation accuracy: 0.9415201485202578
Model Test Accuracy:  0.9446834665027658
Pruning Epoch 7
++++++++++++++++++
number of weights to prune:  14034.0
Sparsity of Pruned Mask:  tensor(0.7903)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2645 Acc: 0.1643
val Loss: 2.2362 Acc: 0.1875
Epoch finished in 3m 8s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.2363 Acc: 0.1896
val Loss: 2.2366 Acc: 0.1873
Epoch finished in 2m 32s
Training Epoch 2/24
********************
Warmup
train Loss: 2.2363 Acc: 0.1895
val Loss: 2.2366 Acc: 0.1873
Epoch finished in 0m 42s
Training Epoch 3/24
********************
Warmup
train Loss: 2.2362 Acc: 0.1897
val Loss: 2.2373 Acc: 0.1874
Epoch finished in 0m 42s
Training Epoch 4/24
********************
Warmup
train Loss: 2.2362 Acc: 0.1896
val Loss: 2.2378 Acc: 0.1871
Epoch finished in 0m 42s
Training Epoch 5/24
********************
Warmup
train Loss: 2.2364 Acc: 0.1897
val Loss: 2.2365 Acc: 0.1875
Epoch finished in 0m 42s
Training Epoch 6/24
********************
Warmup
train Loss: 2.2361 Acc: 0.1897
val Loss: 2.2360 Acc: 0.1874
Epoch finished in 0m 42s
Training Epoch 7/24
********************
Warmup
train Loss: 2.2363 Acc: 0.1897
val Loss: 2.2365 Acc: 0.1873
Epoch finished in 0m 42s
Training Epoch 8/24
********************
Warmup
train Loss: 2.2360 Acc: 0.1897
val Loss: 2.2356 Acc: 0.1875
Epoch finished in 0m 42s
Training Epoch 9/24
********************
Warmup
train Loss: 2.2358 Acc: 0.1897
val Loss: 2.2379 Acc: 0.1875
Epoch finished in 0m 42s
Training Epoch 10/24
********************
Warmup
train Loss: 2.2360 Acc: 0.1896
val Loss: 2.2364 Acc: 0.1874
Epoch finished in 0m 42s
Training Epoch 11/24
********************
Warmup
train Loss: 2.2358 Acc: 0.1896
val Loss: 2.2357 Acc: 0.1875
Epoch finished in 0m 42s
Training Epoch 12/24
********************
Warmup
train Loss: 2.2357 Acc: 0.1897
val Loss: 2.2366 Acc: 0.1875
Epoch finished in 0m 42s
Training Epoch 13/24
********************
Warmup
train Loss: 2.2356 Acc: 0.1896
val Loss: 2.2361 Acc: 0.1874
Epoch finished in 0m 42s
Training Epoch 14/24
********************
Warmup
train Loss: 2.2355 Acc: 0.1897
val Loss: 2.2363 Acc: 0.1874
Epoch finished in 0m 42s
Training Epoch 15/24
********************
Warmup
train Loss: 2.2356 Acc: 0.1897
val Loss: 2.2361 Acc: 0.1873
Epoch finished in 0m 42s
Training Epoch 16/24
********************
Warmup
train Loss: 2.2356 Acc: 0.1896
val Loss: 2.2364 Acc: 0.1873
Epoch finished in 0m 42s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 2.2351 Acc: 0.1897
val Loss: 2.2361 Acc: 0.1875
Epoch finished in 0m 42s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 2.2349 Acc: 0.1897
val Loss: 2.2360 Acc: 0.1875
Epoch finished in 0m 42s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 2.2349 Acc: 0.1897
val Loss: 2.2359 Acc: 0.1875
Epoch finished in 0m 42s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 2.2348 Acc: 0.1897
val Loss: 2.2360 Acc: 0.1873
Epoch finished in 0m 42s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 2.2349 Acc: 0.1897
val Loss: 2.2358 Acc: 0.1875
Epoch finished in 0m 42s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 2.2349 Acc: 0.1896
val Loss: 2.2360 Acc: 0.1874
Epoch finished in 0m 42s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 2.2349 Acc: 0.1897
val Loss: 2.2360 Acc: 0.1873
Epoch finished in 0m 42s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 2.2348 Acc: 0.1897
val Loss: 2.2359 Acc: 0.1874
Epoch finished in 0m 42s
Best validation accuracy: 0.18739761930763352
Model Test Accuracy:  0.19549016594960048
conv_layer_1.weight
x:  16
y:  3
layer1.0.conv_layer_1.weight
x:  16
y:  16
layer1.0.conv_layer_2.weight
x:  16
y:  16
layer1.1.conv_layer_1.weight
x:  16
y:  16
layer1.1.conv_layer_2.weight
x:  16
y:  16
layer1.2.conv_layer_1.weight
x:  16
y:  16
layer1.2.conv_layer_2.weight
x:  16
y:  16
layer2.0.conv_layer_1.weight
x:  32
y:  16
layer2.0.conv_layer_2.weight
x:  32
y:  32
layer2.1.conv_layer_1.weight
x:  32
y:  32
layer2.1.conv_layer_2.weight
x:  32
y:  32
layer2.2.conv_layer_1.weight
x:  32
y:  32
layer2.2.conv_layer_2.weight
x:  32
y:  32
layer3.0.conv_layer_1.weight
x:  64
y:  32
layer3.0.conv_layer_2.weight
x:  64
y:  64
layer3.1.conv_layer_1.weight
x:  64
y:  64
layer3.1.conv_layer_2.weight
x:  64
y:  64
layer3.2.conv_layer_1.weight
x:  64
y:  64
layer3.2.conv_layer_2.weight
x:  64
y:  64
conv_layer_1.weight
24.88372093023256
x:  16
y:  3
layer1.0.conv_layer_1.weight
10.990443092962641
x:  16
y:  16
layer1.0.conv_layer_2.weight
7.949609035621199
x:  16
y:  16
layer1.1.conv_layer_1.weight
7.515204170286707
x:  16
y:  16
layer1.1.conv_layer_2.weight
7.167680278019114
x:  16
y:  16
layer1.2.conv_layer_1.weight
8.210251954821894
x:  16
y:  16
layer1.2.conv_layer_2.weight
8.166811468288445
x:  16
y:  16
layer2.0.conv_layer_1.weight
3.6039947894051236
x:  32
y:  16
layer2.0.conv_layer_2.weight
2.5830258302583027
x:  32
y:  32
layer2.1.conv_layer_1.weight
2.7132624267419145
x:  32
y:  32
layer2.1.conv_layer_2.weight
2.5613197308443674
x:  32
y:  32
layer2.2.conv_layer_1.weight
2.3334056869980464
x:  32
y:  32
layer2.2.conv_layer_2.weight
1.7256349034078575
x:  31
y:  32
layer3.0.conv_layer_1.weight
0.6239826370048833
x:  42
y:  28
layer3.0.conv_layer_2.weight
0.320112853344908
x:  48
y:  46
layer3.1.conv_layer_1.weight
0.41777440182301556
x:  42
y:  62
layer3.1.conv_layer_2.weight
0.19532309695621508
x:  25
y:  40
layer3.2.conv_layer_1.weight
0.13564103955292714
x:  22
y:  33
layer3.2.conv_layer_2.weight
0.027128207910585428
x:  9
y:  12
conv_layer_1.weight
14.186046511627907
x:  15
y:  3
layer1.0.conv_layer_1.weight
7.862728062554301
x:  16
y:  16
layer1.0.conv_layer_2.weight
4.387489139878366
x:  16
y:  16
layer1.1.conv_layer_1.weight
4.73501303214596
x:  16
y:  16
layer1.1.conv_layer_2.weight
4.344048653344918
x:  16
y:  16
layer1.2.conv_layer_1.weight
4.430929626411816
x:  16
y:  16
layer1.2.conv_layer_2.weight
3.649000868809731
x:  16
y:  16
layer2.0.conv_layer_1.weight
1.2375162831089883
x:  22
y:  15
layer2.0.conv_layer_2.weight
0.6945951812459301
x:  28
y:  25
layer2.1.conv_layer_1.weight
0.9333622747992186
x:  27
y:  32
layer2.1.conv_layer_2.weight
1.0310397221619274
x:  31
y:  27
layer2.2.conv_layer_1.weight
1.2481007163012807
x:  26
y:  31
layer2.2.conv_layer_2.weight
0.9767744736270892
x:  29
y:  27
layer3.0.conv_layer_1.weight
0.2658708627238199
x:  28
y:  23
layer3.0.conv_layer_2.weight
0.14920514350821984
x:  29
y:  28
layer3.1.conv_layer_1.weight
0.20888720091150778
x:  34
y:  44
layer3.1.conv_layer_2.weight
0.2522923335684445
x:  39
y:  41
layer3.2.conv_layer_1.weight
0.027128207910585428
x:  10
y:  10
layer3.2.conv_layer_2.weight
0.016276924746351257
x:  8
y:  7
conv_layer_1.weight
56.27906976744186
x:  16
y:  3
layer1.0.conv_layer_1.weight
52.69331016507385
x:  16
y:  16
layer1.0.conv_layer_2.weight
49.9131190269331
x:  16
y:  16
layer1.1.conv_layer_1.weight
50.52128583840139
x:  16
y:  16
layer1.1.conv_layer_2.weight
50.2606429192007
x:  16
y:  16
layer1.2.conv_layer_1.weight
51.04257167680278
x:  16
y:  16
layer1.2.conv_layer_2.weight
51.08601216333623
x:  16
y:  16
layer2.0.conv_layer_1.weight
35.75770733825445
x:  32
y:  16
layer2.0.conv_layer_2.weight
31.169958758411113
x:  32
y:  32
layer2.1.conv_layer_1.weight
33.19947905361406
x:  32
y:  32
layer2.1.conv_layer_2.weight
32.61341436943781
x:  32
y:  32
layer2.2.conv_layer_1.weight
32.049055784675495
x:  32
y:  32
layer2.2.conv_layer_2.weight
30.800955068374215
x:  32
y:  32
layer3.0.conv_layer_1.weight
16.174715138361368
x:  64
y:  32
layer3.0.conv_layer_2.weight
16.043622158320222
x:  64
y:  64
layer3.1.conv_layer_1.weight
16.021919591991754
x:  64
y:  64
layer3.1.conv_layer_2.weight
14.201616841191472
x:  64
y:  64
layer3.2.conv_layer_1.weight
15.324724648689708
x:  64
y:  64
layer3.2.conv_layer_2.weight
18.346807009928924
x:  64
y:  64
                         Layer 0      Layer 1  ...                       
                                 BasicBlock 0  ... BasicBlock 2          
                         conv. 0      conv. 0  ...      conv. 0   conv. 1
Original Model           [16, 3]     [16, 16]  ...     [64, 64]  [64, 64]
ReLU ResNet20            [16, 3]     [16, 16]  ...     [22, 33]   [9, 12]
univ. rational ResNet20  [15, 3]     [16, 16]  ...     [10, 10]    [8, 7]
mix. exp. ResNet20       [16, 3]     [16, 16]  ...     [64, 64]  [64, 64]

[4 rows x 19 columns]
                        Layer 0      Layer 1  ...                     
                                BasicBlock 0  ... BasicBlock 2        
                        conv. 0      conv. 0  ...      conv. 0 conv. 1
Original Model              430         2302  ...        36862   36862
ReLU ResNet20               107          253  ...           50      10
univ. rational ResNet20      61          181  ...           10       6
mix. exp. ResNet20          242         1213  ...         5649    6763

[4 rows x 19 columns]
                           Layer 0      Layer 1  ...                        
                                   BasicBlock 0  ... BasicBlock 2           
                           conv. 0      conv. 0  ...      conv. 0    conv. 1
ReLU ResNet20            24.883721    10.990443  ...     0.135641   0.027128
univ. rational ResNet20  14.186047     7.862728  ...     0.027128   0.016277
mix. exp. ResNet20       56.279070    52.693310  ...    15.324725  18.346807

[3 rows x 19 columns]
