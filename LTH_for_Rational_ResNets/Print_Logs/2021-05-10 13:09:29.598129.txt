Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac39a7910
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac39b3c80
    (shortcut): Sequential()
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6af363b320
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac39bd550
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac39bda00
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac39bde60
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac39cb370
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac39cb7d0
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac39cbc30
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac2755320
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac27557d0
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac2755c30
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac2755fa0
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac275e5a0
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac275ea50
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac275efa0
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac276e5a0
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f6ac276ea00
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac277b2d0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac277beb0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2788500
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2788410
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac27883c0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac277bf00
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac277bfa0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2788050
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2788640
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2788550
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac27887d0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2711460
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac27114b0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac27113c0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2711af0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2711410
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2711370
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac27112d0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2711c30
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2711fa0
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2711eb0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2720960
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac27209b0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2720e60
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac272c0f0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2720910
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2720870
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac27208c0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac272c370
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac272c280
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac272c4b0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac272cc30
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac272c730
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac273a0a0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac273a410
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac272ccd0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac272cd70
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac273a690
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac273a550
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac273a460
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac273a6e0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2743640
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2743690
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2743e60
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2743c30
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac27435f0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2743550
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac27434b0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2743d70
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26d03c0
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26d0190
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26d0140
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26d0af0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26dc190
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26dc550
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26d0be0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26d0c80
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26dc410
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26dc320
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26dc2d0
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26dc460
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26e8280
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26e82d0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26e81e0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26e88c0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26e8230
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26e8190
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26e80f0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26e8780
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26e8a00
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26e8c80
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26f29b0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26f2820
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2700370
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2700280
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26f2960
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26f28c0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac26f2910
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac27000f0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac27004b0
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2700230
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2700640
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac270b640
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac270b690
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac270b500
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2700f00
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac2700f50
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac270b140
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac270b0a0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f6ac270b7d0
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2523 Acc: 0.1853
val Loss: 2.2186 Acc: 0.1960
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 2.0473 Acc: 0.2724
val Loss: 1.9013 Acc: 0.3202
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 1.6277 Acc: 0.4282
val Loss: 1.3510 Acc: 0.5304
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 1.0261 Acc: 0.6591
val Loss: 0.7533 Acc: 0.7507
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.6156 Acc: 0.8026
val Loss: 0.5651 Acc: 0.8185
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4857 Acc: 0.8476
val Loss: 0.4578 Acc: 0.8564
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4167 Acc: 0.8703
val Loss: 0.4530 Acc: 0.8566
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3777 Acc: 0.8833
val Loss: 0.3920 Acc: 0.8773
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3504 Acc: 0.8921
val Loss: 0.3927 Acc: 0.8773
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3333 Acc: 0.8986
val Loss: 0.3844 Acc: 0.8796
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3163 Acc: 0.9042
val Loss: 0.3563 Acc: 0.8893
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3025 Acc: 0.9097
val Loss: 0.3028 Acc: 0.9095
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2947 Acc: 0.9099
val Loss: 0.3276 Acc: 0.8993
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2838 Acc: 0.9138
val Loss: 0.3087 Acc: 0.9065
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2757 Acc: 0.9159
val Loss: 0.2943 Acc: 0.9114
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2695 Acc: 0.9192
val Loss: 0.3347 Acc: 0.8987
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2646 Acc: 0.9215
val Loss: 0.2638 Acc: 0.9188
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2289 Acc: 0.9324
val Loss: 0.2412 Acc: 0.9294
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2197 Acc: 0.9346
val Loss: 0.2311 Acc: 0.9314
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2137 Acc: 0.9372
val Loss: 0.2320 Acc: 0.9325
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2096 Acc: 0.9386
val Loss: 0.2305 Acc: 0.9325
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2109 Acc: 0.9381
val Loss: 0.2322 Acc: 0.9303
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2094 Acc: 0.9385
val Loss: 0.2313 Acc: 0.9333
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2076 Acc: 0.9399
val Loss: 0.2325 Acc: 0.9316
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2080 Acc: 0.9390
val Loss: 0.2330 Acc: 0.9315
Epoch finished in 0m 9s
Best validation accuracy: 0.9315277929452878
Before Pruning
++++++++++++++++++
Model Test Accuracy:  0.9388829133374308
Pruning Epoch 1
++++++++++++++++++
number of weights to prune:  53540.0
Sparsity of Pruned Mask:  tensor(0.2000)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.1414 Acc: 0.2427
val Loss: 1.9320 Acc: 0.3136
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.5813 Acc: 0.4565
val Loss: 1.1926 Acc: 0.5917
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.7670 Acc: 0.7612
val Loss: 0.6000 Acc: 0.8042
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4877 Acc: 0.8471
val Loss: 0.4443 Acc: 0.8638
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4000 Acc: 0.8761
val Loss: 0.4457 Acc: 0.8587
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3626 Acc: 0.8884
val Loss: 0.3558 Acc: 0.8931
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3331 Acc: 0.8974
val Loss: 0.3597 Acc: 0.8903
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3190 Acc: 0.9016
val Loss: 0.3180 Acc: 0.9035
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3071 Acc: 0.9064
val Loss: 0.3495 Acc: 0.8927
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2949 Acc: 0.9106
val Loss: 0.3408 Acc: 0.8959
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2858 Acc: 0.9129
val Loss: 0.2975 Acc: 0.9110
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2751 Acc: 0.9163
val Loss: 0.3292 Acc: 0.9039
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2703 Acc: 0.9169
val Loss: 0.3793 Acc: 0.8825
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2613 Acc: 0.9213
val Loss: 0.2751 Acc: 0.9186
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2564 Acc: 0.9229
val Loss: 0.3148 Acc: 0.9047
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2512 Acc: 0.9249
val Loss: 0.2819 Acc: 0.9149
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2485 Acc: 0.9252
val Loss: 0.2495 Acc: 0.9259
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2150 Acc: 0.9367
val Loss: 0.2315 Acc: 0.9310
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2054 Acc: 0.9398
val Loss: 0.2307 Acc: 0.9311
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1990 Acc: 0.9414
val Loss: 0.2248 Acc: 0.9344
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1954 Acc: 0.9426
val Loss: 0.2257 Acc: 0.9346
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1954 Acc: 0.9434
val Loss: 0.2244 Acc: 0.9344
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1971 Acc: 0.9427
val Loss: 0.2228 Acc: 0.9346
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1952 Acc: 0.9440
val Loss: 0.2223 Acc: 0.9345
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1969 Acc: 0.9423
val Loss: 0.2256 Acc: 0.9331
Epoch finished in 0m 9s
Best validation accuracy: 0.933111280987223
Model Test Accuracy:  0.9424170251997541
Pruning Epoch 2
++++++++++++++++++
number of weights to prune:  42831.0
Sparsity of Pruned Mask:  tensor(0.3600)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.0044 Acc: 0.3053
val Loss: 1.6057 Acc: 0.4811
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.0060 Acc: 0.6981
val Loss: 0.5734 Acc: 0.8260
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4692 Acc: 0.8581
val Loss: 0.3915 Acc: 0.8830
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3658 Acc: 0.8886
val Loss: 0.3668 Acc: 0.8882
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3276 Acc: 0.9009
val Loss: 0.3388 Acc: 0.8976
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3049 Acc: 0.9084
val Loss: 0.3302 Acc: 0.9008
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2906 Acc: 0.9119
val Loss: 0.3086 Acc: 0.9068
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2789 Acc: 0.9167
val Loss: 0.2957 Acc: 0.9112
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2707 Acc: 0.9180
val Loss: 0.3262 Acc: 0.9009
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2674 Acc: 0.9188
val Loss: 0.2893 Acc: 0.9128
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2594 Acc: 0.9212
val Loss: 0.3082 Acc: 0.9059
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2520 Acc: 0.9234
val Loss: 0.2800 Acc: 0.9167
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2512 Acc: 0.9246
val Loss: 0.3034 Acc: 0.9067
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2443 Acc: 0.9268
val Loss: 0.2834 Acc: 0.9136
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2384 Acc: 0.9287
val Loss: 0.2894 Acc: 0.9139
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2370 Acc: 0.9287
val Loss: 0.3014 Acc: 0.9104
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2301 Acc: 0.9308
val Loss: 0.2446 Acc: 0.9268
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1986 Acc: 0.9410
val Loss: 0.2245 Acc: 0.9340
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1909 Acc: 0.9446
val Loss: 0.2199 Acc: 0.9367
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1869 Acc: 0.9453
val Loss: 0.2225 Acc: 0.9352
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1824 Acc: 0.9473
val Loss: 0.2155 Acc: 0.9390
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1825 Acc: 0.9472
val Loss: 0.2160 Acc: 0.9370
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1835 Acc: 0.9469
val Loss: 0.2176 Acc: 0.9363
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1843 Acc: 0.9469
val Loss: 0.2182 Acc: 0.9376
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1823 Acc: 0.9460
val Loss: 0.2180 Acc: 0.9375
Epoch finished in 0m 9s
Best validation accuracy: 0.9375341268974555
Model Test Accuracy:  0.9468346650276582
Pruning Epoch 3
++++++++++++++++++
number of weights to prune:  34265.0
Sparsity of Pruned Mask:  tensor(0.4880)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.8414 Acc: 0.3918
val Loss: 1.1829 Acc: 0.6850
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.6826 Acc: 0.8191
val Loss: 0.4361 Acc: 0.8750
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3839 Acc: 0.8867
val Loss: 0.3373 Acc: 0.8981
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3126 Acc: 0.9056
val Loss: 0.3095 Acc: 0.9068
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2915 Acc: 0.9105
val Loss: 0.2976 Acc: 0.9091
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2727 Acc: 0.9170
val Loss: 0.3013 Acc: 0.9072
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2638 Acc: 0.9203
val Loss: 0.2808 Acc: 0.9170
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2537 Acc: 0.9238
val Loss: 0.3150 Acc: 0.9048
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2490 Acc: 0.9247
val Loss: 0.2815 Acc: 0.9154
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2429 Acc: 0.9273
val Loss: 0.2751 Acc: 0.9174
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2418 Acc: 0.9285
val Loss: 0.2916 Acc: 0.9136
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2371 Acc: 0.9285
val Loss: 0.2823 Acc: 0.9153
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2309 Acc: 0.9302
val Loss: 0.2854 Acc: 0.9161
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2335 Acc: 0.9295
val Loss: 0.2746 Acc: 0.9172
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2314 Acc: 0.9308
val Loss: 0.2950 Acc: 0.9123
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2267 Acc: 0.9325
val Loss: 0.2755 Acc: 0.9182
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2191 Acc: 0.9352
val Loss: 0.2374 Acc: 0.9290
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1953 Acc: 0.9422
val Loss: 0.2224 Acc: 0.9342
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1831 Acc: 0.9465
val Loss: 0.2143 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1780 Acc: 0.9483
val Loss: 0.2161 Acc: 0.9374
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1756 Acc: 0.9493
val Loss: 0.2131 Acc: 0.9388
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1771 Acc: 0.9483
val Loss: 0.2105 Acc: 0.9387
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1746 Acc: 0.9491
val Loss: 0.2126 Acc: 0.9396
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1762 Acc: 0.9501
val Loss: 0.2109 Acc: 0.9397
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1749 Acc: 0.9495
val Loss: 0.2110 Acc: 0.9380
Epoch finished in 0m 9s
Best validation accuracy: 0.9379709511848859
Model Test Accuracy:  0.946220036877689
Pruning Epoch 4
++++++++++++++++++
number of weights to prune:  27412.0
Sparsity of Pruned Mask:  tensor(0.5904)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.7239 Acc: 0.4583
val Loss: 0.9709 Acc: 0.7638
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5721 Acc: 0.8533
val Loss: 0.3938 Acc: 0.8890
Epoch finished in 0m 10s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3476 Acc: 0.8992
val Loss: 0.3179 Acc: 0.9060
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2907 Acc: 0.9132
val Loss: 0.3413 Acc: 0.8969
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2671 Acc: 0.9203
val Loss: 0.2815 Acc: 0.9144
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2572 Acc: 0.9232
val Loss: 0.2923 Acc: 0.9111
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2473 Acc: 0.9248
val Loss: 0.2638 Acc: 0.9200
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2391 Acc: 0.9284
val Loss: 0.2659 Acc: 0.9184
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2368 Acc: 0.9287
val Loss: 0.2768 Acc: 0.9153
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2334 Acc: 0.9287
val Loss: 0.2740 Acc: 0.9192
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2294 Acc: 0.9314
val Loss: 0.2631 Acc: 0.9207
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2265 Acc: 0.9321
val Loss: 0.2610 Acc: 0.9230
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2217 Acc: 0.9344
val Loss: 0.2799 Acc: 0.9152
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2195 Acc: 0.9340
val Loss: 0.2671 Acc: 0.9216
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2207 Acc: 0.9338
val Loss: 0.2706 Acc: 0.9203
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2183 Acc: 0.9346
val Loss: 0.2754 Acc: 0.9196
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2191 Acc: 0.9352
val Loss: 0.2357 Acc: 0.9296
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1923 Acc: 0.9440
val Loss: 0.2213 Acc: 0.9360
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1779 Acc: 0.9482
val Loss: 0.2158 Acc: 0.9363
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1741 Acc: 0.9502
val Loss: 0.2124 Acc: 0.9376
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1706 Acc: 0.9508
val Loss: 0.2178 Acc: 0.9370
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1721 Acc: 0.9504
val Loss: 0.2093 Acc: 0.9402
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1720 Acc: 0.9511
val Loss: 0.2136 Acc: 0.9372
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1710 Acc: 0.9510
val Loss: 0.2162 Acc: 0.9372
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1702 Acc: 0.9514
val Loss: 0.2129 Acc: 0.9390
Epoch finished in 0m 9s
Best validation accuracy: 0.939008408867533
Model Test Accuracy:  0.9462968653964351
Pruning Epoch 5
++++++++++++++++++
number of weights to prune:  21929.0
Sparsity of Pruned Mask:  tensor(0.6723)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6485 Acc: 0.5082
val Loss: 0.8297 Acc: 0.8177
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5262 Acc: 0.8674
val Loss: 0.3774 Acc: 0.8928
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3267 Acc: 0.9050
val Loss: 0.3062 Acc: 0.9090
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2776 Acc: 0.9165
val Loss: 0.2890 Acc: 0.9145
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2559 Acc: 0.9231
val Loss: 0.2762 Acc: 0.9168
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2456 Acc: 0.9263
val Loss: 0.2821 Acc: 0.9141
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2344 Acc: 0.9307
val Loss: 0.2748 Acc: 0.9164
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2332 Acc: 0.9301
val Loss: 0.2699 Acc: 0.9215
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2263 Acc: 0.9333
val Loss: 0.2634 Acc: 0.9203
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2231 Acc: 0.9328
val Loss: 0.2638 Acc: 0.9211
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2210 Acc: 0.9339
val Loss: 0.2584 Acc: 0.9250
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2215 Acc: 0.9338
val Loss: 0.2938 Acc: 0.9090
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2157 Acc: 0.9357
val Loss: 0.2559 Acc: 0.9245
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2169 Acc: 0.9356
val Loss: 0.2666 Acc: 0.9224
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2140 Acc: 0.9370
val Loss: 0.2889 Acc: 0.9149
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2145 Acc: 0.9357
val Loss: 0.2527 Acc: 0.9260
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2110 Acc: 0.9364
val Loss: 0.2313 Acc: 0.9338
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1852 Acc: 0.9463
val Loss: 0.2174 Acc: 0.9373
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1752 Acc: 0.9498
val Loss: 0.2144 Acc: 0.9371
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1708 Acc: 0.9507
val Loss: 0.2079 Acc: 0.9398
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1683 Acc: 0.9516
val Loss: 0.2139 Acc: 0.9385
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1696 Acc: 0.9505
val Loss: 0.2107 Acc: 0.9395
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1678 Acc: 0.9515
val Loss: 0.2083 Acc: 0.9402
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1681 Acc: 0.9516
val Loss: 0.2097 Acc: 0.9387
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1669 Acc: 0.9526
val Loss: 0.2115 Acc: 0.9391
Epoch finished in 0m 9s
Best validation accuracy: 0.9391176149393906
Model Test Accuracy:  0.9441840811309157
Pruning Epoch 6
++++++++++++++++++
number of weights to prune:  17543.0
Sparsity of Pruned Mask:  tensor(0.7379)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6422 Acc: 0.5086
val Loss: 0.8162 Acc: 0.8199
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5120 Acc: 0.8731
val Loss: 0.3790 Acc: 0.8944
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3151 Acc: 0.9092
val Loss: 0.3074 Acc: 0.9056
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2694 Acc: 0.9193
val Loss: 0.2730 Acc: 0.9195
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2479 Acc: 0.9264
val Loss: 0.3072 Acc: 0.9059
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2356 Acc: 0.9297
val Loss: 0.2651 Acc: 0.9216
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2326 Acc: 0.9296
val Loss: 0.2500 Acc: 0.9245
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2241 Acc: 0.9332
val Loss: 0.2560 Acc: 0.9250
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2219 Acc: 0.9333
val Loss: 0.2722 Acc: 0.9191
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2160 Acc: 0.9360
val Loss: 0.2554 Acc: 0.9246
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2209 Acc: 0.9336
val Loss: 0.2492 Acc: 0.9279
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2143 Acc: 0.9359
val Loss: 0.2623 Acc: 0.9218
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2125 Acc: 0.9365
val Loss: 0.2624 Acc: 0.9239
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2121 Acc: 0.9363
val Loss: 0.2701 Acc: 0.9197
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2124 Acc: 0.9357
val Loss: 0.2489 Acc: 0.9265
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2091 Acc: 0.9368
val Loss: 0.2481 Acc: 0.9273
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2056 Acc: 0.9380
val Loss: 0.2229 Acc: 0.9356
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1768 Acc: 0.9491
val Loss: 0.2172 Acc: 0.9378
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1683 Acc: 0.9510
val Loss: 0.2111 Acc: 0.9393
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1672 Acc: 0.9515
val Loss: 0.2081 Acc: 0.9391
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1642 Acc: 0.9534
val Loss: 0.2115 Acc: 0.9394
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1634 Acc: 0.9528
val Loss: 0.2158 Acc: 0.9372
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1658 Acc: 0.9526
val Loss: 0.2079 Acc: 0.9396
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1637 Acc: 0.9528
val Loss: 0.2105 Acc: 0.9379
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1638 Acc: 0.9531
val Loss: 0.2085 Acc: 0.9392
Epoch finished in 0m 9s
Best validation accuracy: 0.9391722179753195
Model Test Accuracy:  0.9474877074370005
Pruning Epoch 7
++++++++++++++++++
number of weights to prune:  14034.0
Sparsity of Pruned Mask:  tensor(0.7903)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6305 Acc: 0.5181
val Loss: 0.8285 Acc: 0.8247
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5063 Acc: 0.8774
val Loss: 0.3660 Acc: 0.8958
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3111 Acc: 0.9096
val Loss: 0.2879 Acc: 0.9162
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2611 Acc: 0.9223
val Loss: 0.2746 Acc: 0.9169
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2422 Acc: 0.9276
val Loss: 0.2595 Acc: 0.9226
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2320 Acc: 0.9311
val Loss: 0.2636 Acc: 0.9214
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2250 Acc: 0.9333
val Loss: 0.2641 Acc: 0.9186
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2224 Acc: 0.9336
val Loss: 0.2517 Acc: 0.9262
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2171 Acc: 0.9348
val Loss: 0.2468 Acc: 0.9280
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2171 Acc: 0.9336
val Loss: 0.2602 Acc: 0.9219
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2160 Acc: 0.9361
val Loss: 0.2605 Acc: 0.9251
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2129 Acc: 0.9369
val Loss: 0.2541 Acc: 0.9253
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2099 Acc: 0.9369
val Loss: 0.2590 Acc: 0.9239
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2105 Acc: 0.9372
val Loss: 0.2455 Acc: 0.9276
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2085 Acc: 0.9375
val Loss: 0.2644 Acc: 0.9224
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2099 Acc: 0.9379
val Loss: 0.2615 Acc: 0.9225
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2079 Acc: 0.9382
val Loss: 0.2308 Acc: 0.9313
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1801 Acc: 0.9475
val Loss: 0.2198 Acc: 0.9362
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1706 Acc: 0.9508
val Loss: 0.2106 Acc: 0.9381
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1662 Acc: 0.9516
val Loss: 0.2108 Acc: 0.9381
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1644 Acc: 0.9531
val Loss: 0.2102 Acc: 0.9396
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1657 Acc: 0.9525
val Loss: 0.2063 Acc: 0.9407
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1646 Acc: 0.9533
val Loss: 0.2097 Acc: 0.9382
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1634 Acc: 0.9524
val Loss: 0.2084 Acc: 0.9394
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1626 Acc: 0.9533
val Loss: 0.2105 Acc: 0.9398
Epoch finished in 0m 9s
Best validation accuracy: 0.9397728513705362
Model Test Accuracy:  0.945759065765212
Pruning Epoch 8
++++++++++++++++++
number of weights to prune:  11227.0
Sparsity of Pruned Mask:  tensor(0.8322)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6458 Acc: 0.5025
val Loss: 0.8327 Acc: 0.8263
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5091 Acc: 0.8774
val Loss: 0.3678 Acc: 0.8985
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3122 Acc: 0.9106
val Loss: 0.2953 Acc: 0.9138
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2622 Acc: 0.9235
val Loss: 0.2732 Acc: 0.9189
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2422 Acc: 0.9278
val Loss: 0.2687 Acc: 0.9189
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2310 Acc: 0.9311
val Loss: 0.2625 Acc: 0.9215
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2217 Acc: 0.9338
val Loss: 0.2600 Acc: 0.9230
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2230 Acc: 0.9329
val Loss: 0.2502 Acc: 0.9255
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2170 Acc: 0.9365
val Loss: 0.2500 Acc: 0.9246
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2185 Acc: 0.9339
val Loss: 0.2616 Acc: 0.9225
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2156 Acc: 0.9361
val Loss: 0.2560 Acc: 0.9242
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2142 Acc: 0.9351
val Loss: 0.2439 Acc: 0.9279
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2128 Acc: 0.9358
val Loss: 0.2842 Acc: 0.9162
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2092 Acc: 0.9379
val Loss: 0.2685 Acc: 0.9201
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2099 Acc: 0.9368
val Loss: 0.2955 Acc: 0.9126
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2128 Acc: 0.9364
val Loss: 0.2709 Acc: 0.9213
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2072 Acc: 0.9378
val Loss: 0.2280 Acc: 0.9326
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1816 Acc: 0.9466
val Loss: 0.2197 Acc: 0.9372
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1740 Acc: 0.9501
val Loss: 0.2157 Acc: 0.9379
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1692 Acc: 0.9503
val Loss: 0.2132 Acc: 0.9383
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1685 Acc: 0.9513
val Loss: 0.2135 Acc: 0.9376
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1681 Acc: 0.9514
val Loss: 0.2127 Acc: 0.9373
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1679 Acc: 0.9513
val Loss: 0.2145 Acc: 0.9367
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1679 Acc: 0.9515
val Loss: 0.2103 Acc: 0.9392
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1674 Acc: 0.9516
val Loss: 0.2127 Acc: 0.9376
Epoch finished in 0m 9s
Best validation accuracy: 0.9375887299333843
Model Test Accuracy:  0.9474108789182544
Pruning Epoch 9
++++++++++++++++++
number of weights to prune:  8982.0
Sparsity of Pruned Mask:  tensor(0.8658)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6183 Acc: 0.5270
val Loss: 0.7982 Acc: 0.8373
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5032 Acc: 0.8786
val Loss: 0.3544 Acc: 0.9036
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3122 Acc: 0.9106
val Loss: 0.2990 Acc: 0.9097
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2646 Acc: 0.9219
val Loss: 0.2821 Acc: 0.9151
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2432 Acc: 0.9282
val Loss: 0.2649 Acc: 0.9200
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2324 Acc: 0.9313
val Loss: 0.2642 Acc: 0.9218
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2261 Acc: 0.9328
val Loss: 0.2508 Acc: 0.9263
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2231 Acc: 0.9333
val Loss: 0.2652 Acc: 0.9201
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2204 Acc: 0.9343
val Loss: 0.2555 Acc: 0.9240
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2197 Acc: 0.9334
val Loss: 0.2591 Acc: 0.9228
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2168 Acc: 0.9351
val Loss: 0.2521 Acc: 0.9260
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2178 Acc: 0.9344
val Loss: 0.2513 Acc: 0.9252
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2148 Acc: 0.9361
val Loss: 0.2647 Acc: 0.9223
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2174 Acc: 0.9351
val Loss: 0.2614 Acc: 0.9212
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2135 Acc: 0.9358
val Loss: 0.2611 Acc: 0.9224
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2140 Acc: 0.9353
val Loss: 0.2553 Acc: 0.9250
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2082 Acc: 0.9386
val Loss: 0.2316 Acc: 0.9326
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1864 Acc: 0.9453
val Loss: 0.2223 Acc: 0.9372
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1795 Acc: 0.9480
val Loss: 0.2124 Acc: 0.9380
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1764 Acc: 0.9486
val Loss: 0.2112 Acc: 0.9387
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1745 Acc: 0.9503
val Loss: 0.2135 Acc: 0.9375
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1713 Acc: 0.9509
val Loss: 0.2124 Acc: 0.9382
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1709 Acc: 0.9507
val Loss: 0.2088 Acc: 0.9409
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1713 Acc: 0.9507
val Loss: 0.2086 Acc: 0.9405
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1738 Acc: 0.9511
val Loss: 0.2114 Acc: 0.9391
Epoch finished in 0m 9s
Best validation accuracy: 0.9390630119034619
Model Test Accuracy:  0.9454517516902273
Pruning Epoch 10
++++++++++++++++++
number of weights to prune:  7185.0
Sparsity of Pruned Mask:  tensor(0.8926)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6906 Acc: 0.4898
val Loss: 0.8626 Acc: 0.8147
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5382 Acc: 0.8689
val Loss: 0.3741 Acc: 0.8976
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3230 Acc: 0.9085
val Loss: 0.2896 Acc: 0.9167
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2679 Acc: 0.9214
val Loss: 0.2722 Acc: 0.9185
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2491 Acc: 0.9259
val Loss: 0.2619 Acc: 0.9208
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2354 Acc: 0.9300
val Loss: 0.2694 Acc: 0.9203
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2312 Acc: 0.9311
val Loss: 0.2549 Acc: 0.9250
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2288 Acc: 0.9317
val Loss: 0.2716 Acc: 0.9178
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2267 Acc: 0.9318
val Loss: 0.2684 Acc: 0.9182
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2262 Acc: 0.9321
val Loss: 0.2667 Acc: 0.9215
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2192 Acc: 0.9338
val Loss: 0.2525 Acc: 0.9265
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2221 Acc: 0.9333
val Loss: 0.2632 Acc: 0.9216
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2215 Acc: 0.9337
val Loss: 0.2808 Acc: 0.9174
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2195 Acc: 0.9333
val Loss: 0.2513 Acc: 0.9248
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2189 Acc: 0.9356
val Loss: 0.2786 Acc: 0.9145
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2217 Acc: 0.9333
val Loss: 0.2971 Acc: 0.9119
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2221 Acc: 0.9330
val Loss: 0.2393 Acc: 0.9291
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1931 Acc: 0.9424
val Loss: 0.2206 Acc: 0.9360
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1833 Acc: 0.9464
val Loss: 0.2220 Acc: 0.9343
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1812 Acc: 0.9474
val Loss: 0.2160 Acc: 0.9369
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1792 Acc: 0.9476
val Loss: 0.2171 Acc: 0.9371
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1775 Acc: 0.9480
val Loss: 0.2154 Acc: 0.9396
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1776 Acc: 0.9487
val Loss: 0.2195 Acc: 0.9373
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1772 Acc: 0.9483
val Loss: 0.2122 Acc: 0.9403
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1767 Acc: 0.9480
val Loss: 0.2172 Acc: 0.9360
Epoch finished in 0m 9s
Best validation accuracy: 0.9359506388555204
Model Test Accuracy:  0.9434926244622003
Pruning Epoch 11
++++++++++++++++++
number of weights to prune:  5748.0
Sparsity of Pruned Mask:  tensor(0.9141)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.7484 Acc: 0.4553
val Loss: 0.9423 Acc: 0.7949
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5741 Acc: 0.8633
val Loss: 0.3938 Acc: 0.8944
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3335 Acc: 0.9054
val Loss: 0.3141 Acc: 0.9092
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2738 Acc: 0.9196
val Loss: 0.2884 Acc: 0.9126
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2532 Acc: 0.9241
val Loss: 0.2617 Acc: 0.9225
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2435 Acc: 0.9273
val Loss: 0.2753 Acc: 0.9173
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2368 Acc: 0.9294
val Loss: 0.2751 Acc: 0.9172
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2353 Acc: 0.9285
val Loss: 0.2610 Acc: 0.9216
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2325 Acc: 0.9299
val Loss: 0.2643 Acc: 0.9215
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2311 Acc: 0.9311
val Loss: 0.2772 Acc: 0.9182
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2308 Acc: 0.9306
val Loss: 0.2544 Acc: 0.9247
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2278 Acc: 0.9312
val Loss: 0.2532 Acc: 0.9245
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2273 Acc: 0.9320
val Loss: 0.2603 Acc: 0.9241
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2256 Acc: 0.9329
val Loss: 0.2778 Acc: 0.9184
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2248 Acc: 0.9331
val Loss: 0.2801 Acc: 0.9177
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2275 Acc: 0.9317
val Loss: 0.3103 Acc: 0.9064
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2272 Acc: 0.9319
val Loss: 0.2420 Acc: 0.9269
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2068 Acc: 0.9385
val Loss: 0.2293 Acc: 0.9323
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1920 Acc: 0.9444
val Loss: 0.2205 Acc: 0.9351
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1895 Acc: 0.9454
val Loss: 0.2180 Acc: 0.9349
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1882 Acc: 0.9455
val Loss: 0.2187 Acc: 0.9363
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1874 Acc: 0.9453
val Loss: 0.2144 Acc: 0.9387
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1855 Acc: 0.9456
val Loss: 0.2190 Acc: 0.9379
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1846 Acc: 0.9459
val Loss: 0.2222 Acc: 0.9355
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1870 Acc: 0.9464
val Loss: 0.2186 Acc: 0.9368
Epoch finished in 0m 9s
Best validation accuracy: 0.9367696843944523
Model Test Accuracy:  0.9413414259373079
Pruning Epoch 12
++++++++++++++++++
number of weights to prune:  4598.0
Sparsity of Pruned Mask:  tensor(0.9313)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.8257 Acc: 0.4179
val Loss: 1.0442 Acc: 0.7688
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.6243 Acc: 0.8505
val Loss: 0.4134 Acc: 0.8897
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3472 Acc: 0.9035
val Loss: 0.3192 Acc: 0.9102
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2857 Acc: 0.9166
val Loss: 0.2898 Acc: 0.9137
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2609 Acc: 0.9226
val Loss: 0.2718 Acc: 0.9204
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2501 Acc: 0.9253
val Loss: 0.2887 Acc: 0.9147
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2445 Acc: 0.9264
val Loss: 0.2830 Acc: 0.9138
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2469 Acc: 0.9254
val Loss: 0.2708 Acc: 0.9194
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2400 Acc: 0.9275
val Loss: 0.2927 Acc: 0.9085
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2392 Acc: 0.9282
val Loss: 0.2733 Acc: 0.9175
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2380 Acc: 0.9294
val Loss: 0.2697 Acc: 0.9186
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2379 Acc: 0.9283
val Loss: 0.2841 Acc: 0.9145
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2377 Acc: 0.9287
val Loss: 0.2722 Acc: 0.9201
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2349 Acc: 0.9297
val Loss: 0.2942 Acc: 0.9123
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2339 Acc: 0.9299
val Loss: 0.2531 Acc: 0.9264
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2339 Acc: 0.9299
val Loss: 0.2572 Acc: 0.9243
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2306 Acc: 0.9316
val Loss: 0.2400 Acc: 0.9289
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2040 Acc: 0.9411
val Loss: 0.2282 Acc: 0.9321
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1982 Acc: 0.9410
val Loss: 0.2270 Acc: 0.9317
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1941 Acc: 0.9429
val Loss: 0.2240 Acc: 0.9338
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1924 Acc: 0.9426
val Loss: 0.2220 Acc: 0.9360
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1914 Acc: 0.9439
val Loss: 0.2255 Acc: 0.9347
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1930 Acc: 0.9431
val Loss: 0.2246 Acc: 0.9345
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1934 Acc: 0.9434
val Loss: 0.2227 Acc: 0.9344
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1920 Acc: 0.9432
val Loss: 0.2214 Acc: 0.9344
Epoch finished in 0m 9s
Best validation accuracy: 0.9343671508135852
Model Test Accuracy:  0.9384987707437
Pruning Epoch 13
++++++++++++++++++
number of weights to prune:  3678.0
Sparsity of Pruned Mask:  tensor(0.9450)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.8353 Acc: 0.4141
val Loss: 1.0930 Acc: 0.7461
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.6479 Acc: 0.8466
val Loss: 0.4236 Acc: 0.8872
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3572 Acc: 0.8987
val Loss: 0.3244 Acc: 0.9076
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2953 Acc: 0.9136
val Loss: 0.3060 Acc: 0.9092
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2717 Acc: 0.9187
val Loss: 0.3046 Acc: 0.9093
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2587 Acc: 0.9236
val Loss: 0.2643 Acc: 0.9207
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2550 Acc: 0.9234
val Loss: 0.2730 Acc: 0.9187
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2508 Acc: 0.9244
val Loss: 0.2998 Acc: 0.9103
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2493 Acc: 0.9243
val Loss: 0.2705 Acc: 0.9180
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2490 Acc: 0.9267
val Loss: 0.2752 Acc: 0.9179
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2477 Acc: 0.9259
val Loss: 0.2634 Acc: 0.9226
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2441 Acc: 0.9270
val Loss: 0.2669 Acc: 0.9213
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2429 Acc: 0.9259
val Loss: 0.2747 Acc: 0.9172
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2435 Acc: 0.9273
val Loss: 0.2842 Acc: 0.9149
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2444 Acc: 0.9267
val Loss: 0.3037 Acc: 0.9078
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2416 Acc: 0.9272
val Loss: 0.3170 Acc: 0.9024
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2436 Acc: 0.9275
val Loss: 0.2448 Acc: 0.9280
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2187 Acc: 0.9358
val Loss: 0.2347 Acc: 0.9321
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2118 Acc: 0.9383
val Loss: 0.2333 Acc: 0.9313
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2064 Acc: 0.9395
val Loss: 0.2297 Acc: 0.9327
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2046 Acc: 0.9398
val Loss: 0.2245 Acc: 0.9338
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2013 Acc: 0.9407
val Loss: 0.2266 Acc: 0.9351
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2035 Acc: 0.9403
val Loss: 0.2307 Acc: 0.9332
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2028 Acc: 0.9416
val Loss: 0.2291 Acc: 0.9328
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2036 Acc: 0.9400
val Loss: 0.2285 Acc: 0.9335
Epoch finished in 0m 9s
Best validation accuracy: 0.9334935022387245
Model Test Accuracy:  0.9386524277811923
Pruning Epoch 14
++++++++++++++++++
number of weights to prune:  2943.0
Sparsity of Pruned Mask:  tensor(0.9560)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.9207 Acc: 0.3660
val Loss: 1.2460 Acc: 0.6796
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.7452 Acc: 0.8222
val Loss: 0.4748 Acc: 0.8745
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3911 Acc: 0.8917
val Loss: 0.3462 Acc: 0.8998
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3162 Acc: 0.9080
val Loss: 0.3096 Acc: 0.9083
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2882 Acc: 0.9150
val Loss: 0.3046 Acc: 0.9089
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2775 Acc: 0.9175
val Loss: 0.2991 Acc: 0.9109
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2708 Acc: 0.9191
val Loss: 0.3289 Acc: 0.8977
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2657 Acc: 0.9195
val Loss: 0.2893 Acc: 0.9119
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2655 Acc: 0.9208
val Loss: 0.2900 Acc: 0.9117
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2596 Acc: 0.9231
val Loss: 0.2980 Acc: 0.9095
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2602 Acc: 0.9219
val Loss: 0.2815 Acc: 0.9174
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2584 Acc: 0.9222
val Loss: 0.2739 Acc: 0.9174
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2596 Acc: 0.9223
val Loss: 0.2925 Acc: 0.9119
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2539 Acc: 0.9236
val Loss: 0.3158 Acc: 0.9038
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2560 Acc: 0.9228
val Loss: 0.2955 Acc: 0.9126
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2543 Acc: 0.9243
val Loss: 0.2713 Acc: 0.9186
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2545 Acc: 0.9240
val Loss: 0.2629 Acc: 0.9249
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2313 Acc: 0.9322
val Loss: 0.2436 Acc: 0.9273
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2214 Acc: 0.9343
val Loss: 0.2386 Acc: 0.9311
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2208 Acc: 0.9347
val Loss: 0.2367 Acc: 0.9293
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2159 Acc: 0.9360
val Loss: 0.2395 Acc: 0.9308
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2141 Acc: 0.9373
val Loss: 0.2347 Acc: 0.9312
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2142 Acc: 0.9368
val Loss: 0.2369 Acc: 0.9307
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2157 Acc: 0.9373
val Loss: 0.2358 Acc: 0.9304
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2156 Acc: 0.9365
val Loss: 0.2373 Acc: 0.9309
Epoch finished in 0m 9s
Best validation accuracy: 0.930927159550071
Model Test Accuracy:  0.9368469575906576
Pruning Epoch 15
++++++++++++++++++
number of weights to prune:  2354.0
Sparsity of Pruned Mask:  tensor(0.9648)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.0319 Acc: 0.3104
val Loss: 1.5640 Acc: 0.5165
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.9501 Acc: 0.7531
val Loss: 0.5577 Acc: 0.8550
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4538 Acc: 0.8739
val Loss: 0.3944 Acc: 0.8870
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3511 Acc: 0.8972
val Loss: 0.3521 Acc: 0.8957
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3133 Acc: 0.9068
val Loss: 0.3120 Acc: 0.9057
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2989 Acc: 0.9115
val Loss: 0.2936 Acc: 0.9119
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2898 Acc: 0.9132
val Loss: 0.2949 Acc: 0.9122
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2854 Acc: 0.9142
val Loss: 0.3258 Acc: 0.9003
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2829 Acc: 0.9153
val Loss: 0.3043 Acc: 0.9092
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2781 Acc: 0.9161
val Loss: 0.3111 Acc: 0.9049
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2733 Acc: 0.9178
val Loss: 0.2978 Acc: 0.9105
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2772 Acc: 0.9161
val Loss: 0.2978 Acc: 0.9114
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2719 Acc: 0.9177
val Loss: 0.3137 Acc: 0.9049
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2699 Acc: 0.9182
val Loss: 0.2685 Acc: 0.9195
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2689 Acc: 0.9193
val Loss: 0.3068 Acc: 0.9065
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2668 Acc: 0.9196
val Loss: 0.2795 Acc: 0.9154
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2686 Acc: 0.9190
val Loss: 0.2636 Acc: 0.9217
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2412 Acc: 0.9276
val Loss: 0.2513 Acc: 0.9243
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2338 Acc: 0.9314
val Loss: 0.2457 Acc: 0.9283
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2314 Acc: 0.9320
val Loss: 0.2451 Acc: 0.9280
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2280 Acc: 0.9337
val Loss: 0.2440 Acc: 0.9283
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2298 Acc: 0.9324
val Loss: 0.2438 Acc: 0.9270
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2281 Acc: 0.9332
val Loss: 0.2448 Acc: 0.9291
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2271 Acc: 0.9330
val Loss: 0.2453 Acc: 0.9288
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2286 Acc: 0.9328
val Loss: 0.2428 Acc: 0.9281
Epoch finished in 0m 9s
Best validation accuracy: 0.9281424047177024
Model Test Accuracy:  0.933658574062692
Pruning Epoch 16
++++++++++++++++++
number of weights to prune:  1883.0
Sparsity of Pruned Mask:  tensor(0.9719)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.0892 Acc: 0.2744
val Loss: 1.7594 Acc: 0.4020
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.1737 Acc: 0.6620
val Loss: 0.6908 Acc: 0.8223
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.5398 Acc: 0.8506
val Loss: 0.4538 Acc: 0.8675
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4000 Acc: 0.8840
val Loss: 0.3782 Acc: 0.8893
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3493 Acc: 0.8958
val Loss: 0.3369 Acc: 0.8995
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3269 Acc: 0.9029
val Loss: 0.3229 Acc: 0.9040
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3155 Acc: 0.9059
val Loss: 0.3418 Acc: 0.8958
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3073 Acc: 0.9086
val Loss: 0.3494 Acc: 0.8930
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2997 Acc: 0.9095
val Loss: 0.3158 Acc: 0.9052
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2948 Acc: 0.9101
val Loss: 0.3097 Acc: 0.9070
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2896 Acc: 0.9135
val Loss: 0.3164 Acc: 0.9002
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2916 Acc: 0.9120
val Loss: 0.3046 Acc: 0.9082
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2878 Acc: 0.9132
val Loss: 0.2885 Acc: 0.9120
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2890 Acc: 0.9128
val Loss: 0.3010 Acc: 0.9107
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2870 Acc: 0.9136
val Loss: 0.2995 Acc: 0.9113
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2830 Acc: 0.9139
val Loss: 0.2925 Acc: 0.9113
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2783 Acc: 0.9164
val Loss: 0.2715 Acc: 0.9181
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2548 Acc: 0.9244
val Loss: 0.2636 Acc: 0.9210
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2502 Acc: 0.9259
val Loss: 0.2565 Acc: 0.9249
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2444 Acc: 0.9273
val Loss: 0.2537 Acc: 0.9234
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2419 Acc: 0.9283
val Loss: 0.2527 Acc: 0.9251
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2427 Acc: 0.9284
val Loss: 0.2535 Acc: 0.9241
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2437 Acc: 0.9281
val Loss: 0.2542 Acc: 0.9242
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2423 Acc: 0.9291
val Loss: 0.2552 Acc: 0.9248
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2411 Acc: 0.9289
val Loss: 0.2497 Acc: 0.9263
Epoch finished in 0m 9s
Best validation accuracy: 0.926340504532052
Model Test Accuracy:  0.9326213890596189
Pruning Epoch 17
++++++++++++++++++
number of weights to prune:  1506.0
Sparsity of Pruned Mask:  tensor(0.9775)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.1382 Acc: 0.2420
val Loss: 1.8303 Acc: 0.3508
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.3155 Acc: 0.6000
val Loss: 0.8264 Acc: 0.7857
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.6204 Acc: 0.8343
val Loss: 0.5074 Acc: 0.8519
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4421 Acc: 0.8713
val Loss: 0.3988 Acc: 0.8794
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3876 Acc: 0.8846
val Loss: 0.3823 Acc: 0.8822
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3571 Acc: 0.8924
val Loss: 0.3688 Acc: 0.8863
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3459 Acc: 0.8950
val Loss: 0.3714 Acc: 0.8880
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3341 Acc: 0.9007
val Loss: 0.3417 Acc: 0.8960
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3254 Acc: 0.9011
val Loss: 0.3417 Acc: 0.8986
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3196 Acc: 0.9031
val Loss: 0.3530 Acc: 0.8907
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3168 Acc: 0.9038
val Loss: 0.3172 Acc: 0.9038
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3105 Acc: 0.9050
val Loss: 0.3280 Acc: 0.9008
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3123 Acc: 0.9048
val Loss: 0.3170 Acc: 0.9053
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3051 Acc: 0.9070
val Loss: 0.3121 Acc: 0.9048
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3012 Acc: 0.9081
val Loss: 0.3079 Acc: 0.9061
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3010 Acc: 0.9081
val Loss: 0.3197 Acc: 0.9022
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2937 Acc: 0.9111
val Loss: 0.2802 Acc: 0.9168
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2698 Acc: 0.9199
val Loss: 0.2732 Acc: 0.9188
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2657 Acc: 0.9203
val Loss: 0.2648 Acc: 0.9209
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2611 Acc: 0.9224
val Loss: 0.2643 Acc: 0.9230
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2585 Acc: 0.9232
val Loss: 0.2639 Acc: 0.9216
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2574 Acc: 0.9231
val Loss: 0.2656 Acc: 0.9205
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2563 Acc: 0.9240
val Loss: 0.2641 Acc: 0.9200
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2594 Acc: 0.9219
val Loss: 0.2692 Acc: 0.9209
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2579 Acc: 0.9230
val Loss: 0.2640 Acc: 0.9216
Epoch finished in 0m 9s
Best validation accuracy: 0.9216446434421754
Model Test Accuracy:  0.9273202212661339
Pruning Epoch 18
++++++++++++++++++
number of weights to prune:  1205.0
Sparsity of Pruned Mask:  tensor(0.9820)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.1757 Acc: 0.2236
val Loss: 1.9389 Acc: 0.3137
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.5699 Acc: 0.4784
val Loss: 1.1167 Acc: 0.6722
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.8278 Acc: 0.7778
val Loss: 0.6374 Acc: 0.8265
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5365 Acc: 0.8479
val Loss: 0.4940 Acc: 0.8526
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4440 Acc: 0.8691
val Loss: 0.4274 Acc: 0.8708
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4073 Acc: 0.8768
val Loss: 0.4457 Acc: 0.8607
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3783 Acc: 0.8844
val Loss: 0.4420 Acc: 0.8611
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3594 Acc: 0.8916
val Loss: 0.3781 Acc: 0.8816
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3556 Acc: 0.8908
val Loss: 0.4468 Acc: 0.8608
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3463 Acc: 0.8943
val Loss: 0.3601 Acc: 0.8892
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3387 Acc: 0.8967
val Loss: 0.3502 Acc: 0.8927
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3344 Acc: 0.8979
val Loss: 0.3649 Acc: 0.8885
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3291 Acc: 0.8997
val Loss: 0.3430 Acc: 0.8960
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3265 Acc: 0.9013
val Loss: 0.3412 Acc: 0.8958
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3206 Acc: 0.9030
val Loss: 0.3422 Acc: 0.8947
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3195 Acc: 0.9033
val Loss: 0.3397 Acc: 0.8936
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3202 Acc: 0.9030
val Loss: 0.3022 Acc: 0.9082
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2910 Acc: 0.9127
val Loss: 0.2886 Acc: 0.9129
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2857 Acc: 0.9142
val Loss: 0.2850 Acc: 0.9143
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2816 Acc: 0.9167
val Loss: 0.2808 Acc: 0.9169
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2804 Acc: 0.9157
val Loss: 0.2814 Acc: 0.9172
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2777 Acc: 0.9176
val Loss: 0.2840 Acc: 0.9163
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2788 Acc: 0.9166
val Loss: 0.2825 Acc: 0.9162
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2778 Acc: 0.9162
val Loss: 0.2780 Acc: 0.9188
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2753 Acc: 0.9174
val Loss: 0.2792 Acc: 0.9154
Epoch finished in 0m 9s
Best validation accuracy: 0.9154198973462925
Model Test Accuracy:  0.9232098955132144
Pruning Epoch 19
++++++++++++++++++
number of weights to prune:  963.0
Sparsity of Pruned Mask:  tensor(0.9856)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2204 Acc: 0.1971
val Loss: 2.1243 Acc: 0.2524
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.8641 Acc: 0.3525
val Loss: 1.5847 Acc: 0.4871
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 1.1954 Acc: 0.6283
val Loss: 0.8980 Acc: 0.7418
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.7366 Acc: 0.7891
val Loss: 0.6400 Acc: 0.8039
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5758 Acc: 0.8274
val Loss: 0.5595 Acc: 0.8274
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.5099 Acc: 0.8447
val Loss: 0.5067 Acc: 0.8420
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4710 Acc: 0.8560
val Loss: 0.4712 Acc: 0.8524
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4489 Acc: 0.8632
val Loss: 0.4493 Acc: 0.8602
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4256 Acc: 0.8674
val Loss: 0.4194 Acc: 0.8692
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4093 Acc: 0.8729
val Loss: 0.4149 Acc: 0.8714
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.4028 Acc: 0.8756
val Loss: 0.4109 Acc: 0.8708
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3934 Acc: 0.8803
val Loss: 0.4079 Acc: 0.8732
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3817 Acc: 0.8823
val Loss: 0.3817 Acc: 0.8814
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3758 Acc: 0.8848
val Loss: 0.3761 Acc: 0.8850
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3672 Acc: 0.8868
val Loss: 0.4259 Acc: 0.8668
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3636 Acc: 0.8878
val Loss: 0.3816 Acc: 0.8801
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3595 Acc: 0.8893
val Loss: 0.3401 Acc: 0.8957
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3373 Acc: 0.8971
val Loss: 0.3212 Acc: 0.9032
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3257 Acc: 0.8999
val Loss: 0.3201 Acc: 0.9024
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3221 Acc: 0.9024
val Loss: 0.3153 Acc: 0.9042
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3191 Acc: 0.9033
val Loss: 0.3132 Acc: 0.9050
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3203 Acc: 0.9036
val Loss: 0.3140 Acc: 0.9053
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3183 Acc: 0.9038
val Loss: 0.3161 Acc: 0.9032
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3180 Acc: 0.9047
val Loss: 0.3147 Acc: 0.9025
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3185 Acc: 0.9042
val Loss: 0.3130 Acc: 0.9050
Epoch finished in 0m 9s
Best validation accuracy: 0.9050453205198209
Model Test Accuracy:  0.911839274738783
Pruning Epoch 20
++++++++++++++++++
number of weights to prune:  771.0
Sparsity of Pruned Mask:  tensor(0.9885)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2077 Acc: 0.2096
val Loss: 2.0762 Acc: 0.2686
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.8932 Acc: 0.3303
val Loss: 1.7040 Acc: 0.4095
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 1.3828 Acc: 0.5443
val Loss: 1.0801 Acc: 0.6676
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.8759 Acc: 0.7420
val Loss: 0.7411 Acc: 0.7836
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.6530 Acc: 0.8090
val Loss: 0.6159 Acc: 0.8064
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.5486 Acc: 0.8328
val Loss: 0.5958 Acc: 0.8122
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.5000 Acc: 0.8466
val Loss: 0.4987 Acc: 0.8437
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4679 Acc: 0.8559
val Loss: 0.4920 Acc: 0.8460
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4474 Acc: 0.8629
val Loss: 0.4510 Acc: 0.8619
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4314 Acc: 0.8675
val Loss: 0.4512 Acc: 0.8572
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.4210 Acc: 0.8711
val Loss: 0.4403 Acc: 0.8618
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.4127 Acc: 0.8731
val Loss: 0.4313 Acc: 0.8661
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.4018 Acc: 0.8757
val Loss: 0.3981 Acc: 0.8764
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3965 Acc: 0.8782
val Loss: 0.4185 Acc: 0.8715
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3922 Acc: 0.8789
val Loss: 0.4167 Acc: 0.8716
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3856 Acc: 0.8809
val Loss: 0.3947 Acc: 0.8763
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3786 Acc: 0.8853
val Loss: 0.3534 Acc: 0.8918
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3503 Acc: 0.8929
val Loss: 0.3425 Acc: 0.8976
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3440 Acc: 0.8949
val Loss: 0.3408 Acc: 0.8971
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3386 Acc: 0.8981
val Loss: 0.3321 Acc: 0.8998
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3406 Acc: 0.8964
val Loss: 0.3341 Acc: 0.8979
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3358 Acc: 0.8973
val Loss: 0.3348 Acc: 0.8985
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3390 Acc: 0.8965
val Loss: 0.3354 Acc: 0.8949
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3375 Acc: 0.8971
val Loss: 0.3296 Acc: 0.8997
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3383 Acc: 0.8979
val Loss: 0.3320 Acc: 0.8977
Epoch finished in 0m 9s
Best validation accuracy: 0.8976739106694333
Model Test Accuracy:  0.9051551936078671
Pruning Epoch 21
++++++++++++++++++
number of weights to prune:  616.0
Sparsity of Pruned Mask:  tensor(0.9908)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2269 Acc: 0.1926
val Loss: 2.1426 Acc: 0.2548
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.9736 Acc: 0.3019
val Loss: 1.8605 Acc: 0.3473
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 1.6683 Acc: 0.4230
val Loss: 1.4011 Acc: 0.5279
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 1.1590 Acc: 0.6254
val Loss: 0.9961 Acc: 0.7027
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.8370 Acc: 0.7475
val Loss: 0.7699 Acc: 0.7630
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.6774 Acc: 0.7920
val Loss: 0.6540 Acc: 0.7921
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.6020 Acc: 0.8136
val Loss: 0.7714 Acc: 0.7534
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.5549 Acc: 0.8278
val Loss: 0.5470 Acc: 0.8272
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.5257 Acc: 0.8355
val Loss: 0.6411 Acc: 0.7937
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.5048 Acc: 0.8419
val Loss: 0.5136 Acc: 0.8384
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.4844 Acc: 0.8479
val Loss: 0.5132 Acc: 0.8364
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.4702 Acc: 0.8522
val Loss: 0.4788 Acc: 0.8498
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.4648 Acc: 0.8547
val Loss: 0.5485 Acc: 0.8323
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.4509 Acc: 0.8612
val Loss: 0.4884 Acc: 0.8411
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.4423 Acc: 0.8626
val Loss: 0.4427 Acc: 0.8602
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.4363 Acc: 0.8638
val Loss: 0.4626 Acc: 0.8545
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.4290 Acc: 0.8667
val Loss: 0.4008 Acc: 0.8765
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.4011 Acc: 0.8763
val Loss: 0.3819 Acc: 0.8831
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3921 Acc: 0.8804
val Loss: 0.3825 Acc: 0.8828
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3886 Acc: 0.8812
val Loss: 0.3781 Acc: 0.8847
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3892 Acc: 0.8800
val Loss: 0.3813 Acc: 0.8848
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3845 Acc: 0.8816
val Loss: 0.3777 Acc: 0.8853
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3858 Acc: 0.8811
val Loss: 0.3736 Acc: 0.8866
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3853 Acc: 0.8816
val Loss: 0.3779 Acc: 0.8852
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3866 Acc: 0.8824
val Loss: 0.3781 Acc: 0.8845
Epoch finished in 0m 9s
Best validation accuracy: 0.884514579010593
Model Test Accuracy:  0.8839121081745543
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2556 Acc: 0.1792
val Loss: 2.2226 Acc: 0.1959
Epoch finished in 0m 12s
Training Epoch 1/24
********************
Warmup
train Loss: 2.0674 Acc: 0.2662
val Loss: 1.8526 Acc: 0.3405
Epoch finished in 0m 13s
Training Epoch 2/24
********************
Warmup
train Loss: 1.2056 Acc: 0.5901
val Loss: 0.8813 Acc: 0.7158
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5511 Acc: 0.8266
val Loss: 0.6331 Acc: 0.8070
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4350 Acc: 0.8671
val Loss: 0.4961 Acc: 0.8627
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3798 Acc: 0.8843
val Loss: 0.3658 Acc: 0.8878
Epoch finished in 0m 13s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3461 Acc: 0.8953
val Loss: 0.3661 Acc: 0.8912
Epoch finished in 0m 13s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3234 Acc: 0.9031
val Loss: 0.3123 Acc: 0.9075
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3046 Acc: 0.9089
val Loss: 0.3314 Acc: 0.9033
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2834 Acc: 0.9153
val Loss: 0.3217 Acc: 0.9074
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2769 Acc: 0.9174
val Loss: 0.3011 Acc: 0.9123
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2626 Acc: 0.9213
val Loss: 0.2829 Acc: 0.9159
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2499 Acc: 0.9252
val Loss: 0.3086 Acc: 0.9086
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2439 Acc: 0.9284
val Loss: 0.2474 Acc: 0.9257
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2386 Acc: 0.9281
val Loss: 0.2598 Acc: 0.9260
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2322 Acc: 0.9325
val Loss: 0.2579 Acc: 0.9268
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2223 Acc: 0.9346
val Loss: 0.2402 Acc: 0.9302
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1917 Acc: 0.9427
val Loss: 0.2244 Acc: 0.9335
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1811 Acc: 0.9487
val Loss: 0.2196 Acc: 0.9366
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1747 Acc: 0.9497
val Loss: 0.2175 Acc: 0.9368
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1723 Acc: 0.9506
val Loss: 0.2154 Acc: 0.9390
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1717 Acc: 0.9504
val Loss: 0.2171 Acc: 0.9379
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1727 Acc: 0.9507
val Loss: 0.2157 Acc: 0.9368
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1710 Acc: 0.9503
val Loss: 0.2133 Acc: 0.9387
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1717 Acc: 0.9505
val Loss: 0.2077 Acc: 0.9402
Epoch finished in 0m 12s
Best validation accuracy: 0.9401550726220378
Before Pruning
++++++++++++++++++
Model Test Accuracy:  0.9440688383527964
Pruning Epoch 1
++++++++++++++++++
number of weights to prune:  53540.0
Sparsity of Pruned Mask:  tensor(0.2000)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.1864 Acc: 0.2141
val Loss: 1.9306 Acc: 0.3178
Epoch finished in 0m 12s
Training Epoch 1/24
********************
Warmup
train Loss: 1.0709 Acc: 0.6404
val Loss: 0.5504 Acc: 0.8253
Epoch finished in 0m 12s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4476 Acc: 0.8620
val Loss: 0.4277 Acc: 0.8682
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3687 Acc: 0.8885
val Loss: 0.3644 Acc: 0.8870
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3278 Acc: 0.9025
val Loss: 0.3802 Acc: 0.8815
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3029 Acc: 0.9087
val Loss: 0.3353 Acc: 0.9011
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2834 Acc: 0.9149
val Loss: 0.4071 Acc: 0.8901
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2707 Acc: 0.9191
val Loss: 0.2864 Acc: 0.9172
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2566 Acc: 0.9256
val Loss: 0.2993 Acc: 0.9118
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2482 Acc: 0.9272
val Loss: 0.2995 Acc: 0.9130
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2386 Acc: 0.9291
val Loss: 0.2876 Acc: 0.9135
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2327 Acc: 0.9315
val Loss: 0.2791 Acc: 0.9175
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2258 Acc: 0.9331
val Loss: 0.2606 Acc: 0.9240
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2196 Acc: 0.9358
val Loss: 0.2882 Acc: 0.9136
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2150 Acc: 0.9351
val Loss: 0.2804 Acc: 0.9156
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2125 Acc: 0.9378
val Loss: 0.2819 Acc: 0.9140
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2084 Acc: 0.9388
val Loss: 0.2263 Acc: 0.9346
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1723 Acc: 0.9500
val Loss: 0.2103 Acc: 0.9404
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1609 Acc: 0.9539
val Loss: 0.2094 Acc: 0.9407
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1573 Acc: 0.9549
val Loss: 0.2067 Acc: 0.9409
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1568 Acc: 0.9552
val Loss: 0.2116 Acc: 0.9391
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1554 Acc: 0.9550
val Loss: 0.2050 Acc: 0.9432
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1556 Acc: 0.9550
val Loss: 0.2107 Acc: 0.9413
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1540 Acc: 0.9553
val Loss: 0.2082 Acc: 0.9409
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1533 Acc: 0.9564
val Loss: 0.2076 Acc: 0.9417
Epoch finished in 0m 12s
Best validation accuracy: 0.9417385606639729
