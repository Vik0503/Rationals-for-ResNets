Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dff0b2410
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfe793fa0
    (shortcut): Sequential()
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfe79b550
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfe79b9b0
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfe79be60
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfe7a6370
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfe7a6780
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfe7a6c30
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfd530190
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfd530780
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfd530c80
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfd53d190
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfd53d5a0
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfd53da50
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfd53df00
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfd54a5f0
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfd54aaa0
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7f8dfd54af00
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd556dc0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd5654b0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd565500
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd565410
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd565a50
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd565460
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd5653c0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd565320
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd565910
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd565cd0
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd565e10
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4f10f0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4f17d0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8e07463370
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4fd190
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4f18c0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4f1870
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4f1aa0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4fd050
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4fd410
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4fd0a0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4fddc0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4fde10
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd50d4b0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd50d460
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4fde60
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4fdf00
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd50d6e0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd50d730
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd50d5a0
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd50d870
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd516910
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd516960
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd516870
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd516d20
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd5168c0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd516820
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd5167d0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd516aa0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd516e60
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd524370
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd524280
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd524b40
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b1320
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b16e0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd524c30
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd524cd0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b15a0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b14b0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b1460
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b15f0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b93c0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b9410
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b9320
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b9a50
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b9370
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b92d0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b9230
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b9910
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b9cd0
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4b9e10
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4c70f0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4c7c30
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfe7c0550
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4d4190
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4c7cd0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4c7c80
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4c7d70
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4d43c0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4d42d0
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4d41e0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4d4f00
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4e1050
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4e10a0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4e1870
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4d4f50
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4e16e0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4e1730
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4e1140
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4e19b0
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4e1e60
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4eb780
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4eb7d0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4ebcd0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd478320
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4eb730
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4eb690
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4eb5f0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4ebe10
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f8dfd4780a0
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2574 Acc: 0.1721
val Loss: 2.2307 Acc: 0.1913
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 2.1304 Acc: 0.2381
val Loss: 1.9252 Acc: 0.3223
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 1.6048 Acc: 0.4378
val Loss: 1.3178 Acc: 0.5413
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.8996 Acc: 0.7053
val Loss: 0.7152 Acc: 0.7643
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5449 Acc: 0.8267
val Loss: 0.5303 Acc: 0.8322
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4459 Acc: 0.8619
val Loss: 0.6173 Acc: 0.8101
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4006 Acc: 0.8760
val Loss: 0.4853 Acc: 0.8447
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3639 Acc: 0.8873
val Loss: 0.4434 Acc: 0.8649
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3439 Acc: 0.8943
val Loss: 0.3872 Acc: 0.8797
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3278 Acc: 0.9002
val Loss: 0.3918 Acc: 0.8763
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3132 Acc: 0.9050
val Loss: 0.3448 Acc: 0.8941
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2939 Acc: 0.9105
val Loss: 0.3685 Acc: 0.8860
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2910 Acc: 0.9111
val Loss: 0.4044 Acc: 0.8775
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2780 Acc: 0.9148
val Loss: 0.4149 Acc: 0.8702
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2718 Acc: 0.9168
val Loss: 0.3109 Acc: 0.9070
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2651 Acc: 0.9197
val Loss: 0.3428 Acc: 0.8985
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2537 Acc: 0.9242
val Loss: 0.2589 Acc: 0.9239
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2202 Acc: 0.9346
val Loss: 0.2430 Acc: 0.9294
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2081 Acc: 0.9389
val Loss: 0.2372 Acc: 0.9313
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2047 Acc: 0.9405
val Loss: 0.2338 Acc: 0.9308
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2021 Acc: 0.9416
val Loss: 0.2373 Acc: 0.9304
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2024 Acc: 0.9409
val Loss: 0.2350 Acc: 0.9316
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2021 Acc: 0.9409
val Loss: 0.2358 Acc: 0.9309
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2022 Acc: 0.9417
val Loss: 0.2334 Acc: 0.9338
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2006 Acc: 0.9409
val Loss: 0.2357 Acc: 0.9301
Epoch finished in 0m 9s
Best validation accuracy: 0.930108114011139
Before Pruning
++++++++++++++++++
Model Test Accuracy:  0.9403810694529808
Pruning Epoch 1
++++++++++++++++++
number of weights to prune:  53540.0
Sparsity of Pruned Mask:  tensor(0.2000)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.1598 Acc: 0.2296
val Loss: 1.8912 Acc: 0.3535
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.4879 Acc: 0.4975
val Loss: 0.9910 Acc: 0.6819
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.6600 Acc: 0.7964
val Loss: 0.5322 Acc: 0.8334
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4440 Acc: 0.8607
val Loss: 0.4434 Acc: 0.8598
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3783 Acc: 0.8824
val Loss: 0.3954 Acc: 0.8752
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3454 Acc: 0.8944
val Loss: 0.4865 Acc: 0.8500
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3266 Acc: 0.9004
val Loss: 0.3480 Acc: 0.8935
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3058 Acc: 0.9065
val Loss: 0.3695 Acc: 0.8864
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2965 Acc: 0.9097
val Loss: 0.4177 Acc: 0.8703
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2851 Acc: 0.9134
val Loss: 0.3255 Acc: 0.9016
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2754 Acc: 0.9172
val Loss: 0.3264 Acc: 0.9037
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2739 Acc: 0.9161
val Loss: 0.3036 Acc: 0.9085
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2615 Acc: 0.9215
val Loss: 0.3016 Acc: 0.9092
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2579 Acc: 0.9227
val Loss: 0.3007 Acc: 0.9093
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2522 Acc: 0.9238
val Loss: 0.2994 Acc: 0.9119
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2482 Acc: 0.9261
val Loss: 0.3012 Acc: 0.9101
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2430 Acc: 0.9274
val Loss: 0.2609 Acc: 0.9231
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2101 Acc: 0.9382
val Loss: 0.2367 Acc: 0.9303
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1997 Acc: 0.9417
val Loss: 0.2316 Acc: 0.9333
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1934 Acc: 0.9437
val Loss: 0.2315 Acc: 0.9323
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1935 Acc: 0.9435
val Loss: 0.2297 Acc: 0.9337
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1918 Acc: 0.9440
val Loss: 0.2326 Acc: 0.9332
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1911 Acc: 0.9438
val Loss: 0.2287 Acc: 0.9346
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1906 Acc: 0.9451
val Loss: 0.2279 Acc: 0.9344
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1906 Acc: 0.9443
val Loss: 0.2266 Acc: 0.9351
Epoch finished in 0m 9s
Best validation accuracy: 0.9351315933165885
Model Test Accuracy:  0.9409572833435771
Pruning Epoch 2
++++++++++++++++++
number of weights to prune:  42831.0
Sparsity of Pruned Mask:  tensor(0.3600)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.9994 Acc: 0.3049
val Loss: 1.5082 Acc: 0.5297
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.8723 Acc: 0.7498
val Loss: 0.5184 Acc: 0.8456
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4306 Acc: 0.8709
val Loss: 0.4119 Acc: 0.8706
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3449 Acc: 0.8941
val Loss: 0.3446 Acc: 0.8927
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3140 Acc: 0.9040
val Loss: 0.3509 Acc: 0.8954
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2960 Acc: 0.9105
val Loss: 0.3348 Acc: 0.8980
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2793 Acc: 0.9146
val Loss: 0.3444 Acc: 0.8957
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2730 Acc: 0.9166
val Loss: 0.2976 Acc: 0.9100
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2620 Acc: 0.9202
val Loss: 0.3002 Acc: 0.9108
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2581 Acc: 0.9206
val Loss: 0.2909 Acc: 0.9116
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2558 Acc: 0.9232
val Loss: 0.2981 Acc: 0.9112
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2434 Acc: 0.9270
val Loss: 0.3148 Acc: 0.9060
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2471 Acc: 0.9256
val Loss: 0.2902 Acc: 0.9144
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2371 Acc: 0.9287
val Loss: 0.3203 Acc: 0.9064
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2336 Acc: 0.9297
val Loss: 0.2608 Acc: 0.9220
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2360 Acc: 0.9289
val Loss: 0.2999 Acc: 0.9100
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2257 Acc: 0.9325
val Loss: 0.2450 Acc: 0.9276
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1980 Acc: 0.9413
val Loss: 0.2319 Acc: 0.9333
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1848 Acc: 0.9463
val Loss: 0.2266 Acc: 0.9339
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1801 Acc: 0.9477
val Loss: 0.2177 Acc: 0.9381
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1788 Acc: 0.9477
val Loss: 0.2227 Acc: 0.9380
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1796 Acc: 0.9481
val Loss: 0.2247 Acc: 0.9357
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1761 Acc: 0.9500
val Loss: 0.2223 Acc: 0.9361
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1797 Acc: 0.9483
val Loss: 0.2223 Acc: 0.9350
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1793 Acc: 0.9481
val Loss: 0.2206 Acc: 0.9370
Epoch finished in 0m 9s
Best validation accuracy: 0.9369880965381675
Model Test Accuracy:  0.9434157959434541
Pruning Epoch 3
++++++++++++++++++
number of weights to prune:  34265.0
Sparsity of Pruned Mask:  tensor(0.4880)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.8168 Acc: 0.4023
val Loss: 1.0390 Acc: 0.7415
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.6119 Acc: 0.8408
val Loss: 0.4337 Acc: 0.8736
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3626 Acc: 0.8925
val Loss: 0.3385 Acc: 0.8989
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3087 Acc: 0.9067
val Loss: 0.3058 Acc: 0.9094
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2815 Acc: 0.9146
val Loss: 0.3276 Acc: 0.9022
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2652 Acc: 0.9195
val Loss: 0.3441 Acc: 0.8976
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2561 Acc: 0.9239
val Loss: 0.2991 Acc: 0.9111
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2490 Acc: 0.9240
val Loss: 0.3207 Acc: 0.9055
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2453 Acc: 0.9256
val Loss: 0.2926 Acc: 0.9125
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2387 Acc: 0.9281
val Loss: 0.2825 Acc: 0.9151
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2353 Acc: 0.9294
val Loss: 0.2819 Acc: 0.9163
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2313 Acc: 0.9304
val Loss: 0.2841 Acc: 0.9162
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2284 Acc: 0.9315
val Loss: 0.2928 Acc: 0.9145
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2256 Acc: 0.9316
val Loss: 0.2823 Acc: 0.9149
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2266 Acc: 0.9312
val Loss: 0.2757 Acc: 0.9168
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2195 Acc: 0.9339
val Loss: 0.2783 Acc: 0.9175
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2189 Acc: 0.9344
val Loss: 0.2393 Acc: 0.9293
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1888 Acc: 0.9443
val Loss: 0.2262 Acc: 0.9348
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1793 Acc: 0.9485
val Loss: 0.2255 Acc: 0.9340
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1749 Acc: 0.9493
val Loss: 0.2183 Acc: 0.9379
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1725 Acc: 0.9498
val Loss: 0.2223 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1717 Acc: 0.9507
val Loss: 0.2204 Acc: 0.9376
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1708 Acc: 0.9502
val Loss: 0.2192 Acc: 0.9361
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1731 Acc: 0.9492
val Loss: 0.2175 Acc: 0.9370
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1700 Acc: 0.9512
val Loss: 0.2206 Acc: 0.9368
Epoch finished in 0m 9s
Best validation accuracy: 0.9368242874303812
Model Test Accuracy:  0.9433005531653349
Pruning Epoch 4
++++++++++++++++++
number of weights to prune:  27412.0
Sparsity of Pruned Mask:  tensor(0.5904)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6643 Acc: 0.4907
val Loss: 0.8445 Acc: 0.8064
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5375 Acc: 0.8618
val Loss: 0.4015 Acc: 0.8859
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3345 Acc: 0.9038
val Loss: 0.3176 Acc: 0.9034
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2853 Acc: 0.9134
val Loss: 0.3040 Acc: 0.9088
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2614 Acc: 0.9213
val Loss: 0.2934 Acc: 0.9146
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2503 Acc: 0.9252
val Loss: 0.2777 Acc: 0.9179
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2421 Acc: 0.9273
val Loss: 0.3027 Acc: 0.9079
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2332 Acc: 0.9304
val Loss: 0.2699 Acc: 0.9197
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2308 Acc: 0.9305
val Loss: 0.2790 Acc: 0.9168
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2275 Acc: 0.9315
val Loss: 0.2811 Acc: 0.9166
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2230 Acc: 0.9339
val Loss: 0.2913 Acc: 0.9138
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2228 Acc: 0.9333
val Loss: 0.2810 Acc: 0.9156
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2201 Acc: 0.9344
val Loss: 0.2727 Acc: 0.9213
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2155 Acc: 0.9347
val Loss: 0.2646 Acc: 0.9230
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2154 Acc: 0.9359
val Loss: 0.2814 Acc: 0.9161
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2134 Acc: 0.9351
val Loss: 0.2629 Acc: 0.9228
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2091 Acc: 0.9376
val Loss: 0.2367 Acc: 0.9321
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1813 Acc: 0.9468
val Loss: 0.2233 Acc: 0.9352
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1733 Acc: 0.9501
val Loss: 0.2206 Acc: 0.9362
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1691 Acc: 0.9503
val Loss: 0.2174 Acc: 0.9381
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1675 Acc: 0.9509
val Loss: 0.2195 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1652 Acc: 0.9523
val Loss: 0.2152 Acc: 0.9383
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1651 Acc: 0.9524
val Loss: 0.2160 Acc: 0.9378
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1661 Acc: 0.9515
val Loss: 0.2149 Acc: 0.9376
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1657 Acc: 0.9521
val Loss: 0.2168 Acc: 0.9380
Epoch finished in 0m 9s
Best validation accuracy: 0.9379709511848859
Model Test Accuracy:  0.946757836508912
Pruning Epoch 5
++++++++++++++++++
number of weights to prune:  21929.0
Sparsity of Pruned Mask:  tensor(0.6723)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.5922 Acc: 0.5256
val Loss: 0.7778 Acc: 0.8226
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5049 Acc: 0.8715
val Loss: 0.3847 Acc: 0.8933
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3152 Acc: 0.9074
val Loss: 0.3136 Acc: 0.9074
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2659 Acc: 0.9201
val Loss: 0.2827 Acc: 0.9149
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2497 Acc: 0.9245
val Loss: 0.2788 Acc: 0.9156
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2336 Acc: 0.9301
val Loss: 0.2772 Acc: 0.9163
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2296 Acc: 0.9311
val Loss: 0.2857 Acc: 0.9148
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2278 Acc: 0.9329
val Loss: 0.2934 Acc: 0.9139
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2166 Acc: 0.9344
val Loss: 0.2918 Acc: 0.9111
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2208 Acc: 0.9343
val Loss: 0.2696 Acc: 0.9221
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2174 Acc: 0.9354
val Loss: 0.2711 Acc: 0.9212
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2159 Acc: 0.9362
val Loss: 0.2762 Acc: 0.9186
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2141 Acc: 0.9350
val Loss: 0.2744 Acc: 0.9180
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2159 Acc: 0.9357
val Loss: 0.2813 Acc: 0.9172
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2113 Acc: 0.9356
val Loss: 0.2720 Acc: 0.9214
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2093 Acc: 0.9372
val Loss: 0.2711 Acc: 0.9232
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2030 Acc: 0.9392
val Loss: 0.2389 Acc: 0.9317
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1802 Acc: 0.9473
val Loss: 0.2230 Acc: 0.9356
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1712 Acc: 0.9509
val Loss: 0.2183 Acc: 0.9373
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1657 Acc: 0.9527
val Loss: 0.2214 Acc: 0.9386
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1635 Acc: 0.9523
val Loss: 0.2142 Acc: 0.9388
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1636 Acc: 0.9525
val Loss: 0.2188 Acc: 0.9381
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1657 Acc: 0.9525
val Loss: 0.2173 Acc: 0.9375
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1637 Acc: 0.9529
val Loss: 0.2187 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1629 Acc: 0.9527
val Loss: 0.2152 Acc: 0.9375
Epoch finished in 0m 9s
Best validation accuracy: 0.9375341268974555
Model Test Accuracy:  0.9501382913337431
Pruning Epoch 6
++++++++++++++++++
number of weights to prune:  17543.0
Sparsity of Pruned Mask:  tensor(0.7379)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.5557 Acc: 0.5510
val Loss: 0.7700 Acc: 0.8308
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.4969 Acc: 0.8755
val Loss: 0.3848 Acc: 0.8927
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3112 Acc: 0.9094
val Loss: 0.2955 Acc: 0.9123
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2630 Acc: 0.9227
val Loss: 0.2832 Acc: 0.9149
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2382 Acc: 0.9294
val Loss: 0.2838 Acc: 0.9140
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2299 Acc: 0.9313
val Loss: 0.2876 Acc: 0.9147
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2240 Acc: 0.9327
val Loss: 0.2643 Acc: 0.9224
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2183 Acc: 0.9333
val Loss: 0.2741 Acc: 0.9190
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2169 Acc: 0.9353
val Loss: 0.3071 Acc: 0.9083
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2102 Acc: 0.9364
val Loss: 0.2773 Acc: 0.9198
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2109 Acc: 0.9366
val Loss: 0.2605 Acc: 0.9225
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2092 Acc: 0.9377
val Loss: 0.2504 Acc: 0.9265
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2072 Acc: 0.9381
val Loss: 0.2792 Acc: 0.9182
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2062 Acc: 0.9387
val Loss: 0.2703 Acc: 0.9191
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2059 Acc: 0.9383
val Loss: 0.2924 Acc: 0.9134
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2049 Acc: 0.9384
val Loss: 0.2676 Acc: 0.9233
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2048 Acc: 0.9382
val Loss: 0.2420 Acc: 0.9308
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1798 Acc: 0.9461
val Loss: 0.2271 Acc: 0.9352
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1680 Acc: 0.9511
val Loss: 0.2210 Acc: 0.9380
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1643 Acc: 0.9523
val Loss: 0.2201 Acc: 0.9375
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1629 Acc: 0.9532
val Loss: 0.2162 Acc: 0.9386
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1626 Acc: 0.9522
val Loss: 0.2223 Acc: 0.9366
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1640 Acc: 0.9532
val Loss: 0.2204 Acc: 0.9355
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1614 Acc: 0.9531
val Loss: 0.2208 Acc: 0.9377
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1623 Acc: 0.9529
val Loss: 0.2176 Acc: 0.9375
Epoch finished in 0m 9s
Best validation accuracy: 0.9375341268974555
Model Test Accuracy:  0.9456438229870927
Pruning Epoch 7
++++++++++++++++++
number of weights to prune:  14034.0
Sparsity of Pruned Mask:  tensor(0.7903)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.5397 Acc: 0.5540
val Loss: 0.7543 Acc: 0.8317
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.4927 Acc: 0.8768
val Loss: 0.3663 Acc: 0.8967
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3055 Acc: 0.9120
val Loss: 0.2962 Acc: 0.9118
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2557 Acc: 0.9245
val Loss: 0.2866 Acc: 0.9143
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2359 Acc: 0.9297
val Loss: 0.2785 Acc: 0.9183
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2254 Acc: 0.9324
val Loss: 0.2594 Acc: 0.9262
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2192 Acc: 0.9344
val Loss: 0.2774 Acc: 0.9186
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2163 Acc: 0.9360
val Loss: 0.2706 Acc: 0.9181
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2131 Acc: 0.9357
val Loss: 0.2617 Acc: 0.9251
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2117 Acc: 0.9360
val Loss: 0.2804 Acc: 0.9165
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2098 Acc: 0.9375
val Loss: 0.2770 Acc: 0.9194
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2087 Acc: 0.9376
val Loss: 0.3102 Acc: 0.9089
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2059 Acc: 0.9388
val Loss: 0.3050 Acc: 0.9083
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2061 Acc: 0.9385
val Loss: 0.3175 Acc: 0.9077
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2030 Acc: 0.9387
val Loss: 0.2650 Acc: 0.9243
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2021 Acc: 0.9389
val Loss: 0.2654 Acc: 0.9252
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2025 Acc: 0.9382
val Loss: 0.2435 Acc: 0.9284
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1769 Acc: 0.9483
val Loss: 0.2300 Acc: 0.9346
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1702 Acc: 0.9507
val Loss: 0.2208 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1634 Acc: 0.9523
val Loss: 0.2201 Acc: 0.9393
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1643 Acc: 0.9520
val Loss: 0.2166 Acc: 0.9370
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1636 Acc: 0.9523
val Loss: 0.2198 Acc: 0.9369
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1610 Acc: 0.9530
val Loss: 0.2182 Acc: 0.9367
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1617 Acc: 0.9534
val Loss: 0.2215 Acc: 0.9362
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1607 Acc: 0.9536
val Loss: 0.2197 Acc: 0.9384
Epoch finished in 0m 9s
Best validation accuracy: 0.9383531724363875
Model Test Accuracy:  0.9441072526121695
Pruning Epoch 8
++++++++++++++++++
number of weights to prune:  11227.0
Sparsity of Pruned Mask:  tensor(0.8322)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.5528 Acc: 0.5530
val Loss: 0.7746 Acc: 0.8261
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.4979 Acc: 0.8762
val Loss: 0.3724 Acc: 0.8949
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3065 Acc: 0.9119
val Loss: 0.2994 Acc: 0.9113
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2593 Acc: 0.9216
val Loss: 0.2761 Acc: 0.9173
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2360 Acc: 0.9292
val Loss: 0.2694 Acc: 0.9193
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2256 Acc: 0.9332
val Loss: 0.2665 Acc: 0.9196
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2174 Acc: 0.9341
val Loss: 0.2748 Acc: 0.9169
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2157 Acc: 0.9347
val Loss: 0.2738 Acc: 0.9193
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2136 Acc: 0.9362
val Loss: 0.2608 Acc: 0.9243
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2107 Acc: 0.9367
val Loss: 0.2714 Acc: 0.9209
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2103 Acc: 0.9364
val Loss: 0.2634 Acc: 0.9210
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2075 Acc: 0.9383
val Loss: 0.2855 Acc: 0.9150
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2107 Acc: 0.9380
val Loss: 0.2845 Acc: 0.9176
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2036 Acc: 0.9392
val Loss: 0.2776 Acc: 0.9183
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2071 Acc: 0.9384
val Loss: 0.2827 Acc: 0.9180
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2055 Acc: 0.9380
val Loss: 0.2753 Acc: 0.9225
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2019 Acc: 0.9403
val Loss: 0.2386 Acc: 0.9326
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1778 Acc: 0.9474
val Loss: 0.2279 Acc: 0.9357
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1671 Acc: 0.9501
val Loss: 0.2230 Acc: 0.9364
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1684 Acc: 0.9509
val Loss: 0.2208 Acc: 0.9377
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1654 Acc: 0.9519
val Loss: 0.2212 Acc: 0.9381
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1637 Acc: 0.9522
val Loss: 0.2250 Acc: 0.9364
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1644 Acc: 0.9520
val Loss: 0.2184 Acc: 0.9391
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1629 Acc: 0.9525
val Loss: 0.2227 Acc: 0.9368
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1618 Acc: 0.9534
val Loss: 0.2198 Acc: 0.9388
Epoch finished in 0m 9s
Best validation accuracy: 0.9387899967238179
Model Test Accuracy:  0.9465657652120466
Pruning Epoch 9
++++++++++++++++++
number of weights to prune:  8982.0
Sparsity of Pruned Mask:  tensor(0.8658)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.5898 Acc: 0.5332
val Loss: 0.7759 Acc: 0.8355
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.4989 Acc: 0.8773
val Loss: 0.3651 Acc: 0.8969
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3111 Acc: 0.9108
val Loss: 0.2929 Acc: 0.9127
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2600 Acc: 0.9240
val Loss: 0.2764 Acc: 0.9150
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2389 Acc: 0.9281
val Loss: 0.3056 Acc: 0.9091
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2302 Acc: 0.9309
val Loss: 0.2681 Acc: 0.9216
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2234 Acc: 0.9330
val Loss: 0.3078 Acc: 0.9080
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2175 Acc: 0.9349
val Loss: 0.2586 Acc: 0.9267
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2144 Acc: 0.9360
val Loss: 0.2530 Acc: 0.9247
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2152 Acc: 0.9350
val Loss: 0.2843 Acc: 0.9159
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2121 Acc: 0.9370
val Loss: 0.2622 Acc: 0.9220
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2108 Acc: 0.9363
val Loss: 0.2902 Acc: 0.9145
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2124 Acc: 0.9364
val Loss: 0.2680 Acc: 0.9223
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2111 Acc: 0.9365
val Loss: 0.2705 Acc: 0.9216
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2070 Acc: 0.9393
val Loss: 0.2645 Acc: 0.9237
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2056 Acc: 0.9388
val Loss: 0.2574 Acc: 0.9254
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2088 Acc: 0.9370
val Loss: 0.2382 Acc: 0.9317
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1818 Acc: 0.9469
val Loss: 0.2269 Acc: 0.9349
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1750 Acc: 0.9492
val Loss: 0.2223 Acc: 0.9380
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1717 Acc: 0.9489
val Loss: 0.2207 Acc: 0.9386
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1686 Acc: 0.9504
val Loss: 0.2171 Acc: 0.9385
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1675 Acc: 0.9509
val Loss: 0.2176 Acc: 0.9387
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1703 Acc: 0.9497
val Loss: 0.2189 Acc: 0.9390
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1686 Acc: 0.9508
val Loss: 0.2176 Acc: 0.9390
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1672 Acc: 0.9510
val Loss: 0.2203 Acc: 0.9373
Epoch finished in 0m 9s
Best validation accuracy: 0.9373157147537403
Model Test Accuracy:  0.9461816226183158
Pruning Epoch 10
++++++++++++++++++
number of weights to prune:  7185.0
Sparsity of Pruned Mask:  tensor(0.8926)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.6004 Acc: 0.5269
val Loss: 0.8034 Acc: 0.8219
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5097 Acc: 0.8760
val Loss: 0.3732 Acc: 0.8953
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3137 Acc: 0.9092
val Loss: 0.3064 Acc: 0.9082
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2631 Acc: 0.9230
val Loss: 0.2772 Acc: 0.9164
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2447 Acc: 0.9271
val Loss: 0.2708 Acc: 0.9186
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2320 Acc: 0.9313
val Loss: 0.2631 Acc: 0.9218
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2276 Acc: 0.9318
val Loss: 0.2636 Acc: 0.9233
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2249 Acc: 0.9335
val Loss: 0.2699 Acc: 0.9213
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2202 Acc: 0.9342
val Loss: 0.2655 Acc: 0.9214
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2227 Acc: 0.9332
val Loss: 0.3087 Acc: 0.9073
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2196 Acc: 0.9343
val Loss: 0.2707 Acc: 0.9223
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2192 Acc: 0.9345
val Loss: 0.2633 Acc: 0.9228
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2158 Acc: 0.9351
val Loss: 0.2662 Acc: 0.9232
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2154 Acc: 0.9351
val Loss: 0.2765 Acc: 0.9190
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2179 Acc: 0.9339
val Loss: 0.2745 Acc: 0.9185
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2167 Acc: 0.9355
val Loss: 0.2583 Acc: 0.9271
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2139 Acc: 0.9354
val Loss: 0.2488 Acc: 0.9270
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1924 Acc: 0.9428
val Loss: 0.2329 Acc: 0.9331
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1811 Acc: 0.9465
val Loss: 0.2297 Acc: 0.9335
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1776 Acc: 0.9477
val Loss: 0.2262 Acc: 0.9358
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1755 Acc: 0.9481
val Loss: 0.2234 Acc: 0.9360
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1753 Acc: 0.9493
val Loss: 0.2214 Acc: 0.9382
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1752 Acc: 0.9494
val Loss: 0.2247 Acc: 0.9374
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1748 Acc: 0.9492
val Loss: 0.2227 Acc: 0.9345
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1736 Acc: 0.9493
val Loss: 0.2226 Acc: 0.9361
Epoch finished in 0m 9s
Best validation accuracy: 0.9360598449273779
Model Test Accuracy:  0.9432621389059618
Pruning Epoch 11
++++++++++++++++++
number of weights to prune:  5748.0
Sparsity of Pruned Mask:  tensor(0.9141)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.7242 Acc: 0.4679
val Loss: 0.9277 Acc: 0.8044
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5552 Acc: 0.8682
val Loss: 0.3954 Acc: 0.8918
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3249 Acc: 0.9087
val Loss: 0.3038 Acc: 0.9115
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2695 Acc: 0.9199
val Loss: 0.2857 Acc: 0.9156
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2497 Acc: 0.9254
val Loss: 0.2664 Acc: 0.9215
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2387 Acc: 0.9280
val Loss: 0.2873 Acc: 0.9155
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2329 Acc: 0.9308
val Loss: 0.3025 Acc: 0.9105
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2303 Acc: 0.9317
val Loss: 0.2718 Acc: 0.9200
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2276 Acc: 0.9317
val Loss: 0.2973 Acc: 0.9100
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2269 Acc: 0.9313
val Loss: 0.3020 Acc: 0.9117
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2224 Acc: 0.9329
val Loss: 0.2839 Acc: 0.9178
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2228 Acc: 0.9328
val Loss: 0.3128 Acc: 0.9086
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2214 Acc: 0.9331
val Loss: 0.2812 Acc: 0.9192
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2224 Acc: 0.9324
val Loss: 0.3139 Acc: 0.9078
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2207 Acc: 0.9335
val Loss: 0.2787 Acc: 0.9177
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2235 Acc: 0.9329
val Loss: 0.2904 Acc: 0.9132
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2152 Acc: 0.9353
val Loss: 0.2413 Acc: 0.9309
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1964 Acc: 0.9420
val Loss: 0.2316 Acc: 0.9347
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1872 Acc: 0.9454
val Loss: 0.2284 Acc: 0.9360
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1839 Acc: 0.9465
val Loss: 0.2280 Acc: 0.9345
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1826 Acc: 0.9471
val Loss: 0.2262 Acc: 0.9358
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1802 Acc: 0.9474
val Loss: 0.2250 Acc: 0.9358
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1792 Acc: 0.9479
val Loss: 0.2279 Acc: 0.9363
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1822 Acc: 0.9463
val Loss: 0.2277 Acc: 0.9344
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1807 Acc: 0.9470
val Loss: 0.2289 Acc: 0.9370
Epoch finished in 0m 9s
Best validation accuracy: 0.9370426995740964
Model Test Accuracy:  0.9446450522433927
Pruning Epoch 12
++++++++++++++++++
number of weights to prune:  4598.0
Sparsity of Pruned Mask:  tensor(0.9313)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.7620 Acc: 0.4492
val Loss: 0.9667 Acc: 0.7921
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.5832 Acc: 0.8620
val Loss: 0.4404 Acc: 0.8799
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3354 Acc: 0.9053
val Loss: 0.3115 Acc: 0.9083
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2808 Acc: 0.9177
val Loss: 0.2924 Acc: 0.9126
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2592 Acc: 0.9220
val Loss: 0.2842 Acc: 0.9159
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2500 Acc: 0.9270
val Loss: 0.2883 Acc: 0.9147
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2410 Acc: 0.9273
val Loss: 0.2793 Acc: 0.9184
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2364 Acc: 0.9287
val Loss: 0.2972 Acc: 0.9121
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2349 Acc: 0.9288
val Loss: 0.2737 Acc: 0.9198
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2351 Acc: 0.9295
val Loss: 0.2691 Acc: 0.9216
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2326 Acc: 0.9300
val Loss: 0.3244 Acc: 0.9039
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2351 Acc: 0.9300
val Loss: 0.3036 Acc: 0.9111
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2338 Acc: 0.9292
val Loss: 0.2901 Acc: 0.9165
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2313 Acc: 0.9308
val Loss: 0.3259 Acc: 0.9050
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2319 Acc: 0.9306
val Loss: 0.2895 Acc: 0.9137
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2346 Acc: 0.9284
val Loss: 0.2622 Acc: 0.9234
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2273 Acc: 0.9313
val Loss: 0.2485 Acc: 0.9287
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2029 Acc: 0.9389
val Loss: 0.2389 Acc: 0.9303
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1972 Acc: 0.9423
val Loss: 0.2367 Acc: 0.9300
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1917 Acc: 0.9441
val Loss: 0.2310 Acc: 0.9328
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1916 Acc: 0.9426
val Loss: 0.2316 Acc: 0.9329
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1927 Acc: 0.9440
val Loss: 0.2332 Acc: 0.9339
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1889 Acc: 0.9449
val Loss: 0.2331 Acc: 0.9332
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1898 Acc: 0.9439
val Loss: 0.2306 Acc: 0.9345
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1893 Acc: 0.9445
val Loss: 0.2320 Acc: 0.9332
Epoch finished in 0m 9s
Best validation accuracy: 0.9332204870590805
Model Test Accuracy:  0.9422249539028886
Pruning Epoch 13
++++++++++++++++++
number of weights to prune:  3678.0
Sparsity of Pruned Mask:  tensor(0.9450)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.8176 Acc: 0.4074
val Loss: 1.0678 Acc: 0.7500
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.6418 Acc: 0.8462
val Loss: 0.4353 Acc: 0.8810
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3567 Acc: 0.8986
val Loss: 0.3278 Acc: 0.9049
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2916 Acc: 0.9153
val Loss: 0.3043 Acc: 0.9102
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2663 Acc: 0.9206
val Loss: 0.3126 Acc: 0.9059
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2558 Acc: 0.9232
val Loss: 0.2861 Acc: 0.9143
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2510 Acc: 0.9242
val Loss: 0.2952 Acc: 0.9125
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2461 Acc: 0.9259
val Loss: 0.3154 Acc: 0.9054
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2462 Acc: 0.9253
val Loss: 0.2913 Acc: 0.9124
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2424 Acc: 0.9274
val Loss: 0.2776 Acc: 0.9177
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2456 Acc: 0.9259
val Loss: 0.2829 Acc: 0.9177
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2415 Acc: 0.9280
val Loss: 0.3050 Acc: 0.9092
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2392 Acc: 0.9284
val Loss: 0.2968 Acc: 0.9136
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2386 Acc: 0.9294
val Loss: 0.2890 Acc: 0.9151
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2404 Acc: 0.9274
val Loss: 0.2728 Acc: 0.9209
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2381 Acc: 0.9281
val Loss: 0.2756 Acc: 0.9198
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2359 Acc: 0.9292
val Loss: 0.2531 Acc: 0.9250
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2111 Acc: 0.9377
val Loss: 0.2412 Acc: 0.9289
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2060 Acc: 0.9397
val Loss: 0.2396 Acc: 0.9311
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2012 Acc: 0.9404
val Loss: 0.2394 Acc: 0.9303
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1983 Acc: 0.9417
val Loss: 0.2380 Acc: 0.9320
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1991 Acc: 0.9412
val Loss: 0.2375 Acc: 0.9311
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2001 Acc: 0.9415
val Loss: 0.2372 Acc: 0.9333
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1991 Acc: 0.9428
val Loss: 0.2361 Acc: 0.9315
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2001 Acc: 0.9413
val Loss: 0.2370 Acc: 0.9305
Epoch finished in 0m 9s
Best validation accuracy: 0.9305449382985694
Model Test Accuracy:  0.9400737553779962
Pruning Epoch 14
++++++++++++++++++
number of weights to prune:  2943.0
Sparsity of Pruned Mask:  tensor(0.9560)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 1.8713 Acc: 0.3864
val Loss: 1.1766 Acc: 0.7143
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.7000 Acc: 0.8323
val Loss: 0.4662 Acc: 0.8694
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3797 Acc: 0.8943
val Loss: 0.3528 Acc: 0.8973
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3106 Acc: 0.9095
val Loss: 0.3173 Acc: 0.9050
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2867 Acc: 0.9147
val Loss: 0.3104 Acc: 0.9079
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2694 Acc: 0.9204
val Loss: 0.3004 Acc: 0.9084
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2662 Acc: 0.9193
val Loss: 0.3204 Acc: 0.9032
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2587 Acc: 0.9229
val Loss: 0.3048 Acc: 0.9107
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2592 Acc: 0.9219
val Loss: 0.2891 Acc: 0.9147
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2583 Acc: 0.9219
val Loss: 0.3108 Acc: 0.9080
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2544 Acc: 0.9239
val Loss: 0.2814 Acc: 0.9179
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2573 Acc: 0.9226
val Loss: 0.3135 Acc: 0.9057
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2527 Acc: 0.9250
val Loss: 0.3102 Acc: 0.9081
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2529 Acc: 0.9242
val Loss: 0.2975 Acc: 0.9120
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2497 Acc: 0.9241
val Loss: 0.3070 Acc: 0.9072
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2517 Acc: 0.9247
val Loss: 0.2825 Acc: 0.9155
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2487 Acc: 0.9257
val Loss: 0.2653 Acc: 0.9218
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2251 Acc: 0.9332
val Loss: 0.2540 Acc: 0.9267
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2164 Acc: 0.9353
val Loss: 0.2495 Acc: 0.9278
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2125 Acc: 0.9378
val Loss: 0.2470 Acc: 0.9291
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2108 Acc: 0.9381
val Loss: 0.2412 Acc: 0.9314
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2091 Acc: 0.9384
val Loss: 0.2452 Acc: 0.9289
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2098 Acc: 0.9383
val Loss: 0.2417 Acc: 0.9299
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2109 Acc: 0.9379
val Loss: 0.2475 Acc: 0.9292
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2094 Acc: 0.9386
val Loss: 0.2423 Acc: 0.9298
Epoch finished in 0m 9s
Best validation accuracy: 0.9298350988314951
Model Test Accuracy:  0.9374615857406269
Pruning Epoch 15
++++++++++++++++++
number of weights to prune:  2354.0
Sparsity of Pruned Mask:  tensor(0.9648)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.0245 Acc: 0.3021
val Loss: 1.4685 Acc: 0.5597
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 0.8653 Acc: 0.7831
val Loss: 0.5190 Acc: 0.8604
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4171 Acc: 0.8853
val Loss: 0.3684 Acc: 0.8902
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3342 Acc: 0.9032
val Loss: 0.3378 Acc: 0.8981
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2989 Acc: 0.9119
val Loss: 0.3019 Acc: 0.9119
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2878 Acc: 0.9139
val Loss: 0.3114 Acc: 0.9086
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2789 Acc: 0.9147
val Loss: 0.3262 Acc: 0.9041
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2764 Acc: 0.9172
val Loss: 0.3201 Acc: 0.9068
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2710 Acc: 0.9181
val Loss: 0.3306 Acc: 0.9028
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2744 Acc: 0.9161
val Loss: 0.3259 Acc: 0.9031
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2687 Acc: 0.9189
val Loss: 0.3047 Acc: 0.9075
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2665 Acc: 0.9194
val Loss: 0.3130 Acc: 0.9073
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2655 Acc: 0.9199
val Loss: 0.3043 Acc: 0.9102
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2630 Acc: 0.9202
val Loss: 0.3181 Acc: 0.9057
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2649 Acc: 0.9208
val Loss: 0.3201 Acc: 0.9056
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2649 Acc: 0.9202
val Loss: 0.2923 Acc: 0.9126
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2585 Acc: 0.9220
val Loss: 0.2704 Acc: 0.9213
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2330 Acc: 0.9313
val Loss: 0.2612 Acc: 0.9242
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2264 Acc: 0.9335
val Loss: 0.2561 Acc: 0.9257
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2247 Acc: 0.9337
val Loss: 0.2532 Acc: 0.9263
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2231 Acc: 0.9350
val Loss: 0.2513 Acc: 0.9271
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2199 Acc: 0.9349
val Loss: 0.2535 Acc: 0.9259
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2226 Acc: 0.9344
val Loss: 0.2524 Acc: 0.9273
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2215 Acc: 0.9351
val Loss: 0.2559 Acc: 0.9251
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2204 Acc: 0.9354
val Loss: 0.2526 Acc: 0.9263
Epoch finished in 0m 9s
Best validation accuracy: 0.9262859014961232
Model Test Accuracy:  0.9340811309157959
Pruning Epoch 16
++++++++++++++++++
number of weights to prune:  1883.0
Sparsity of Pruned Mask:  tensor(0.9719)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.0891 Acc: 0.2647
val Loss: 1.6976 Acc: 0.4658
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.1138 Acc: 0.7056
val Loss: 0.6439 Acc: 0.8349
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.5059 Acc: 0.8636
val Loss: 0.4405 Acc: 0.8752
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3812 Acc: 0.8911
val Loss: 0.3924 Acc: 0.8852
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3371 Acc: 0.9012
val Loss: 0.3703 Acc: 0.8874
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3162 Acc: 0.9060
val Loss: 0.3516 Acc: 0.8928
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3042 Acc: 0.9086
val Loss: 0.3487 Acc: 0.8953
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2983 Acc: 0.9108
val Loss: 0.3320 Acc: 0.8987
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2931 Acc: 0.9119
val Loss: 0.3873 Acc: 0.8780
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2912 Acc: 0.9120
val Loss: 0.3256 Acc: 0.9018
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2863 Acc: 0.9135
val Loss: 0.3252 Acc: 0.9042
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2872 Acc: 0.9141
val Loss: 0.3674 Acc: 0.8894
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2796 Acc: 0.9168
val Loss: 0.3161 Acc: 0.9054
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2841 Acc: 0.9142
val Loss: 0.3293 Acc: 0.9029
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2804 Acc: 0.9148
val Loss: 0.3252 Acc: 0.9047
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2811 Acc: 0.9154
val Loss: 0.3313 Acc: 0.9003
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2776 Acc: 0.9172
val Loss: 0.2888 Acc: 0.9141
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2558 Acc: 0.9228
val Loss: 0.2700 Acc: 0.9219
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2448 Acc: 0.9265
val Loss: 0.2659 Acc: 0.9248
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2399 Acc: 0.9287
val Loss: 0.2639 Acc: 0.9230
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2396 Acc: 0.9291
val Loss: 0.2646 Acc: 0.9245
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2390 Acc: 0.9293
val Loss: 0.2653 Acc: 0.9237
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2377 Acc: 0.9295
val Loss: 0.2628 Acc: 0.9226
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2355 Acc: 0.9316
val Loss: 0.2602 Acc: 0.9263
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2371 Acc: 0.9302
val Loss: 0.2666 Acc: 0.9236
Epoch finished in 0m 9s
Best validation accuracy: 0.9236103527356121
Model Test Accuracy:  0.9327750460971111
Pruning Epoch 17
++++++++++++++++++
number of weights to prune:  1506.0
Sparsity of Pruned Mask:  tensor(0.9775)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.1134 Acc: 0.2571
val Loss: 1.8093 Acc: 0.3911
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.3232 Acc: 0.6064
val Loss: 0.8652 Acc: 0.7712
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.6556 Acc: 0.8254
val Loss: 0.5299 Acc: 0.8491
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4585 Acc: 0.8693
val Loss: 0.4278 Acc: 0.8705
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3923 Acc: 0.8852
val Loss: 0.4054 Acc: 0.8773
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3588 Acc: 0.8936
val Loss: 0.3885 Acc: 0.8819
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3413 Acc: 0.8964
val Loss: 0.3711 Acc: 0.8905
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3297 Acc: 0.9006
val Loss: 0.3364 Acc: 0.8977
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3231 Acc: 0.9028
val Loss: 0.3513 Acc: 0.8959
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3174 Acc: 0.9042
val Loss: 0.3429 Acc: 0.8977
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3112 Acc: 0.9069
val Loss: 0.3379 Acc: 0.8995
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3061 Acc: 0.9079
val Loss: 0.3375 Acc: 0.8984
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3039 Acc: 0.9075
val Loss: 0.3340 Acc: 0.9017
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3020 Acc: 0.9088
val Loss: 0.3979 Acc: 0.8800
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3036 Acc: 0.9083
val Loss: 0.3632 Acc: 0.8878
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2996 Acc: 0.9105
val Loss: 0.3991 Acc: 0.8798
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2951 Acc: 0.9105
val Loss: 0.3005 Acc: 0.9123
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2730 Acc: 0.9178
val Loss: 0.2879 Acc: 0.9152
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2636 Acc: 0.9223
val Loss: 0.2840 Acc: 0.9167
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2592 Acc: 0.9223
val Loss: 0.2785 Acc: 0.9196
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2579 Acc: 0.9237
val Loss: 0.2827 Acc: 0.9138
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2583 Acc: 0.9228
val Loss: 0.2817 Acc: 0.9167
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2545 Acc: 0.9248
val Loss: 0.2801 Acc: 0.9173
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2568 Acc: 0.9244
val Loss: 0.2834 Acc: 0.9174
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2552 Acc: 0.9237
val Loss: 0.2779 Acc: 0.9184
Epoch finished in 0m 9s
Best validation accuracy: 0.9184230643223763
Model Test Accuracy:  0.9280885064535955
Pruning Epoch 18
++++++++++++++++++
number of weights to prune:  1205.0
Sparsity of Pruned Mask:  tensor(0.9820)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.1472 Acc: 0.2366
val Loss: 1.8995 Acc: 0.3484
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.5650 Acc: 0.4958
val Loss: 1.1653 Acc: 0.6655
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 0.8503 Acc: 0.7700
val Loss: 0.6772 Acc: 0.8080
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5715 Acc: 0.8353
val Loss: 0.5330 Acc: 0.8360
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4769 Acc: 0.8578
val Loss: 0.4808 Acc: 0.8546
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4348 Acc: 0.8692
val Loss: 0.4532 Acc: 0.8595
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4051 Acc: 0.8774
val Loss: 0.4195 Acc: 0.8707
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3860 Acc: 0.8819
val Loss: 0.4183 Acc: 0.8714
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3734 Acc: 0.8876
val Loss: 0.4064 Acc: 0.8751
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3595 Acc: 0.8905
val Loss: 0.3801 Acc: 0.8838
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3519 Acc: 0.8920
val Loss: 0.3732 Acc: 0.8878
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3437 Acc: 0.8956
val Loss: 0.4043 Acc: 0.8728
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3432 Acc: 0.8953
val Loss: 0.4109 Acc: 0.8744
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3357 Acc: 0.8978
val Loss: 0.4127 Acc: 0.8728
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3285 Acc: 0.8992
val Loss: 0.3824 Acc: 0.8854
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3267 Acc: 0.9009
val Loss: 0.3635 Acc: 0.8898
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3211 Acc: 0.9026
val Loss: 0.3169 Acc: 0.9046
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2982 Acc: 0.9100
val Loss: 0.3034 Acc: 0.9108
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2877 Acc: 0.9140
val Loss: 0.3059 Acc: 0.9085
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2847 Acc: 0.9153
val Loss: 0.2993 Acc: 0.9114
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2859 Acc: 0.9151
val Loss: 0.2996 Acc: 0.9118
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2859 Acc: 0.9134
val Loss: 0.3016 Acc: 0.9102
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2835 Acc: 0.9152
val Loss: 0.2976 Acc: 0.9102
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2840 Acc: 0.9146
val Loss: 0.3007 Acc: 0.9082
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2850 Acc: 0.9137
val Loss: 0.2996 Acc: 0.9135
Epoch finished in 0m 9s
Best validation accuracy: 0.9134541880528557
Model Test Accuracy:  0.9154502151198524
Pruning Epoch 19
++++++++++++++++++
number of weights to prune:  963.0
Sparsity of Pruned Mask:  tensor(0.9856)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2033 Acc: 0.2055
val Loss: 2.0207 Acc: 0.2990
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.7612 Acc: 0.3944
val Loss: 1.4285 Acc: 0.5779
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 1.0701 Acc: 0.6996
val Loss: 0.8120 Acc: 0.7692
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.6775 Acc: 0.8065
val Loss: 0.5986 Acc: 0.8181
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5471 Acc: 0.8364
val Loss: 0.5322 Acc: 0.8373
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4910 Acc: 0.8510
val Loss: 0.5050 Acc: 0.8419
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4613 Acc: 0.8583
val Loss: 0.4587 Acc: 0.8544
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4400 Acc: 0.8642
val Loss: 0.4931 Acc: 0.8449
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4207 Acc: 0.8702
val Loss: 0.4690 Acc: 0.8521
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4104 Acc: 0.8734
val Loss: 0.4364 Acc: 0.8650
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3981 Acc: 0.8763
val Loss: 0.4315 Acc: 0.8693
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3884 Acc: 0.8809
val Loss: 0.3934 Acc: 0.8797
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3844 Acc: 0.8821
val Loss: 0.4178 Acc: 0.8712
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3724 Acc: 0.8837
val Loss: 0.4107 Acc: 0.8753
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3656 Acc: 0.8882
val Loss: 0.4177 Acc: 0.8702
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3627 Acc: 0.8898
val Loss: 0.3840 Acc: 0.8807
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3543 Acc: 0.8917
val Loss: 0.3505 Acc: 0.8928
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3312 Acc: 0.9003
val Loss: 0.3419 Acc: 0.8963
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3236 Acc: 0.9024
val Loss: 0.3326 Acc: 0.9006
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3165 Acc: 0.9050
val Loss: 0.3314 Acc: 0.9005
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3180 Acc: 0.9045
val Loss: 0.3268 Acc: 0.9025
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3140 Acc: 0.9055
val Loss: 0.3316 Acc: 0.9010
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3184 Acc: 0.9049
val Loss: 0.3257 Acc: 0.9023
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3170 Acc: 0.9049
val Loss: 0.3292 Acc: 0.8998
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3160 Acc: 0.9049
val Loss: 0.3322 Acc: 0.9008
Epoch finished in 0m 9s
Best validation accuracy: 0.9008408867533035
Model Test Accuracy:  0.9048862937922556
Pruning Epoch 20
++++++++++++++++++
number of weights to prune:  771.0
Sparsity of Pruned Mask:  tensor(0.9885)
[10, 15, 20]
Warmup
Training Epoch 0/24
********************
train Loss: 2.2000 Acc: 0.2012
val Loss: 2.0274 Acc: 0.2962
Epoch finished in 0m 9s
Training Epoch 1/24
********************
Warmup
train Loss: 1.8570 Acc: 0.3477
val Loss: 1.6782 Acc: 0.4292
Epoch finished in 0m 9s
Training Epoch 2/24
********************
Warmup
train Loss: 1.3295 Acc: 0.5828
val Loss: 0.9996 Acc: 0.7092
Epoch finished in 0m 9s
Training Epoch 3/24
********************
Warmup
train Loss: 0.8038 Acc: 0.7698
val Loss: 0.7081 Acc: 0.7838
Epoch finished in 0m 9s
Training Epoch 4/24
********************
Warmup
train Loss: 0.6039 Acc: 0.8201
val Loss: 0.6211 Acc: 0.8087
Epoch finished in 0m 9s
Training Epoch 5/24
********************
Warmup
train Loss: 0.5294 Acc: 0.8363
val Loss: 0.5361 Acc: 0.8337
Epoch finished in 0m 9s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4849 Acc: 0.8526
val Loss: 0.5414 Acc: 0.8289
Epoch finished in 0m 9s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4663 Acc: 0.8563
val Loss: 0.4639 Acc: 0.8531
Epoch finished in 0m 9s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4472 Acc: 0.8615
val Loss: 0.4565 Acc: 0.8592
Epoch finished in 0m 9s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4294 Acc: 0.8668
val Loss: 0.4742 Acc: 0.8499
Epoch finished in 0m 9s
Training Epoch 10/24
********************
Warmup
train Loss: 0.4180 Acc: 0.8711
val Loss: 0.5022 Acc: 0.8412
Epoch finished in 0m 9s
Training Epoch 11/24
********************
Warmup
train Loss: 0.4108 Acc: 0.8730
val Loss: 0.4202 Acc: 0.8687
Epoch finished in 0m 9s
Training Epoch 12/24
********************
Warmup
train Loss: 0.4019 Acc: 0.8755
val Loss: 0.4483 Acc: 0.8620
Epoch finished in 0m 9s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3994 Acc: 0.8768
val Loss: 0.4087 Acc: 0.8729
Epoch finished in 0m 9s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3917 Acc: 0.8788
val Loss: 0.4324 Acc: 0.8639
Epoch finished in 0m 9s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3846 Acc: 0.8806
val Loss: 0.4506 Acc: 0.8573
Epoch finished in 0m 9s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3833 Acc: 0.8805
val Loss: 0.3696 Acc: 0.8860
Epoch finished in 0m 9s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3562 Acc: 0.8900
val Loss: 0.3577 Acc: 0.8908
Epoch finished in 0m 9s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3461 Acc: 0.8934
val Loss: 0.3552 Acc: 0.8908
Epoch finished in 0m 9s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3431 Acc: 0.8949
val Loss: 0.3495 Acc: 0.8930
Epoch finished in 0m 9s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3410 Acc: 0.8951
val Loss: 0.3526 Acc: 0.8924
Epoch finished in 0m 9s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3431 Acc: 0.8954
val Loss: 0.3478 Acc: 0.8953
Epoch finished in 0m 9s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3381 Acc: 0.8952
val Loss: 0.3522 Acc: 0.8916
Epoch finished in 0m 9s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3375 Acc: 0.8967
val Loss: 0.3499 Acc: 0.8930
Epoch finished in 0m 9s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3382 Acc: 0.8966
val Loss: 0.3474 Acc: 0.8948
Epoch finished in 0m 9s
Best validation accuracy: 0.8947799497652069
Model Test Accuracy:  0.8957437000614628
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2535 Acc: 0.1724
val Loss: 2.2221 Acc: 0.1956
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.0391 Acc: 0.2750
val Loss: 1.8551 Acc: 0.3634
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 1.1371 Acc: 0.6136
val Loss: 0.7293 Acc: 0.7662
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5609 Acc: 0.8233
val Loss: 0.5681 Acc: 0.8236
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4334 Acc: 0.8656
val Loss: 0.4029 Acc: 0.8782
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3755 Acc: 0.8867
val Loss: 0.4117 Acc: 0.8723
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3431 Acc: 0.8959
val Loss: 0.3560 Acc: 0.8898
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3142 Acc: 0.9043
val Loss: 0.3782 Acc: 0.8866
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2942 Acc: 0.9121
val Loss: 0.3255 Acc: 0.9032
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2799 Acc: 0.9162
val Loss: 0.2998 Acc: 0.9120
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2667 Acc: 0.9199
val Loss: 0.3211 Acc: 0.9054
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2584 Acc: 0.9215
val Loss: 0.2965 Acc: 0.9125
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2459 Acc: 0.9271
val Loss: 0.3128 Acc: 0.9044
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2408 Acc: 0.9278
val Loss: 0.2946 Acc: 0.9145
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2310 Acc: 0.9311
val Loss: 0.3249 Acc: 0.9026
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2239 Acc: 0.9335
val Loss: 0.2677 Acc: 0.9219
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2222 Acc: 0.9341
val Loss: 0.2496 Acc: 0.9272
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1849 Acc: 0.9448
val Loss: 0.2301 Acc: 0.9350
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1734 Acc: 0.9485
val Loss: 0.2280 Acc: 0.9362
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1684 Acc: 0.9502
val Loss: 0.2226 Acc: 0.9367
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1652 Acc: 0.9518
val Loss: 0.2214 Acc: 0.9369
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1673 Acc: 0.9513
val Loss: 0.2250 Acc: 0.9369
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1661 Acc: 0.9511
val Loss: 0.2225 Acc: 0.9369
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1673 Acc: 0.9507
val Loss: 0.2204 Acc: 0.9392
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1661 Acc: 0.9514
val Loss: 0.2193 Acc: 0.9371
Epoch finished in 0m 12s
Best validation accuracy: 0.9370973026100251
Before Pruning
++++++++++++++++++
Model Test Accuracy:  0.9463352796558081
Pruning Epoch 1
++++++++++++++++++
number of weights to prune:  53540.0
Sparsity of Pruned Mask:  tensor(0.2000)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1890 Acc: 0.2145
val Loss: 1.9753 Acc: 0.3090
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.1858 Acc: 0.5949
val Loss: 0.5886 Acc: 0.8149
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4650 Acc: 0.8550
val Loss: 0.4245 Acc: 0.8703
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3653 Acc: 0.8889
val Loss: 0.4035 Acc: 0.8839
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3259 Acc: 0.9023
val Loss: 0.3772 Acc: 0.8857
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2990 Acc: 0.9106
val Loss: 0.3381 Acc: 0.8990
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2761 Acc: 0.9176
val Loss: 0.3409 Acc: 0.8964
Epoch finished in 0m 13s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2598 Acc: 0.9224
val Loss: 0.2885 Acc: 0.9148
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2504 Acc: 0.9250
val Loss: 0.3278 Acc: 0.9084
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2412 Acc: 0.9281
val Loss: 0.2720 Acc: 0.9198
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2322 Acc: 0.9312
val Loss: 0.2654 Acc: 0.9215
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2273 Acc: 0.9334
val Loss: 0.2600 Acc: 0.9254
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2225 Acc: 0.9341
val Loss: 0.2719 Acc: 0.9253
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2143 Acc: 0.9356
val Loss: 0.2854 Acc: 0.9180
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2141 Acc: 0.9364
val Loss: 0.3059 Acc: 0.9077
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2082 Acc: 0.9381
val Loss: 0.2608 Acc: 0.9239
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1985 Acc: 0.9422
val Loss: 0.2338 Acc: 0.9331
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1671 Acc: 0.9521
val Loss: 0.2195 Acc: 0.9394
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1590 Acc: 0.9541
val Loss: 0.2154 Acc: 0.9398
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1543 Acc: 0.9558
val Loss: 0.2124 Acc: 0.9410
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1530 Acc: 0.9562
val Loss: 0.2132 Acc: 0.9407
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1518 Acc: 0.9569
val Loss: 0.2178 Acc: 0.9391
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1493 Acc: 0.9570
val Loss: 0.2173 Acc: 0.9391
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1508 Acc: 0.9569
val Loss: 0.2162 Acc: 0.9383
Epoch finished in 0m 13s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1516 Acc: 0.9572
val Loss: 0.2135 Acc: 0.9398
Epoch finished in 0m 12s
Best validation accuracy: 0.9397728513705362
Model Test Accuracy:  0.9447218807621388
Pruning Epoch 2
++++++++++++++++++
number of weights to prune:  42831.0
Sparsity of Pruned Mask:  tensor(0.3600)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.0306 Acc: 0.2835
val Loss: 1.1157 Acc: 0.6301
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5337 Acc: 0.8310
val Loss: 0.4263 Acc: 0.8667
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3491 Acc: 0.8943
val Loss: 0.3735 Acc: 0.8944
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2971 Acc: 0.9106
val Loss: 0.3264 Acc: 0.9058
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2722 Acc: 0.9179
val Loss: 0.3102 Acc: 0.9083
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2530 Acc: 0.9248
val Loss: 0.3017 Acc: 0.9117
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2412 Acc: 0.9269
val Loss: 0.2734 Acc: 0.9216
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2290 Acc: 0.9328
val Loss: 0.2902 Acc: 0.9143
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2249 Acc: 0.9334
val Loss: 0.3097 Acc: 0.9151
Epoch finished in 0m 13s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2173 Acc: 0.9354
val Loss: 0.2906 Acc: 0.9139
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2121 Acc: 0.9383
val Loss: 0.2865 Acc: 0.9237
Epoch finished in 0m 13s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2073 Acc: 0.9375
val Loss: 0.2706 Acc: 0.9248
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2010 Acc: 0.9403
val Loss: 0.2920 Acc: 0.9117
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1978 Acc: 0.9416
val Loss: 0.2595 Acc: 0.9261
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1950 Acc: 0.9410
val Loss: 0.2611 Acc: 0.9248
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1917 Acc: 0.9442
val Loss: 0.2584 Acc: 0.9256
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1859 Acc: 0.9451
val Loss: 0.2264 Acc: 0.9366
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1558 Acc: 0.9548
val Loss: 0.2205 Acc: 0.9373
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1489 Acc: 0.9574
val Loss: 0.2165 Acc: 0.9403
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1428 Acc: 0.9583
val Loss: 0.2141 Acc: 0.9406
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1396 Acc: 0.9600
val Loss: 0.2105 Acc: 0.9411
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1414 Acc: 0.9590
val Loss: 0.2114 Acc: 0.9399
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1416 Acc: 0.9590
val Loss: 0.2119 Acc: 0.9399
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1404 Acc: 0.9592
val Loss: 0.2081 Acc: 0.9428
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1389 Acc: 0.9595
val Loss: 0.2115 Acc: 0.9428
Epoch finished in 0m 12s
Best validation accuracy: 0.9427760183466201
Model Test Accuracy:  0.9487553779963122
Pruning Epoch 3
++++++++++++++++++
number of weights to prune:  34265.0
Sparsity of Pruned Mask:  tensor(0.4880)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.8047 Acc: 0.3742
val Loss: 0.6376 Acc: 0.7957
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4082 Acc: 0.8753
val Loss: 0.3719 Acc: 0.8887
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2994 Acc: 0.9101
val Loss: 0.3096 Acc: 0.9081
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2593 Acc: 0.9229
val Loss: 0.2940 Acc: 0.9129
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2434 Acc: 0.9281
val Loss: 0.2928 Acc: 0.9129
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2252 Acc: 0.9335
val Loss: 0.2935 Acc: 0.9145
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2163 Acc: 0.9364
val Loss: 0.2817 Acc: 0.9211
Epoch finished in 0m 13s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2081 Acc: 0.9390
val Loss: 0.2721 Acc: 0.9235
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2041 Acc: 0.9392
val Loss: 0.2671 Acc: 0.9206
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1992 Acc: 0.9410
val Loss: 0.2797 Acc: 0.9219
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1954 Acc: 0.9425
val Loss: 0.2866 Acc: 0.9168
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1909 Acc: 0.9434
val Loss: 0.2796 Acc: 0.9167
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1901 Acc: 0.9439
val Loss: 0.2533 Acc: 0.9254
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1843 Acc: 0.9450
val Loss: 0.2591 Acc: 0.9248
Epoch finished in 0m 13s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1868 Acc: 0.9447
val Loss: 0.2756 Acc: 0.9215
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1827 Acc: 0.9461
val Loss: 0.2570 Acc: 0.9262
Epoch finished in 0m 13s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1823 Acc: 0.9460
val Loss: 0.2370 Acc: 0.9355
Epoch finished in 0m 13s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1482 Acc: 0.9569
val Loss: 0.2162 Acc: 0.9399
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1386 Acc: 0.9589
val Loss: 0.2146 Acc: 0.9408
Epoch finished in 0m 13s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1366 Acc: 0.9597
val Loss: 0.2127 Acc: 0.9415
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1330 Acc: 0.9618
val Loss: 0.2108 Acc: 0.9415
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1333 Acc: 0.9611
val Loss: 0.2128 Acc: 0.9429
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1323 Acc: 0.9609
val Loss: 0.2153 Acc: 0.9409
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1332 Acc: 0.9620
val Loss: 0.2116 Acc: 0.9410
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1339 Acc: 0.9610
val Loss: 0.2071 Acc: 0.9439
Epoch finished in 0m 12s
Best validation accuracy: 0.943868079065196
Model Test Accuracy:  0.9466425937307928
Pruning Epoch 4
++++++++++++++++++
number of weights to prune:  27412.0
Sparsity of Pruned Mask:  tensor(0.5904)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6159 Acc: 0.4461
val Loss: 0.5025 Acc: 0.8397
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3615 Acc: 0.8903
val Loss: 0.3474 Acc: 0.8963
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2717 Acc: 0.9181
val Loss: 0.2999 Acc: 0.9092
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2414 Acc: 0.9285
val Loss: 0.2652 Acc: 0.9220
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2217 Acc: 0.9349
val Loss: 0.2845 Acc: 0.9202
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2087 Acc: 0.9381
val Loss: 0.3139 Acc: 0.9120
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2033 Acc: 0.9394
val Loss: 0.2573 Acc: 0.9255
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1940 Acc: 0.9432
val Loss: 0.2621 Acc: 0.9263
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1919 Acc: 0.9437
val Loss: 0.2588 Acc: 0.9269
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1883 Acc: 0.9447
val Loss: 0.2667 Acc: 0.9254
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1859 Acc: 0.9443
val Loss: 0.2641 Acc: 0.9250
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1828 Acc: 0.9454
val Loss: 0.2556 Acc: 0.9255
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1797 Acc: 0.9468
val Loss: 0.2379 Acc: 0.9321
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1758 Acc: 0.9481
val Loss: 0.2417 Acc: 0.9302
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1774 Acc: 0.9469
val Loss: 0.2341 Acc: 0.9325
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1727 Acc: 0.9491
val Loss: 0.2674 Acc: 0.9242
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1675 Acc: 0.9498
val Loss: 0.2286 Acc: 0.9355
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1404 Acc: 0.9586
val Loss: 0.2147 Acc: 0.9405
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1326 Acc: 0.9608
val Loss: 0.2168 Acc: 0.9403
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1293 Acc: 0.9611
val Loss: 0.2107 Acc: 0.9422
Epoch finished in 0m 13s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1280 Acc: 0.9627
val Loss: 0.2124 Acc: 0.9422
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1271 Acc: 0.9632
val Loss: 0.2106 Acc: 0.9423
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1270 Acc: 0.9630
val Loss: 0.2107 Acc: 0.9427
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1252 Acc: 0.9638
val Loss: 0.2117 Acc: 0.9415
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1267 Acc: 0.9628
val Loss: 0.2132 Acc: 0.9424
Epoch finished in 0m 13s
Best validation accuracy: 0.9424484001310472
Model Test Accuracy:  0.9491011063306699
Pruning Epoch 5
++++++++++++++++++
number of weights to prune:  21929.0
Sparsity of Pruned Mask:  tensor(0.6723)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6299 Acc: 0.4388
val Loss: 0.4854 Acc: 0.8495
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3490 Acc: 0.8932
val Loss: 0.3293 Acc: 0.9000
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2652 Acc: 0.9214
val Loss: 0.3107 Acc: 0.9095
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2278 Acc: 0.9323
val Loss: 0.2781 Acc: 0.9186
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2138 Acc: 0.9374
val Loss: 0.2743 Acc: 0.9180
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2009 Acc: 0.9411
val Loss: 0.2812 Acc: 0.9266
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1940 Acc: 0.9422
val Loss: 0.2485 Acc: 0.9283
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1860 Acc: 0.9446
val Loss: 0.2968 Acc: 0.9234
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1852 Acc: 0.9454
val Loss: 0.3007 Acc: 0.9221
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1826 Acc: 0.9458
val Loss: 0.2567 Acc: 0.9310
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1774 Acc: 0.9477
val Loss: 0.2787 Acc: 0.9323
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1770 Acc: 0.9464
val Loss: 0.2637 Acc: 0.9286
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1727 Acc: 0.9480
val Loss: 0.3005 Acc: 0.9297
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1749 Acc: 0.9490
val Loss: 0.2848 Acc: 0.9226
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1725 Acc: 0.9490
val Loss: 0.2640 Acc: 0.9314
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1728 Acc: 0.9490
val Loss: 0.2533 Acc: 0.9310
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1687 Acc: 0.9491
val Loss: 0.2251 Acc: 0.9364
Epoch finished in 0m 13s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1394 Acc: 0.9589
val Loss: 0.2170 Acc: 0.9412
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1311 Acc: 0.9621
val Loss: 0.2134 Acc: 0.9421
Epoch finished in 0m 13s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1271 Acc: 0.9632
val Loss: 0.2124 Acc: 0.9409
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1259 Acc: 0.9629
val Loss: 0.2117 Acc: 0.9414
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1249 Acc: 0.9633
val Loss: 0.2138 Acc: 0.9423
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1248 Acc: 0.9640
val Loss: 0.2086 Acc: 0.9434
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1249 Acc: 0.9637
val Loss: 0.2132 Acc: 0.9426
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1246 Acc: 0.9642
val Loss: 0.2139 Acc: 0.9413
Epoch finished in 0m 12s
Best validation accuracy: 0.9413017363765426
Model Test Accuracy:  0.9488322065150583
Pruning Epoch 6
++++++++++++++++++
number of weights to prune:  17543.0
Sparsity of Pruned Mask:  tensor(0.7379)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.5650 Acc: 0.4619
val Loss: 0.4860 Acc: 0.8484
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3441 Acc: 0.8963
val Loss: 0.3201 Acc: 0.9040
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2557 Acc: 0.9240
val Loss: 0.3064 Acc: 0.9071
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2238 Acc: 0.9341
val Loss: 0.2672 Acc: 0.9210
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2099 Acc: 0.9383
val Loss: 0.2968 Acc: 0.9274
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1960 Acc: 0.9420
val Loss: 0.2636 Acc: 0.9233
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1889 Acc: 0.9442
val Loss: 0.2791 Acc: 0.9208
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1864 Acc: 0.9452
val Loss: 0.2626 Acc: 0.9243
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1804 Acc: 0.9469
val Loss: 0.2614 Acc: 0.9250
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1798 Acc: 0.9477
val Loss: 0.2587 Acc: 0.9285
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1763 Acc: 0.9471
val Loss: 0.2686 Acc: 0.9248
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1751 Acc: 0.9475
val Loss: 0.2631 Acc: 0.9248
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1705 Acc: 0.9493
val Loss: 0.2569 Acc: 0.9325
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1716 Acc: 0.9486
val Loss: 0.2902 Acc: 0.9200
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1726 Acc: 0.9488
val Loss: 0.2496 Acc: 0.9286
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1759 Acc: 0.9474
val Loss: 0.2559 Acc: 0.9264
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1654 Acc: 0.9511
val Loss: 0.2224 Acc: 0.9388
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1416 Acc: 0.9583
val Loss: 0.2152 Acc: 0.9420
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1338 Acc: 0.9606
val Loss: 0.2105 Acc: 0.9428
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1276 Acc: 0.9631
val Loss: 0.2145 Acc: 0.9419
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1263 Acc: 0.9633
val Loss: 0.2144 Acc: 0.9412
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1281 Acc: 0.9623
val Loss: 0.2176 Acc: 0.9411
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1261 Acc: 0.9635
val Loss: 0.2113 Acc: 0.9422
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1261 Acc: 0.9646
val Loss: 0.2118 Acc: 0.9420
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1239 Acc: 0.9629
val Loss: 0.2105 Acc: 0.9429
Epoch finished in 0m 12s
Best validation accuracy: 0.9428852244184777
Model Test Accuracy:  0.9478334357713583
Pruning Epoch 7
++++++++++++++++++
number of weights to prune:  14034.0
Sparsity of Pruned Mask:  tensor(0.7903)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.5909 Acc: 0.4500
val Loss: 0.4693 Acc: 0.8525
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3414 Acc: 0.8962
val Loss: 0.3213 Acc: 0.9090
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2595 Acc: 0.9226
val Loss: 0.2882 Acc: 0.9156
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2253 Acc: 0.9323
val Loss: 0.2889 Acc: 0.9224
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2084 Acc: 0.9395
val Loss: 0.2574 Acc: 0.9251
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1963 Acc: 0.9422
val Loss: 0.2572 Acc: 0.9271
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1887 Acc: 0.9448
val Loss: 0.3240 Acc: 0.9166
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1845 Acc: 0.9458
val Loss: 0.2452 Acc: 0.9302
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1799 Acc: 0.9462
val Loss: 0.2556 Acc: 0.9245
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1775 Acc: 0.9484
val Loss: 0.2469 Acc: 0.9297
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1737 Acc: 0.9485
val Loss: 0.2993 Acc: 0.9174
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1752 Acc: 0.9475
val Loss: 0.3483 Acc: 0.9127
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1758 Acc: 0.9483
val Loss: 0.2799 Acc: 0.9328
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1713 Acc: 0.9498
val Loss: 0.2875 Acc: 0.9273
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1711 Acc: 0.9488
val Loss: 0.2474 Acc: 0.9320
Epoch finished in 0m 13s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1703 Acc: 0.9495
val Loss: 0.2514 Acc: 0.9266
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1673 Acc: 0.9505
val Loss: 0.2318 Acc: 0.9367
Epoch finished in 0m 13s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1386 Acc: 0.9600
val Loss: 0.2202 Acc: 0.9393
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1316 Acc: 0.9618
val Loss: 0.2186 Acc: 0.9412
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1285 Acc: 0.9624
val Loss: 0.2153 Acc: 0.9412
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1270 Acc: 0.9631
val Loss: 0.2140 Acc: 0.9416
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1279 Acc: 0.9627
val Loss: 0.2153 Acc: 0.9406
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1244 Acc: 0.9641
val Loss: 0.2160 Acc: 0.9420
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1275 Acc: 0.9635
val Loss: 0.2179 Acc: 0.9405
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1253 Acc: 0.9636
val Loss: 0.2158 Acc: 0.9415
Epoch finished in 0m 12s
Best validation accuracy: 0.9414655454843289
Model Test Accuracy:  0.9480639213275968
Pruning Epoch 8
++++++++++++++++++
number of weights to prune:  11227.0
Sparsity of Pruned Mask:  tensor(0.8322)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6370 Acc: 0.4333
val Loss: 0.4952 Acc: 0.8543
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3435 Acc: 0.8953
val Loss: 0.3139 Acc: 0.9066
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2536 Acc: 0.9248
val Loss: 0.2967 Acc: 0.9148
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2280 Acc: 0.9335
val Loss: 0.2881 Acc: 0.9204
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2083 Acc: 0.9383
val Loss: 0.2529 Acc: 0.9270
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1956 Acc: 0.9427
val Loss: 0.2502 Acc: 0.9301
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1892 Acc: 0.9442
val Loss: 0.2611 Acc: 0.9278
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1838 Acc: 0.9453
val Loss: 0.2857 Acc: 0.9225
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1826 Acc: 0.9456
val Loss: 0.2358 Acc: 0.9326
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1800 Acc: 0.9467
val Loss: 0.2401 Acc: 0.9319
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1756 Acc: 0.9486
val Loss: 0.2433 Acc: 0.9292
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1784 Acc: 0.9472
val Loss: 0.2645 Acc: 0.9269
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1754 Acc: 0.9485
val Loss: 0.2857 Acc: 0.9243
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1769 Acc: 0.9475
val Loss: 0.2536 Acc: 0.9325
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1759 Acc: 0.9471
val Loss: 0.2557 Acc: 0.9261
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1738 Acc: 0.9484
val Loss: 0.2487 Acc: 0.9291
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1708 Acc: 0.9493
val Loss: 0.2304 Acc: 0.9354
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1476 Acc: 0.9567
val Loss: 0.2220 Acc: 0.9378
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1403 Acc: 0.9597
val Loss: 0.2210 Acc: 0.9395
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1359 Acc: 0.9608
val Loss: 0.2208 Acc: 0.9396
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1345 Acc: 0.9614
val Loss: 0.2178 Acc: 0.9403
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1328 Acc: 0.9613
val Loss: 0.2192 Acc: 0.9406
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1328 Acc: 0.9625
val Loss: 0.2197 Acc: 0.9393
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1322 Acc: 0.9609
val Loss: 0.2195 Acc: 0.9404
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1352 Acc: 0.9607
val Loss: 0.2189 Acc: 0.9404
Epoch finished in 0m 12s
Best validation accuracy: 0.9404280878016817
Model Test Accuracy:  0.9467962507682851
Pruning Epoch 9
++++++++++++++++++
number of weights to prune:  8982.0
Sparsity of Pruned Mask:  tensor(0.8658)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.5877 Acc: 0.4550
val Loss: 0.5592 Acc: 0.8486
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3432 Acc: 0.8958
val Loss: 0.3240 Acc: 0.9061
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2610 Acc: 0.9225
val Loss: 0.3397 Acc: 0.9215
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2266 Acc: 0.9327
val Loss: 0.2758 Acc: 0.9232
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2096 Acc: 0.9389
val Loss: 0.2493 Acc: 0.9269
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2013 Acc: 0.9405
val Loss: 0.2581 Acc: 0.9286
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1937 Acc: 0.9430
val Loss: 0.2639 Acc: 0.9251
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1903 Acc: 0.9442
val Loss: 0.2615 Acc: 0.9248
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1874 Acc: 0.9457
val Loss: 0.2493 Acc: 0.9273
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1846 Acc: 0.9456
val Loss: 0.2449 Acc: 0.9299
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1832 Acc: 0.9458
val Loss: 0.2920 Acc: 0.9294
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1798 Acc: 0.9470
val Loss: 0.2726 Acc: 0.9271
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1792 Acc: 0.9474
val Loss: 0.2482 Acc: 0.9286
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1830 Acc: 0.9452
val Loss: 0.2602 Acc: 0.9281
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1785 Acc: 0.9457
val Loss: 0.2427 Acc: 0.9328
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1782 Acc: 0.9464
val Loss: 0.2992 Acc: 0.9145
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1778 Acc: 0.9478
val Loss: 0.2292 Acc: 0.9349
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1551 Acc: 0.9540
val Loss: 0.2231 Acc: 0.9374
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1472 Acc: 0.9563
val Loss: 0.2209 Acc: 0.9400
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1438 Acc: 0.9577
val Loss: 0.2146 Acc: 0.9405
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1408 Acc: 0.9590
val Loss: 0.2185 Acc: 0.9399
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1423 Acc: 0.9586
val Loss: 0.2148 Acc: 0.9408
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1392 Acc: 0.9594
val Loss: 0.2143 Acc: 0.9422
Epoch finished in 0m 13s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1387 Acc: 0.9590
val Loss: 0.2147 Acc: 0.9414
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1389 Acc: 0.9599
val Loss: 0.2152 Acc: 0.9417
Epoch finished in 0m 12s
Best validation accuracy: 0.9417385606639729
Model Test Accuracy:  0.9470267363245236
Pruning Epoch 10
++++++++++++++++++
number of weights to prune:  7185.0
Sparsity of Pruned Mask:  tensor(0.8926)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6448 Acc: 0.4303
val Loss: 0.4897 Acc: 0.8482
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3561 Acc: 0.8912
val Loss: 0.3146 Acc: 0.9065
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2657 Acc: 0.9222
val Loss: 0.2807 Acc: 0.9183
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2348 Acc: 0.9309
val Loss: 0.3046 Acc: 0.9130
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2170 Acc: 0.9359
val Loss: 0.2587 Acc: 0.9240
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2055 Acc: 0.9401
val Loss: 0.2849 Acc: 0.9178
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2005 Acc: 0.9402
val Loss: 0.2906 Acc: 0.9150
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1961 Acc: 0.9424
val Loss: 0.2768 Acc: 0.9240
Epoch finished in 0m 13s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1931 Acc: 0.9420
val Loss: 0.2792 Acc: 0.9254
Epoch finished in 0m 13s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1899 Acc: 0.9443
val Loss: 0.2559 Acc: 0.9313
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1884 Acc: 0.9437
val Loss: 0.2428 Acc: 0.9320
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1883 Acc: 0.9449
val Loss: 0.2708 Acc: 0.9242
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1870 Acc: 0.9444
val Loss: 0.2758 Acc: 0.9231
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1891 Acc: 0.9424
val Loss: 0.2676 Acc: 0.9236
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1895 Acc: 0.9433
val Loss: 0.2637 Acc: 0.9277
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1865 Acc: 0.9452
val Loss: 0.2593 Acc: 0.9302
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1836 Acc: 0.9452
val Loss: 0.2283 Acc: 0.9343
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1574 Acc: 0.9537
val Loss: 0.2235 Acc: 0.9385
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1499 Acc: 0.9563
val Loss: 0.2181 Acc: 0.9412
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1489 Acc: 0.9567
val Loss: 0.2128 Acc: 0.9403
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1451 Acc: 0.9586
val Loss: 0.2139 Acc: 0.9394
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1453 Acc: 0.9578
val Loss: 0.2154 Acc: 0.9401
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1452 Acc: 0.9575
val Loss: 0.2163 Acc: 0.9413
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1461 Acc: 0.9573
val Loss: 0.2174 Acc: 0.9401
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1435 Acc: 0.9591
val Loss: 0.2113 Acc: 0.9417
Epoch finished in 0m 12s
Best validation accuracy: 0.9416839576280441
Model Test Accuracy:  0.9470267363245236
Pruning Epoch 11
++++++++++++++++++
number of weights to prune:  5748.0
Sparsity of Pruned Mask:  tensor(0.9141)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.7265 Acc: 0.3995
val Loss: 0.5187 Acc: 0.8369
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3692 Acc: 0.8877
val Loss: 0.3470 Acc: 0.8962
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2708 Acc: 0.9183
val Loss: 0.2918 Acc: 0.9178
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2378 Acc: 0.9276
val Loss: 0.2932 Acc: 0.9131
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2225 Acc: 0.9350
val Loss: 0.2648 Acc: 0.9237
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2135 Acc: 0.9368
val Loss: 0.2537 Acc: 0.9279
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2058 Acc: 0.9391
val Loss: 0.2576 Acc: 0.9280
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2027 Acc: 0.9385
val Loss: 0.2530 Acc: 0.9260
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1979 Acc: 0.9413
val Loss: 0.2561 Acc: 0.9253
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2005 Acc: 0.9407
val Loss: 0.2629 Acc: 0.9256
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1966 Acc: 0.9416
val Loss: 0.2595 Acc: 0.9279
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1964 Acc: 0.9428
val Loss: 0.2722 Acc: 0.9207
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1937 Acc: 0.9422
val Loss: 0.2589 Acc: 0.9243
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1951 Acc: 0.9422
val Loss: 0.2662 Acc: 0.9242
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1946 Acc: 0.9427
val Loss: 0.2482 Acc: 0.9278
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1946 Acc: 0.9422
val Loss: 0.2473 Acc: 0.9286
Epoch finished in 0m 13s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1911 Acc: 0.9437
val Loss: 0.2336 Acc: 0.9329
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1722 Acc: 0.9500
val Loss: 0.2237 Acc: 0.9370
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1631 Acc: 0.9523
val Loss: 0.2175 Acc: 0.9400
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1566 Acc: 0.9550
val Loss: 0.2193 Acc: 0.9390
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1548 Acc: 0.9552
val Loss: 0.2221 Acc: 0.9384
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1554 Acc: 0.9553
val Loss: 0.2168 Acc: 0.9406
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1554 Acc: 0.9551
val Loss: 0.2156 Acc: 0.9394
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1561 Acc: 0.9548
val Loss: 0.2160 Acc: 0.9399
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1569 Acc: 0.9540
val Loss: 0.2152 Acc: 0.9406
Epoch finished in 0m 12s
Best validation accuracy: 0.940646499945397
Model Test Accuracy:  0.9459127228027043
Pruning Epoch 12
++++++++++++++++++
number of weights to prune:  4598.0
Sparsity of Pruned Mask:  tensor(0.9313)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.8161 Acc: 0.3704
val Loss: 0.5715 Acc: 0.8196
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3909 Acc: 0.8803
val Loss: 0.3431 Acc: 0.8952
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2875 Acc: 0.9140
val Loss: 0.3109 Acc: 0.9136
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2492 Acc: 0.9262
val Loss: 0.2803 Acc: 0.9175
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2367 Acc: 0.9300
val Loss: 0.2693 Acc: 0.9212
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2216 Acc: 0.9346
val Loss: 0.2892 Acc: 0.9150
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2167 Acc: 0.9353
val Loss: 0.2516 Acc: 0.9295
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2130 Acc: 0.9372
val Loss: 0.2585 Acc: 0.9243
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2091 Acc: 0.9376
val Loss: 0.2711 Acc: 0.9216
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2082 Acc: 0.9387
val Loss: 0.2604 Acc: 0.9276
Epoch finished in 0m 13s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2080 Acc: 0.9388
val Loss: 0.2798 Acc: 0.9214
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2095 Acc: 0.9376
val Loss: 0.2524 Acc: 0.9267
Epoch finished in 0m 13s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2065 Acc: 0.9388
val Loss: 0.2951 Acc: 0.9178
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2066 Acc: 0.9375
val Loss: 0.2908 Acc: 0.9151
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2039 Acc: 0.9400
val Loss: 0.2633 Acc: 0.9237
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2042 Acc: 0.9397
val Loss: 0.2673 Acc: 0.9198
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2019 Acc: 0.9400
val Loss: 0.2344 Acc: 0.9339
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1761 Acc: 0.9484
val Loss: 0.2233 Acc: 0.9360
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1695 Acc: 0.9497
val Loss: 0.2229 Acc: 0.9377
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1653 Acc: 0.9513
val Loss: 0.2216 Acc: 0.9367
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1640 Acc: 0.9514
val Loss: 0.2192 Acc: 0.9387
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1627 Acc: 0.9516
val Loss: 0.2215 Acc: 0.9375
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1638 Acc: 0.9524
val Loss: 0.2223 Acc: 0.9376
Epoch finished in 0m 13s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1633 Acc: 0.9522
val Loss: 0.2206 Acc: 0.9386
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1638 Acc: 0.9522
val Loss: 0.2199 Acc: 0.9377
Epoch finished in 0m 12s
Best validation accuracy: 0.9376979360052419
Model Test Accuracy:  0.9457206515058388
Pruning Epoch 13
++++++++++++++++++
number of weights to prune:  3678.0
Sparsity of Pruned Mask:  tensor(0.9450)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.8820 Acc: 0.3413
val Loss: 0.6208 Acc: 0.7987
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3980 Acc: 0.8776
val Loss: 0.3463 Acc: 0.8955
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2946 Acc: 0.9124
val Loss: 0.2960 Acc: 0.9141
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2558 Acc: 0.9248
val Loss: 0.2868 Acc: 0.9190
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2435 Acc: 0.9281
val Loss: 0.2778 Acc: 0.9230
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2282 Acc: 0.9331
val Loss: 0.2688 Acc: 0.9214
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2264 Acc: 0.9333
val Loss: 0.2822 Acc: 0.9192
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2242 Acc: 0.9340
val Loss: 0.2673 Acc: 0.9224
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2211 Acc: 0.9346
val Loss: 0.2609 Acc: 0.9239
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2178 Acc: 0.9345
val Loss: 0.2787 Acc: 0.9283
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2164 Acc: 0.9362
val Loss: 0.2825 Acc: 0.9177
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2155 Acc: 0.9369
val Loss: 0.2839 Acc: 0.9175
Epoch finished in 0m 13s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2176 Acc: 0.9362
val Loss: 0.2711 Acc: 0.9218
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2148 Acc: 0.9361
val Loss: 0.2792 Acc: 0.9189
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2139 Acc: 0.9374
val Loss: 0.2586 Acc: 0.9257
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2146 Acc: 0.9366
val Loss: 0.2742 Acc: 0.9266
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2135 Acc: 0.9369
val Loss: 0.2394 Acc: 0.9319
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1897 Acc: 0.9444
val Loss: 0.2310 Acc: 0.9349
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1841 Acc: 0.9461
val Loss: 0.2258 Acc: 0.9344
Epoch finished in 0m 13s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1771 Acc: 0.9479
val Loss: 0.2242 Acc: 0.9372
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1786 Acc: 0.9473
val Loss: 0.2233 Acc: 0.9382
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1769 Acc: 0.9480
val Loss: 0.2234 Acc: 0.9372
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1742 Acc: 0.9490
val Loss: 0.2294 Acc: 0.9362
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1734 Acc: 0.9493
val Loss: 0.2274 Acc: 0.9373
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1746 Acc: 0.9485
val Loss: 0.2252 Acc: 0.9356
Epoch finished in 0m 12s
Best validation accuracy: 0.9355684176040188
Model Test Accuracy:  0.9446066379840196
Pruning Epoch 14
++++++++++++++++++
number of weights to prune:  2943.0
Sparsity of Pruned Mask:  tensor(0.9560)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.9641 Acc: 0.3116
val Loss: 0.7557 Acc: 0.7529
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4365 Acc: 0.8660
val Loss: 0.3601 Acc: 0.8917
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3023 Acc: 0.9096
val Loss: 0.3060 Acc: 0.9077
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2726 Acc: 0.9191
val Loss: 0.3102 Acc: 0.9094
Epoch finished in 0m 13s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2575 Acc: 0.9239
val Loss: 0.2798 Acc: 0.9179
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2457 Acc: 0.9281
val Loss: 0.3280 Acc: 0.9079
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2390 Acc: 0.9294
val Loss: 0.2750 Acc: 0.9177
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2361 Acc: 0.9291
val Loss: 0.2804 Acc: 0.9157
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2339 Acc: 0.9314
val Loss: 0.4469 Acc: 0.9157
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2303 Acc: 0.9323
val Loss: 0.2605 Acc: 0.9246
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2330 Acc: 0.9309
val Loss: 0.2772 Acc: 0.9216
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2272 Acc: 0.9318
val Loss: 0.2546 Acc: 0.9263
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2250 Acc: 0.9342
val Loss: 0.2986 Acc: 0.9144
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2267 Acc: 0.9322
val Loss: 0.2967 Acc: 0.9123
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2264 Acc: 0.9329
val Loss: 0.2774 Acc: 0.9191
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2242 Acc: 0.9339
val Loss: 0.2714 Acc: 0.9207
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2222 Acc: 0.9340
val Loss: 0.2450 Acc: 0.9290
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1971 Acc: 0.9431
val Loss: 0.2398 Acc: 0.9318
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1932 Acc: 0.9430
val Loss: 0.2354 Acc: 0.9332
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1900 Acc: 0.9447
val Loss: 0.2344 Acc: 0.9338
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1881 Acc: 0.9453
val Loss: 0.2328 Acc: 0.9326
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1858 Acc: 0.9455
val Loss: 0.2337 Acc: 0.9343
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1853 Acc: 0.9450
val Loss: 0.2327 Acc: 0.9327
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1852 Acc: 0.9455
val Loss: 0.2337 Acc: 0.9328
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1868 Acc: 0.9452
val Loss: 0.2348 Acc: 0.9333
Epoch finished in 0m 12s
Best validation accuracy: 0.9332750900950093
Model Test Accuracy:  0.9414566687154271
Pruning Epoch 15
++++++++++++++++++
number of weights to prune:  2354.0
Sparsity of Pruned Mask:  tensor(0.9648)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.0112 Acc: 0.2969
val Loss: 0.9521 Acc: 0.6915
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4808 Acc: 0.8511
val Loss: 0.3815 Acc: 0.8863
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3300 Acc: 0.9010
val Loss: 0.3237 Acc: 0.9062
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2892 Acc: 0.9145
val Loss: 0.3115 Acc: 0.9119
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2693 Acc: 0.9204
val Loss: 0.2924 Acc: 0.9142
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2605 Acc: 0.9220
val Loss: 0.3187 Acc: 0.9108
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2552 Acc: 0.9243
val Loss: 0.2960 Acc: 0.9142
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2481 Acc: 0.9267
val Loss: 0.2972 Acc: 0.9113
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2465 Acc: 0.9280
val Loss: 0.2938 Acc: 0.9184
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2479 Acc: 0.9260
val Loss: 0.2772 Acc: 0.9185
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2436 Acc: 0.9283
val Loss: 0.2822 Acc: 0.9173
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2446 Acc: 0.9262
val Loss: 0.2864 Acc: 0.9183
Epoch finished in 0m 13s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2402 Acc: 0.9266
val Loss: 0.2756 Acc: 0.9195
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2398 Acc: 0.9284
val Loss: 0.2865 Acc: 0.9194
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2386 Acc: 0.9289
val Loss: 0.2823 Acc: 0.9218
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2359 Acc: 0.9292
val Loss: 0.3017 Acc: 0.9112
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2372 Acc: 0.9294
val Loss: 0.2553 Acc: 0.9262
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2163 Acc: 0.9366
val Loss: 0.2450 Acc: 0.9281
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2036 Acc: 0.9401
val Loss: 0.2386 Acc: 0.9313
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2009 Acc: 0.9409
val Loss: 0.2395 Acc: 0.9314
Epoch finished in 0m 13s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1980 Acc: 0.9419
val Loss: 0.2380 Acc: 0.9308
Epoch finished in 0m 13s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1984 Acc: 0.9420
val Loss: 0.2427 Acc: 0.9315
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1978 Acc: 0.9421
val Loss: 0.2361 Acc: 0.9315
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1962 Acc: 0.9422
val Loss: 0.2373 Acc: 0.9308
Epoch finished in 0m 13s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1977 Acc: 0.9420
val Loss: 0.2369 Acc: 0.9315
Epoch finished in 0m 12s
Best validation accuracy: 0.9315277929452878
Model Test Accuracy:  0.9408036263060847
Pruning Epoch 16
++++++++++++++++++
number of weights to prune:  1883.0
Sparsity of Pruned Mask:  tensor(0.9719)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.0958 Acc: 0.2524
val Loss: 1.4564 Acc: 0.4883
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.6016 Acc: 0.8092
val Loss: 0.4363 Acc: 0.8758
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3466 Acc: 0.8953
val Loss: 0.3584 Acc: 0.8933
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3060 Acc: 0.9088
val Loss: 0.3438 Acc: 0.8956
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2882 Acc: 0.9148
val Loss: 0.3179 Acc: 0.9038
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2762 Acc: 0.9179
val Loss: 0.3598 Acc: 0.9010
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2775 Acc: 0.9178
val Loss: 0.3340 Acc: 0.9072
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2711 Acc: 0.9199
val Loss: 0.2981 Acc: 0.9118
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2621 Acc: 0.9211
val Loss: 0.3151 Acc: 0.9048
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2607 Acc: 0.9225
val Loss: 0.3391 Acc: 0.8983
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2580 Acc: 0.9230
val Loss: 0.3124 Acc: 0.9071
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2570 Acc: 0.9232
val Loss: 0.2937 Acc: 0.9166
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2563 Acc: 0.9234
val Loss: 0.3211 Acc: 0.9029
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2553 Acc: 0.9238
val Loss: 0.2929 Acc: 0.9131
Epoch finished in 0m 13s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2551 Acc: 0.9240
val Loss: 0.3063 Acc: 0.9093
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2530 Acc: 0.9246
val Loss: 0.2918 Acc: 0.9119
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2461 Acc: 0.9266
val Loss: 0.2678 Acc: 0.9234
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2218 Acc: 0.9340
val Loss: 0.2558 Acc: 0.9249
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2162 Acc: 0.9355
val Loss: 0.2512 Acc: 0.9268
Epoch finished in 0m 13s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2135 Acc: 0.9372
val Loss: 0.2501 Acc: 0.9295
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2144 Acc: 0.9363
val Loss: 0.2483 Acc: 0.9283
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2093 Acc: 0.9384
val Loss: 0.2517 Acc: 0.9271
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2116 Acc: 0.9371
val Loss: 0.2489 Acc: 0.9289
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2112 Acc: 0.9377
val Loss: 0.2483 Acc: 0.9285
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2095 Acc: 0.9391
val Loss: 0.2501 Acc: 0.9279
Epoch finished in 0m 12s
Best validation accuracy: 0.9279239925739872
Model Test Accuracy:  0.9358866011063306
Pruning Epoch 17
++++++++++++++++++
number of weights to prune:  1506.0
Sparsity of Pruned Mask:  tensor(0.9775)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1529 Acc: 0.2310
val Loss: 1.7246 Acc: 0.4100
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.7112 Acc: 0.7700
val Loss: 0.4467 Acc: 0.8598
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3802 Acc: 0.8848
val Loss: 0.3908 Acc: 0.8798
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3371 Acc: 0.8983
val Loss: 0.4038 Acc: 0.8783
Epoch finished in 0m 13s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3145 Acc: 0.9056
val Loss: 0.3306 Acc: 0.9031
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3016 Acc: 0.9103
val Loss: 0.3299 Acc: 0.9055
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2937 Acc: 0.9117
val Loss: 0.3170 Acc: 0.9055
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2875 Acc: 0.9142
val Loss: 0.3167 Acc: 0.9056
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2826 Acc: 0.9161
val Loss: 0.3173 Acc: 0.9066
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2803 Acc: 0.9164
val Loss: 0.3205 Acc: 0.9076
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2774 Acc: 0.9172
val Loss: 0.3363 Acc: 0.8996
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2716 Acc: 0.9189
val Loss: 0.3120 Acc: 0.9070
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2728 Acc: 0.9191
val Loss: 0.2935 Acc: 0.9131
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2689 Acc: 0.9191
val Loss: 0.2882 Acc: 0.9149
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2710 Acc: 0.9194
val Loss: 0.3248 Acc: 0.9091
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2690 Acc: 0.9202
val Loss: 0.2859 Acc: 0.9162
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2649 Acc: 0.9201
val Loss: 0.2781 Acc: 0.9172
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2399 Acc: 0.9288
val Loss: 0.2686 Acc: 0.9227
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2350 Acc: 0.9311
val Loss: 0.2640 Acc: 0.9239
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2285 Acc: 0.9321
val Loss: 0.2614 Acc: 0.9255
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2275 Acc: 0.9321
val Loss: 0.2636 Acc: 0.9242
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2263 Acc: 0.9332
val Loss: 0.2576 Acc: 0.9254
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2282 Acc: 0.9327
val Loss: 0.2587 Acc: 0.9253
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2269 Acc: 0.9326
val Loss: 0.2611 Acc: 0.9238
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2277 Acc: 0.9328
val Loss: 0.2580 Acc: 0.9267
Epoch finished in 0m 12s
Best validation accuracy: 0.9266681227476248
Model Test Accuracy:  0.9354640442532267
Pruning Epoch 18
++++++++++++++++++
number of weights to prune:  1205.0
Sparsity of Pruned Mask:  tensor(0.9820)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1679 Acc: 0.2278
val Loss: 1.8439 Acc: 0.3518
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.8184 Acc: 0.7278
val Loss: 0.4935 Acc: 0.8469
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4248 Acc: 0.8706
val Loss: 0.3871 Acc: 0.8819
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3567 Acc: 0.8914
val Loss: 0.3493 Acc: 0.8943
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3307 Acc: 0.8991
val Loss: 0.3662 Acc: 0.8887
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3244 Acc: 0.9030
val Loss: 0.3470 Acc: 0.9019
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3106 Acc: 0.9068
val Loss: 0.3323 Acc: 0.9066
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3061 Acc: 0.9083
val Loss: 0.4061 Acc: 0.8903
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2987 Acc: 0.9099
val Loss: 0.3398 Acc: 0.9026
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2988 Acc: 0.9108
val Loss: 0.3159 Acc: 0.9076
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2918 Acc: 0.9127
val Loss: 0.3209 Acc: 0.9088
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2908 Acc: 0.9124
val Loss: 0.3159 Acc: 0.9035
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2872 Acc: 0.9144
val Loss: 0.3293 Acc: 0.9026
Epoch finished in 0m 13s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2846 Acc: 0.9146
val Loss: 0.3226 Acc: 0.9077
Epoch finished in 0m 13s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2849 Acc: 0.9143
val Loss: 0.3578 Acc: 0.9056
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2844 Acc: 0.9145
val Loss: 0.3401 Acc: 0.9013
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2833 Acc: 0.9157
val Loss: 0.2814 Acc: 0.9173
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2567 Acc: 0.9229
val Loss: 0.2718 Acc: 0.9197
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2439 Acc: 0.9273
val Loss: 0.2702 Acc: 0.9226
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2453 Acc: 0.9268
val Loss: 0.2688 Acc: 0.9194
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2392 Acc: 0.9303
val Loss: 0.2643 Acc: 0.9232
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2410 Acc: 0.9281
val Loss: 0.2623 Acc: 0.9239
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2383 Acc: 0.9287
val Loss: 0.2619 Acc: 0.9227
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2438 Acc: 0.9265
val Loss: 0.2638 Acc: 0.9230
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2444 Acc: 0.9275
val Loss: 0.2635 Acc: 0.9232
Epoch finished in 0m 12s
Best validation accuracy: 0.9232281314841105
Model Test Accuracy:  0.9319299323909034
Pruning Epoch 19
++++++++++++++++++
number of weights to prune:  963.0
Sparsity of Pruned Mask:  tensor(0.9856)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2159 Acc: 0.2081
val Loss: 2.0582 Acc: 0.2825
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.2443 Acc: 0.5729
val Loss: 0.5599 Acc: 0.8266
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4784 Acc: 0.8532
val Loss: 0.4459 Acc: 0.8721
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4004 Acc: 0.8784
val Loss: 0.3960 Acc: 0.8836
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3657 Acc: 0.8886
val Loss: 0.3981 Acc: 0.8838
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3502 Acc: 0.8941
val Loss: 0.3599 Acc: 0.8942
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3388 Acc: 0.8986
val Loss: 0.3778 Acc: 0.8957
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3300 Acc: 0.8998
val Loss: 0.3632 Acc: 0.8895
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3283 Acc: 0.9018
val Loss: 0.3581 Acc: 0.8933
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3146 Acc: 0.9049
val Loss: 0.3514 Acc: 0.8947
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3131 Acc: 0.9064
val Loss: 0.3327 Acc: 0.9015
Epoch finished in 0m 13s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3087 Acc: 0.9081
val Loss: 0.3245 Acc: 0.9019
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3043 Acc: 0.9085
val Loss: 0.3313 Acc: 0.9025
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3039 Acc: 0.9087
val Loss: 0.3724 Acc: 0.8931
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3026 Acc: 0.9077
val Loss: 0.3230 Acc: 0.9022
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3014 Acc: 0.9099
val Loss: 0.3271 Acc: 0.9060
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2962 Acc: 0.9104
val Loss: 0.3024 Acc: 0.9101
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2750 Acc: 0.9176
val Loss: 0.2923 Acc: 0.9155
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2634 Acc: 0.9213
val Loss: 0.2805 Acc: 0.9182
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2597 Acc: 0.9222
val Loss: 0.2763 Acc: 0.9185
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2578 Acc: 0.9233
val Loss: 0.2793 Acc: 0.9163
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2585 Acc: 0.9237
val Loss: 0.2787 Acc: 0.9201
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2572 Acc: 0.9223
val Loss: 0.2820 Acc: 0.9172
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2561 Acc: 0.9242
val Loss: 0.2826 Acc: 0.9165
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2570 Acc: 0.9245
val Loss: 0.2825 Acc: 0.9183
Epoch finished in 0m 12s
Best validation accuracy: 0.9183138582505187
Model Test Accuracy:  0.9265903503380454
Pruning Epoch 20
++++++++++++++++++
number of weights to prune:  771.0
Sparsity of Pruned Mask:  tensor(0.9885)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2222 Acc: 0.2006
val Loss: 2.0708 Acc: 0.2775
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.2321 Acc: 0.5747
val Loss: 0.7638 Acc: 0.7836
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.5292 Acc: 0.8345
val Loss: 0.5578 Acc: 0.8459
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4561 Acc: 0.8605
val Loss: 0.4483 Acc: 0.8593
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4102 Acc: 0.8751
val Loss: 0.4210 Acc: 0.8660
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3792 Acc: 0.8855
val Loss: 0.4259 Acc: 0.8831
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3705 Acc: 0.8873
val Loss: 0.4136 Acc: 0.8847
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3601 Acc: 0.8909
val Loss: 0.4172 Acc: 0.8728
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3516 Acc: 0.8928
val Loss: 0.3577 Acc: 0.8930
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3435 Acc: 0.8961
val Loss: 0.3487 Acc: 0.8934
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3375 Acc: 0.8994
val Loss: 0.3816 Acc: 0.8822
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3339 Acc: 0.9000
val Loss: 0.3716 Acc: 0.8928
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3325 Acc: 0.8997
val Loss: 0.3710 Acc: 0.8883
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3250 Acc: 0.9016
val Loss: 0.4301 Acc: 0.8884
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3240 Acc: 0.9033
val Loss: 0.3798 Acc: 0.8913
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3194 Acc: 0.9050
val Loss: 0.4081 Acc: 0.8799
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3200 Acc: 0.9033
val Loss: 0.3187 Acc: 0.9053
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2920 Acc: 0.9126
val Loss: 0.3042 Acc: 0.9105
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2804 Acc: 0.9162
val Loss: 0.2974 Acc: 0.9128
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2768 Acc: 0.9170
val Loss: 0.2950 Acc: 0.9143
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2744 Acc: 0.9187
val Loss: 0.2942 Acc: 0.9125
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2745 Acc: 0.9184
val Loss: 0.2997 Acc: 0.9109
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2741 Acc: 0.9181
val Loss: 0.2943 Acc: 0.9155
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2724 Acc: 0.9187
val Loss: 0.2942 Acc: 0.9126
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2738 Acc: 0.9183
val Loss: 0.2996 Acc: 0.9125
Epoch finished in 0m 12s
Best validation accuracy: 0.9124713334061374
Model Test Accuracy:  0.9219038106945298
Pruning Epoch 21
++++++++++++++++++
number of weights to prune:  616.0
Sparsity of Pruned Mask:  tensor(0.9908)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2339 Acc: 0.1970
val Loss: 2.1311 Acc: 0.2584
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.5312 Acc: 0.4691
val Loss: 0.8474 Acc: 0.7255
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.6657 Acc: 0.7890
val Loss: 0.6747 Acc: 0.7892
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5454 Acc: 0.8284
val Loss: 0.5612 Acc: 0.8249
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4813 Acc: 0.8513
val Loss: 0.4724 Acc: 0.8546
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4453 Acc: 0.8630
val Loss: 0.4448 Acc: 0.8653
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4293 Acc: 0.8694
val Loss: 0.4645 Acc: 0.8555
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4096 Acc: 0.8759
val Loss: 0.4432 Acc: 0.8736
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3956 Acc: 0.8805
val Loss: 0.4354 Acc: 0.8756
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3837 Acc: 0.8833
val Loss: 0.4421 Acc: 0.8662
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3801 Acc: 0.8840
val Loss: 0.4269 Acc: 0.8712
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3726 Acc: 0.8856
val Loss: 0.3784 Acc: 0.8850
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3690 Acc: 0.8884
val Loss: 0.4484 Acc: 0.8718
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3614 Acc: 0.8898
val Loss: 0.3888 Acc: 0.8875
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3596 Acc: 0.8913
val Loss: 0.3827 Acc: 0.8831
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3538 Acc: 0.8915
val Loss: 0.3728 Acc: 0.8869
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3488 Acc: 0.8945
val Loss: 0.3431 Acc: 0.8943
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3195 Acc: 0.9026
val Loss: 0.3270 Acc: 0.9028
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3111 Acc: 0.9062
val Loss: 0.3237 Acc: 0.9018
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3038 Acc: 0.9086
val Loss: 0.3178 Acc: 0.9052
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3058 Acc: 0.9076
val Loss: 0.3203 Acc: 0.9064
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3056 Acc: 0.9079
val Loss: 0.3185 Acc: 0.9040
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3045 Acc: 0.9081
val Loss: 0.3157 Acc: 0.9062
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3055 Acc: 0.9090
val Loss: 0.3192 Acc: 0.9067
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3021 Acc: 0.9085
val Loss: 0.3182 Acc: 0.9058
Epoch finished in 0m 12s
Best validation accuracy: 0.9057551599868953
Model Test Accuracy:  0.9134526736324523
Pruning Epoch 22
++++++++++++++++++
number of weights to prune:  493.0
Sparsity of Pruned Mask:  tensor(0.9926)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2296 Acc: 0.1961
val Loss: 2.0860 Acc: 0.2762
Epoch finished in 0m 42s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.6376 Acc: 0.4312
val Loss: 1.0423 Acc: 0.6525
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 0.7456 Acc: 0.7577
val Loss: 0.6372 Acc: 0.8008
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5793 Acc: 0.8174
val Loss: 0.7271 Acc: 0.7702
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5247 Acc: 0.8372
val Loss: 0.4946 Acc: 0.8427
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.4910 Acc: 0.8481
val Loss: 0.4688 Acc: 0.8530
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.4580 Acc: 0.8594
val Loss: 0.7017 Acc: 0.7892
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4500 Acc: 0.8621
val Loss: 0.4847 Acc: 0.8477
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4316 Acc: 0.8674
val Loss: 0.4722 Acc: 0.8607
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4257 Acc: 0.8701
val Loss: 0.4554 Acc: 0.8630
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.4121 Acc: 0.8739
val Loss: 0.4269 Acc: 0.8706
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.4048 Acc: 0.8778
val Loss: 0.4468 Acc: 0.8652
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3987 Acc: 0.8785
val Loss: 0.4231 Acc: 0.8749
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3921 Acc: 0.8808
val Loss: 0.4265 Acc: 0.8718
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3908 Acc: 0.8810
val Loss: 0.4063 Acc: 0.8721
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3827 Acc: 0.8831
val Loss: 0.4072 Acc: 0.8706
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3839 Acc: 0.8832
val Loss: 0.3772 Acc: 0.8872
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3485 Acc: 0.8951
val Loss: 0.3612 Acc: 0.8907
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3345 Acc: 0.8992
val Loss: 0.3556 Acc: 0.8947
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3331 Acc: 0.8987
val Loss: 0.3482 Acc: 0.8969
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3309 Acc: 0.8991
val Loss: 0.3498 Acc: 0.8953
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3307 Acc: 0.9000
val Loss: 0.3488 Acc: 0.8959
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3288 Acc: 0.9009
val Loss: 0.3487 Acc: 0.8942
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3302 Acc: 0.8997
val Loss: 0.3495 Acc: 0.8950
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3285 Acc: 0.9012
val Loss: 0.3460 Acc: 0.8981
Epoch finished in 0m 12s
Best validation accuracy: 0.8980561319209348
Model Test Accuracy:  0.9052320221266134
Pruning Epoch 23
++++++++++++++++++
number of weights to prune:  394.0
Sparsity of Pruned Mask:  tensor(0.9941)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2497 Acc: 0.1725
val Loss: 2.1890 Acc: 0.2362
Epoch finished in 0m 41s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.9178 Acc: 0.3251
val Loss: 1.6217 Acc: 0.4383
Epoch finished in 0m 34s
Training Epoch 2/24
********************
Warmup
train Loss: 1.1607 Acc: 0.6072
val Loss: 0.8037 Acc: 0.7405
Epoch finished in 0m 12s
Training Epoch 3/24
********************
Warmup
train Loss: 0.6923 Acc: 0.7752
val Loss: 0.6195 Acc: 0.8037
Epoch finished in 0m 12s
Training Epoch 4/24
********************
Warmup
train Loss: 0.5904 Acc: 0.8124
val Loss: 0.6545 Acc: 0.8070
Epoch finished in 0m 12s
Training Epoch 5/24
********************
Warmup
train Loss: 0.5330 Acc: 0.8324
val Loss: 0.5201 Acc: 0.8388
Epoch finished in 0m 12s
Training Epoch 6/24
********************
Warmup
train Loss: 0.5105 Acc: 0.8403
val Loss: 0.5435 Acc: 0.8361
Epoch finished in 0m 12s
Training Epoch 7/24
********************
Warmup
train Loss: 0.4796 Acc: 0.8508
val Loss: 0.5285 Acc: 0.8390
Epoch finished in 0m 12s
Training Epoch 8/24
********************
Warmup
train Loss: 0.4667 Acc: 0.8550
val Loss: 0.4734 Acc: 0.8491
Epoch finished in 0m 12s
Training Epoch 9/24
********************
Warmup
train Loss: 0.4492 Acc: 0.8599
val Loss: 0.4869 Acc: 0.8526
Epoch finished in 0m 12s
Training Epoch 10/24
********************
Warmup
train Loss: 0.4381 Acc: 0.8645
val Loss: 0.4693 Acc: 0.8609
Epoch finished in 0m 12s
Training Epoch 11/24
********************
Warmup
train Loss: 0.4317 Acc: 0.8672
val Loss: 0.4798 Acc: 0.8500
Epoch finished in 0m 12s
Training Epoch 12/24
********************
Warmup
train Loss: 0.4241 Acc: 0.8689
val Loss: 0.4443 Acc: 0.8634
Epoch finished in 0m 12s
Training Epoch 13/24
********************
Warmup
train Loss: 0.4247 Acc: 0.8694
val Loss: 0.5107 Acc: 0.8629
Epoch finished in 0m 12s
Training Epoch 14/24
********************
Warmup
train Loss: 0.4190 Acc: 0.8730
val Loss: 0.4440 Acc: 0.8650
Epoch finished in 0m 12s
Training Epoch 15/24
********************
Warmup
train Loss: 0.4161 Acc: 0.8732
val Loss: 0.4107 Acc: 0.8715
Epoch finished in 0m 12s
Training Epoch 16/24
********************
Warmup
train Loss: 0.4044 Acc: 0.8762
val Loss: 0.3857 Acc: 0.8827
Epoch finished in 0m 12s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.3680 Acc: 0.8888
val Loss: 0.3744 Acc: 0.8853
Epoch finished in 0m 12s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.3602 Acc: 0.8908
val Loss: 0.3722 Acc: 0.8851
Epoch finished in 0m 12s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.3557 Acc: 0.8926
val Loss: 0.3675 Acc: 0.8886
Epoch finished in 0m 12s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.3545 Acc: 0.8928
val Loss: 0.3684 Acc: 0.8886
Epoch finished in 0m 12s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.3542 Acc: 0.8916
val Loss: 0.3699 Acc: 0.8862
Epoch finished in 0m 12s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.3538 Acc: 0.8922
val Loss: 0.3697 Acc: 0.8869
Epoch finished in 0m 12s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.3535 Acc: 0.8931
val Loss: 0.3667 Acc: 0.8872
Epoch finished in 0m 12s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.3516 Acc: 0.8920
val Loss: 0.3659 Acc: 0.8872
Epoch finished in 0m 12s
Best validation accuracy: 0.8871901277711041
Model Test Accuracy:  0.8919022741241548
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2513 Acc: 0.1657
val Loss: 2.1934 Acc: 0.2106
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.8757 Acc: 0.3406
val Loss: 1.8854 Acc: 0.3347
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 1.0089 Acc: 0.6751
val Loss: 0.6882 Acc: 0.7865
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.5207 Acc: 0.8351
val Loss: 0.5219 Acc: 0.8508
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4137 Acc: 0.8728
val Loss: 0.4597 Acc: 0.8552
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3635 Acc: 0.8883
val Loss: 0.4759 Acc: 0.8620
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3342 Acc: 0.8974
val Loss: 0.3616 Acc: 0.8916
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3100 Acc: 0.9062
val Loss: 0.3736 Acc: 0.8954
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2932 Acc: 0.9103
val Loss: 0.3209 Acc: 0.9077
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2750 Acc: 0.9171
val Loss: 0.3080 Acc: 0.9088
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2658 Acc: 0.9194
val Loss: 0.3162 Acc: 0.9081
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2521 Acc: 0.9257
val Loss: 0.3051 Acc: 0.9122
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2454 Acc: 0.9264
val Loss: 0.3096 Acc: 0.9126
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2344 Acc: 0.9295
val Loss: 0.2685 Acc: 0.9218
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2281 Acc: 0.9331
val Loss: 0.2945 Acc: 0.9205
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2221 Acc: 0.9343
val Loss: 0.2939 Acc: 0.9170
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2147 Acc: 0.9359
val Loss: 0.2461 Acc: 0.9289
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1841 Acc: 0.9467
val Loss: 0.2241 Acc: 0.9346
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1755 Acc: 0.9491
val Loss: 0.2184 Acc: 0.9382
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1688 Acc: 0.9503
val Loss: 0.2176 Acc: 0.9376
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1675 Acc: 0.9520
val Loss: 0.2185 Acc: 0.9375
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1681 Acc: 0.9517
val Loss: 0.2201 Acc: 0.9368
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1672 Acc: 0.9511
val Loss: 0.2161 Acc: 0.9399
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1662 Acc: 0.9522
val Loss: 0.2167 Acc: 0.9373
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1671 Acc: 0.9522
val Loss: 0.2168 Acc: 0.9394
Epoch finished in 0m 39s
Best validation accuracy: 0.9394452331549634
Before Pruning
++++++++++++++++++
Model Test Accuracy:  0.9471035648432697
Pruning Epoch 1
++++++++++++++++++
number of weights to prune:  53540.0
Sparsity of Pruned Mask:  tensor(0.2000)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.0443 Acc: 0.2619
val Loss: 1.4653 Acc: 0.5000
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.9653 Acc: 0.6951
val Loss: 0.5426 Acc: 0.8342
Epoch finished in 2m 25s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4286 Acc: 0.8674
val Loss: 0.4549 Acc: 0.8641
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3471 Acc: 0.8950
val Loss: 0.4438 Acc: 0.8654
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3107 Acc: 0.9062
val Loss: 0.3347 Acc: 0.8989
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2835 Acc: 0.9153
val Loss: 0.3118 Acc: 0.9108
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2694 Acc: 0.9210
val Loss: 0.3046 Acc: 0.9106
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2570 Acc: 0.9230
val Loss: 0.3615 Acc: 0.9079
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2460 Acc: 0.9265
val Loss: 0.3126 Acc: 0.9132
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2362 Acc: 0.9296
val Loss: 0.2769 Acc: 0.9183
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2314 Acc: 0.9308
val Loss: 0.2919 Acc: 0.9200
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2242 Acc: 0.9342
val Loss: 0.2820 Acc: 0.9154
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2177 Acc: 0.9353
val Loss: 0.2706 Acc: 0.9233
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2127 Acc: 0.9374
val Loss: 0.2733 Acc: 0.9270
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2079 Acc: 0.9380
val Loss: 0.2905 Acc: 0.9153
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2042 Acc: 0.9393
val Loss: 0.2968 Acc: 0.9163
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1962 Acc: 0.9421
val Loss: 0.2291 Acc: 0.9360
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1672 Acc: 0.9510
val Loss: 0.2171 Acc: 0.9397
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1583 Acc: 0.9536
val Loss: 0.2120 Acc: 0.9411
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1532 Acc: 0.9560
val Loss: 0.2114 Acc: 0.9420
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1525 Acc: 0.9557
val Loss: 0.2078 Acc: 0.9422
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1522 Acc: 0.9558
val Loss: 0.2110 Acc: 0.9407
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1517 Acc: 0.9565
val Loss: 0.2103 Acc: 0.9418
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1505 Acc: 0.9561
val Loss: 0.2062 Acc: 0.9435
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1521 Acc: 0.9563
val Loss: 0.2053 Acc: 0.9419
Epoch finished in 0m 39s
Best validation accuracy: 0.9419023697717593
Model Test Accuracy:  0.9507913337430853
Pruning Epoch 2
++++++++++++++++++
number of weights to prune:  42831.0
Sparsity of Pruned Mask:  tensor(0.3600)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2536 Acc: 0.1739
val Loss: 2.2305 Acc: 0.1930
Epoch finished in 3m 3s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.1139 Acc: 0.2433
val Loss: 1.9661 Acc: 0.3412
Epoch finished in 2m 26s
Training Epoch 2/24
********************
Warmup
train Loss: 1.6923 Acc: 0.4075
val Loss: 1.1723 Acc: 0.6030
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.6970 Acc: 0.7758
val Loss: 0.4959 Acc: 0.8445
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4380 Acc: 0.8643
val Loss: 0.3788 Acc: 0.8837
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3676 Acc: 0.8871
val Loss: 0.3448 Acc: 0.8978
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3290 Acc: 0.8989
val Loss: 0.3598 Acc: 0.8954
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3056 Acc: 0.9080
val Loss: 0.3190 Acc: 0.9026
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2845 Acc: 0.9152
val Loss: 0.3224 Acc: 0.9048
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2718 Acc: 0.9180
val Loss: 0.3154 Acc: 0.9080
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2562 Acc: 0.9231
val Loss: 0.2965 Acc: 0.9112
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2442 Acc: 0.9268
val Loss: 0.2958 Acc: 0.9149
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2362 Acc: 0.9293
val Loss: 0.2745 Acc: 0.9190
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2297 Acc: 0.9312
val Loss: 0.2655 Acc: 0.9235
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2181 Acc: 0.9351
val Loss: 0.2683 Acc: 0.9249
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2165 Acc: 0.9357
val Loss: 0.2502 Acc: 0.9289
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2080 Acc: 0.9373
val Loss: 0.2324 Acc: 0.9332
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1793 Acc: 0.9476
val Loss: 0.2248 Acc: 0.9378
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1687 Acc: 0.9507
val Loss: 0.2219 Acc: 0.9385
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1639 Acc: 0.9520
val Loss: 0.2156 Acc: 0.9386
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1621 Acc: 0.9527
val Loss: 0.2183 Acc: 0.9372
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1614 Acc: 0.9527
val Loss: 0.2178 Acc: 0.9389
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1617 Acc: 0.9531
val Loss: 0.2160 Acc: 0.9386
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1635 Acc: 0.9531
val Loss: 0.2142 Acc: 0.9394
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1626 Acc: 0.9513
val Loss: 0.2158 Acc: 0.9386
Epoch finished in 0m 39s
Best validation accuracy: 0.9386261876160314
Model Test Accuracy:  0.9465657652120466
Pruning Epoch 3
++++++++++++++++++
number of weights to prune:  34265.0
Sparsity of Pruned Mask:  tensor(0.4880)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.9035 Acc: 0.3815
val Loss: 2.0253 Acc: 0.3384
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5395 Acc: 0.8418
val Loss: 0.4084 Acc: 0.8820
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3346 Acc: 0.9030
val Loss: 0.4191 Acc: 0.8913
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2876 Acc: 0.9157
val Loss: 0.2991 Acc: 0.9157
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2587 Acc: 0.9225
val Loss: 0.3111 Acc: 0.9087
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2428 Acc: 0.9280
val Loss: 0.2719 Acc: 0.9272
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2310 Acc: 0.9315
val Loss: 0.2698 Acc: 0.9207
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2212 Acc: 0.9342
val Loss: 0.2911 Acc: 0.9143
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2165 Acc: 0.9348
val Loss: 0.2676 Acc: 0.9204
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2113 Acc: 0.9376
val Loss: 0.2561 Acc: 0.9242
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2069 Acc: 0.9391
val Loss: 0.2700 Acc: 0.9225
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1996 Acc: 0.9412
val Loss: 0.3011 Acc: 0.9198
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2000 Acc: 0.9416
val Loss: 0.2524 Acc: 0.9280
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1956 Acc: 0.9425
val Loss: 0.2362 Acc: 0.9319
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1942 Acc: 0.9424
val Loss: 0.2551 Acc: 0.9238
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1914 Acc: 0.9434
val Loss: 0.2528 Acc: 0.9273
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1837 Acc: 0.9458
val Loss: 0.2196 Acc: 0.9372
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1592 Acc: 0.9534
val Loss: 0.2133 Acc: 0.9405
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1519 Acc: 0.9563
val Loss: 0.2086 Acc: 0.9417
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1441 Acc: 0.9589
val Loss: 0.2050 Acc: 0.9431
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1442 Acc: 0.9579
val Loss: 0.2067 Acc: 0.9420
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1439 Acc: 0.9584
val Loss: 0.2057 Acc: 0.9416
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1446 Acc: 0.9584
val Loss: 0.2061 Acc: 0.9426
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1436 Acc: 0.9590
val Loss: 0.2070 Acc: 0.9418
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1427 Acc: 0.9590
val Loss: 0.2060 Acc: 0.9418
Epoch finished in 0m 39s
Best validation accuracy: 0.9417931636999017
Model Test Accuracy:  0.9527120467117394
Pruning Epoch 4
++++++++++++++++++
number of weights to prune:  27412.0
Sparsity of Pruned Mask:  tensor(0.5904)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1708 Acc: 0.2157
val Loss: 2.2479 Acc: 0.1924
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.1845 Acc: 0.2178
val Loss: 1.9844 Acc: 0.3543
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.8741 Acc: 0.7244
val Loss: 0.3926 Acc: 0.8828
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3170 Acc: 0.9048
val Loss: 0.3029 Acc: 0.9107
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2609 Acc: 0.9224
val Loss: 0.3059 Acc: 0.9123
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2377 Acc: 0.9302
val Loss: 0.2685 Acc: 0.9234
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2203 Acc: 0.9342
val Loss: 0.2632 Acc: 0.9253
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2134 Acc: 0.9370
val Loss: 0.2596 Acc: 0.9239
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2077 Acc: 0.9388
val Loss: 0.2664 Acc: 0.9221
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1974 Acc: 0.9424
val Loss: 0.2541 Acc: 0.9277
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1965 Acc: 0.9412
val Loss: 0.2801 Acc: 0.9232
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1936 Acc: 0.9442
val Loss: 0.2409 Acc: 0.9299
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1883 Acc: 0.9442
val Loss: 0.2751 Acc: 0.9256
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1890 Acc: 0.9448
val Loss: 0.2632 Acc: 0.9230
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1846 Acc: 0.9451
val Loss: 0.2358 Acc: 0.9314
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1816 Acc: 0.9473
val Loss: 0.2505 Acc: 0.9293
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1803 Acc: 0.9464
val Loss: 0.2231 Acc: 0.9385
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1515 Acc: 0.9548
val Loss: 0.2156 Acc: 0.9408
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1434 Acc: 0.9583
val Loss: 0.2118 Acc: 0.9419
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1430 Acc: 0.9583
val Loss: 0.2084 Acc: 0.9432
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1391 Acc: 0.9595
val Loss: 0.2104 Acc: 0.9428
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1385 Acc: 0.9602
val Loss: 0.2146 Acc: 0.9409
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1385 Acc: 0.9602
val Loss: 0.2083 Acc: 0.9427
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1363 Acc: 0.9609
val Loss: 0.2156 Acc: 0.9406
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1364 Acc: 0.9612
val Loss: 0.2086 Acc: 0.9423
Epoch finished in 0m 39s
Best validation accuracy: 0.9422845910232609
Model Test Accuracy:  0.9527888752304855
Pruning Epoch 5
++++++++++++++++++
number of weights to prune:  21929.0
Sparsity of Pruned Mask:  tensor(0.6723)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.8560 Acc: 0.4444
val Loss: 1.7892 Acc: 0.5040
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5785 Acc: 0.8334
val Loss: 0.3100 Acc: 0.9056
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2626 Acc: 0.9209
val Loss: 0.2784 Acc: 0.9183
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2306 Acc: 0.9319
val Loss: 0.2814 Acc: 0.9173
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2118 Acc: 0.9386
val Loss: 0.2501 Acc: 0.9268
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2049 Acc: 0.9397
val Loss: 0.2439 Acc: 0.9296
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1959 Acc: 0.9430
val Loss: 0.2772 Acc: 0.9214
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1919 Acc: 0.9435
val Loss: 0.2601 Acc: 0.9263
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1877 Acc: 0.9452
val Loss: 0.2469 Acc: 0.9278
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1817 Acc: 0.9462
val Loss: 0.2753 Acc: 0.9225
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1808 Acc: 0.9470
val Loss: 0.2400 Acc: 0.9313
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1807 Acc: 0.9459
val Loss: 0.2517 Acc: 0.9286
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1784 Acc: 0.9477
val Loss: 0.2290 Acc: 0.9334
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1805 Acc: 0.9456
val Loss: 0.2389 Acc: 0.9305
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1769 Acc: 0.9480
val Loss: 0.2427 Acc: 0.9314
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1777 Acc: 0.9471
val Loss: 0.2391 Acc: 0.9316
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1737 Acc: 0.9482
val Loss: 0.2218 Acc: 0.9373
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1488 Acc: 0.9568
val Loss: 0.2145 Acc: 0.9410
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1413 Acc: 0.9585
val Loss: 0.2144 Acc: 0.9414
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1342 Acc: 0.9607
val Loss: 0.2133 Acc: 0.9404
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1344 Acc: 0.9612
val Loss: 0.2100 Acc: 0.9421
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1331 Acc: 0.9612
val Loss: 0.2118 Acc: 0.9421
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1343 Acc: 0.9605
val Loss: 0.2157 Acc: 0.9395
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1328 Acc: 0.9617
val Loss: 0.2113 Acc: 0.9426
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1338 Acc: 0.9606
val Loss: 0.2085 Acc: 0.9418
Epoch finished in 0m 39s
Best validation accuracy: 0.9417931636999017
Model Test Accuracy:  0.9517516902274124
Pruning Epoch 6
++++++++++++++++++
number of weights to prune:  17543.0
Sparsity of Pruned Mask:  tensor(0.7379)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.4064 Acc: 0.5762
val Loss: 0.4140 Acc: 0.8703
Epoch finished in 2m 60s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3247 Acc: 0.9039
val Loss: 0.3849 Acc: 0.9055
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2515 Acc: 0.9256
val Loss: 0.3714 Acc: 0.9113
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2205 Acc: 0.9358
val Loss: 0.2878 Acc: 0.9186
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2013 Acc: 0.9411
val Loss: 0.2867 Acc: 0.9272
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1939 Acc: 0.9439
val Loss: 0.2440 Acc: 0.9306
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1888 Acc: 0.9441
val Loss: 0.2479 Acc: 0.9279
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1843 Acc: 0.9455
val Loss: 0.2701 Acc: 0.9254
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1808 Acc: 0.9470
val Loss: 0.2411 Acc: 0.9335
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1767 Acc: 0.9480
val Loss: 0.2511 Acc: 0.9292
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1766 Acc: 0.9474
val Loss: 0.2439 Acc: 0.9303
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1771 Acc: 0.9481
val Loss: 0.2523 Acc: 0.9301
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1718 Acc: 0.9488
val Loss: 0.2638 Acc: 0.9276
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1736 Acc: 0.9491
val Loss: 0.2356 Acc: 0.9348
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1733 Acc: 0.9479
val Loss: 0.2404 Acc: 0.9316
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1723 Acc: 0.9494
val Loss: 0.2360 Acc: 0.9331
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1685 Acc: 0.9500
val Loss: 0.2245 Acc: 0.9380
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1463 Acc: 0.9563
val Loss: 0.2183 Acc: 0.9412
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1386 Acc: 0.9587
val Loss: 0.2116 Acc: 0.9429
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1356 Acc: 0.9602
val Loss: 0.2072 Acc: 0.9446
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1324 Acc: 0.9609
val Loss: 0.2136 Acc: 0.9435
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1306 Acc: 0.9618
val Loss: 0.2115 Acc: 0.9436
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1331 Acc: 0.9602
val Loss: 0.2072 Acc: 0.9436
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1310 Acc: 0.9620
val Loss: 0.2087 Acc: 0.9428
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1312 Acc: 0.9612
val Loss: 0.2081 Acc: 0.9446
Epoch finished in 0m 39s
Best validation accuracy: 0.9445779185322704
Model Test Accuracy:  0.9500614628149968
Pruning Epoch 7
++++++++++++++++++
number of weights to prune:  14034.0
Sparsity of Pruned Mask:  tensor(0.7903)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.6196 Acc: 0.5038
val Loss: 0.7863 Acc: 0.8130
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3452 Acc: 0.9003
val Loss: 0.3053 Acc: 0.9106
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2437 Acc: 0.9284
val Loss: 0.3103 Acc: 0.9119
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2162 Acc: 0.9363
val Loss: 0.2571 Acc: 0.9251
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2014 Acc: 0.9416
val Loss: 0.2870 Acc: 0.9275
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1891 Acc: 0.9445
val Loss: 0.2439 Acc: 0.9298
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1831 Acc: 0.9465
val Loss: 0.2551 Acc: 0.9271
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1828 Acc: 0.9458
val Loss: 0.2466 Acc: 0.9285
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1780 Acc: 0.9477
val Loss: 0.2516 Acc: 0.9331
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1750 Acc: 0.9485
val Loss: 0.2367 Acc: 0.9340
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1753 Acc: 0.9485
val Loss: 0.2370 Acc: 0.9331
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1734 Acc: 0.9486
val Loss: 0.2487 Acc: 0.9332
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1740 Acc: 0.9489
val Loss: 0.2322 Acc: 0.9335
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1744 Acc: 0.9473
val Loss: 0.2360 Acc: 0.9329
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1730 Acc: 0.9490
val Loss: 0.2588 Acc: 0.9280
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1724 Acc: 0.9493
val Loss: 0.2433 Acc: 0.9325
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1697 Acc: 0.9492
val Loss: 0.2163 Acc: 0.9387
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1473 Acc: 0.9561
val Loss: 0.2157 Acc: 0.9399
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1387 Acc: 0.9600
val Loss: 0.2101 Acc: 0.9430
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1342 Acc: 0.9605
val Loss: 0.2071 Acc: 0.9435
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1332 Acc: 0.9613
val Loss: 0.2105 Acc: 0.9438
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1326 Acc: 0.9615
val Loss: 0.2114 Acc: 0.9423
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1322 Acc: 0.9612
val Loss: 0.2056 Acc: 0.9434
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1335 Acc: 0.9610
val Loss: 0.2070 Acc: 0.9446
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1340 Acc: 0.9612
val Loss: 0.2083 Acc: 0.9427
Epoch finished in 0m 39s
Best validation accuracy: 0.9426668122747625
Model Test Accuracy:  0.9500230485556238
Pruning Epoch 8
++++++++++++++++++
number of weights to prune:  11227.0
Sparsity of Pruned Mask:  tensor(0.8322)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.4490 Acc: 0.5603
val Loss: 0.5055 Acc: 0.8605
Epoch finished in 2m 60s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3384 Acc: 0.8982
val Loss: 0.3137 Acc: 0.9084
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2488 Acc: 0.9263
val Loss: 0.2946 Acc: 0.9154
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2213 Acc: 0.9360
val Loss: 0.3004 Acc: 0.9190
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2069 Acc: 0.9401
val Loss: 0.2420 Acc: 0.9295
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1957 Acc: 0.9429
val Loss: 0.2754 Acc: 0.9311
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1883 Acc: 0.9450
val Loss: 0.2426 Acc: 0.9284
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1813 Acc: 0.9461
val Loss: 0.2535 Acc: 0.9311
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1800 Acc: 0.9468
val Loss: 0.2687 Acc: 0.9266
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1780 Acc: 0.9470
val Loss: 0.2387 Acc: 0.9310
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1782 Acc: 0.9483
val Loss: 0.2569 Acc: 0.9270
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1762 Acc: 0.9478
val Loss: 0.3079 Acc: 0.9121
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1737 Acc: 0.9487
val Loss: 0.2459 Acc: 0.9325
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1779 Acc: 0.9482
val Loss: 0.2611 Acc: 0.9257
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1785 Acc: 0.9474
val Loss: 0.2641 Acc: 0.9270
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1746 Acc: 0.9471
val Loss: 0.3089 Acc: 0.9223
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1725 Acc: 0.9505
val Loss: 0.2248 Acc: 0.9363
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1474 Acc: 0.9560
val Loss: 0.2142 Acc: 0.9416
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1397 Acc: 0.9589
val Loss: 0.2130 Acc: 0.9420
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1382 Acc: 0.9592
val Loss: 0.2092 Acc: 0.9422
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1357 Acc: 0.9601
val Loss: 0.2082 Acc: 0.9432
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1359 Acc: 0.9607
val Loss: 0.2127 Acc: 0.9441
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1350 Acc: 0.9605
val Loss: 0.2059 Acc: 0.9425
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1355 Acc: 0.9604
val Loss: 0.2139 Acc: 0.9409
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1356 Acc: 0.9594
val Loss: 0.2107 Acc: 0.9418
Epoch finished in 0m 39s
Best validation accuracy: 0.9418477667358305
Model Test Accuracy:  0.9502919483712353
Pruning Epoch 9
++++++++++++++++++
number of weights to prune:  8982.0
Sparsity of Pruned Mask:  tensor(0.8658)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.7236 Acc: 0.4732
val Loss: 0.4986 Acc: 0.8438
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3473 Acc: 0.8970
val Loss: 0.3336 Acc: 0.9066
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2598 Acc: 0.9248
val Loss: 0.2899 Acc: 0.9178
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2242 Acc: 0.9338
val Loss: 0.3246 Acc: 0.9255
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2079 Acc: 0.9384
val Loss: 0.2461 Acc: 0.9277
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.1969 Acc: 0.9419
val Loss: 0.2481 Acc: 0.9313
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1893 Acc: 0.9441
val Loss: 0.2358 Acc: 0.9327
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1892 Acc: 0.9449
val Loss: 0.2374 Acc: 0.9313
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1848 Acc: 0.9455
val Loss: 0.2474 Acc: 0.9298
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1819 Acc: 0.9453
val Loss: 0.2786 Acc: 0.9245
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1797 Acc: 0.9478
val Loss: 0.2651 Acc: 0.9300
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1835 Acc: 0.9446
val Loss: 0.2778 Acc: 0.9247
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1808 Acc: 0.9473
val Loss: 0.2368 Acc: 0.9327
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1803 Acc: 0.9468
val Loss: 0.2433 Acc: 0.9328
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1798 Acc: 0.9470
val Loss: 0.2479 Acc: 0.9299
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1796 Acc: 0.9463
val Loss: 0.2563 Acc: 0.9273
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1783 Acc: 0.9460
val Loss: 0.2255 Acc: 0.9362
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1569 Acc: 0.9535
val Loss: 0.2180 Acc: 0.9384
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1486 Acc: 0.9566
val Loss: 0.2138 Acc: 0.9406
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1438 Acc: 0.9575
val Loss: 0.2122 Acc: 0.9423
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1430 Acc: 0.9583
val Loss: 0.2111 Acc: 0.9425
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1428 Acc: 0.9578
val Loss: 0.2162 Acc: 0.9416
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1410 Acc: 0.9594
val Loss: 0.2141 Acc: 0.9397
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1417 Acc: 0.9590
val Loss: 0.2104 Acc: 0.9423
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1406 Acc: 0.9590
val Loss: 0.2114 Acc: 0.9414
Epoch finished in 0m 39s
Best validation accuracy: 0.9413563394124713
Model Test Accuracy:  0.9525968039336201
Pruning Epoch 10
++++++++++++++++++
number of weights to prune:  7185.0
Sparsity of Pruned Mask:  tensor(0.8926)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.7498 Acc: 0.4555
val Loss: 1.0423 Acc: 0.7490
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.3855 Acc: 0.8915
val Loss: 0.3455 Acc: 0.8966
Epoch finished in 2m 25s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2558 Acc: 0.9252
val Loss: 0.3076 Acc: 0.9200
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2256 Acc: 0.9329
val Loss: 0.2519 Acc: 0.9278
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2098 Acc: 0.9390
val Loss: 0.2538 Acc: 0.9271
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2025 Acc: 0.9406
val Loss: 0.2630 Acc: 0.9248
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.1947 Acc: 0.9425
val Loss: 0.2450 Acc: 0.9291
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.1904 Acc: 0.9442
val Loss: 0.2368 Acc: 0.9322
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1901 Acc: 0.9443
val Loss: 0.2368 Acc: 0.9331
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1883 Acc: 0.9442
val Loss: 0.2397 Acc: 0.9321
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1880 Acc: 0.9451
val Loss: 0.2598 Acc: 0.9289
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1902 Acc: 0.9434
val Loss: 0.2488 Acc: 0.9294
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1861 Acc: 0.9462
val Loss: 0.3023 Acc: 0.9219
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1877 Acc: 0.9445
val Loss: 0.2481 Acc: 0.9280
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1854 Acc: 0.9460
val Loss: 0.2723 Acc: 0.9237
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1869 Acc: 0.9439
val Loss: 0.2390 Acc: 0.9320
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1854 Acc: 0.9448
val Loss: 0.2269 Acc: 0.9368
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1631 Acc: 0.9524
val Loss: 0.2179 Acc: 0.9380
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1555 Acc: 0.9552
val Loss: 0.2179 Acc: 0.9395
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1498 Acc: 0.9559
val Loss: 0.2198 Acc: 0.9400
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1502 Acc: 0.9572
val Loss: 0.2138 Acc: 0.9417
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1489 Acc: 0.9573
val Loss: 0.2125 Acc: 0.9413
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1490 Acc: 0.9564
val Loss: 0.2124 Acc: 0.9421
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1484 Acc: 0.9569
val Loss: 0.2141 Acc: 0.9414
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1469 Acc: 0.9577
val Loss: 0.2138 Acc: 0.9416
Epoch finished in 0m 39s
Best validation accuracy: 0.9415747515561865
Model Test Accuracy:  0.9491395205900429
Pruning Epoch 11
++++++++++++++++++
number of weights to prune:  5748.0
Sparsity of Pruned Mask:  tensor(0.9141)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.7868 Acc: 0.4403
val Loss: 1.0492 Acc: 0.7737
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.4246 Acc: 0.8843
val Loss: 0.5666 Acc: 0.8979
Epoch finished in 2m 25s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2726 Acc: 0.9200
val Loss: 0.2889 Acc: 0.9156
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2367 Acc: 0.9307
val Loss: 0.2768 Acc: 0.9201
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2226 Acc: 0.9342
val Loss: 0.2464 Acc: 0.9303
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2101 Acc: 0.9392
val Loss: 0.2437 Acc: 0.9308
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2033 Acc: 0.9410
val Loss: 0.2400 Acc: 0.9313
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2028 Acc: 0.9413
val Loss: 0.2535 Acc: 0.9257
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.1975 Acc: 0.9417
val Loss: 0.2512 Acc: 0.9305
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.1972 Acc: 0.9409
val Loss: 0.2503 Acc: 0.9271
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.1968 Acc: 0.9421
val Loss: 0.2900 Acc: 0.9149
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.1944 Acc: 0.9421
val Loss: 0.2712 Acc: 0.9258
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.1977 Acc: 0.9415
val Loss: 0.2697 Acc: 0.9280
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.1945 Acc: 0.9423
val Loss: 0.2661 Acc: 0.9230
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.1936 Acc: 0.9424
val Loss: 0.2480 Acc: 0.9304
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.1960 Acc: 0.9419
val Loss: 0.2438 Acc: 0.9288
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.1934 Acc: 0.9431
val Loss: 0.2254 Acc: 0.9367
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1683 Acc: 0.9512
val Loss: 0.2214 Acc: 0.9385
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1628 Acc: 0.9530
val Loss: 0.2155 Acc: 0.9392
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1577 Acc: 0.9542
val Loss: 0.2108 Acc: 0.9417
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1555 Acc: 0.9552
val Loss: 0.2148 Acc: 0.9418
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1534 Acc: 0.9552
val Loss: 0.2135 Acc: 0.9416
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1559 Acc: 0.9542
val Loss: 0.2140 Acc: 0.9414
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1562 Acc: 0.9542
val Loss: 0.2138 Acc: 0.9411
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1552 Acc: 0.9548
val Loss: 0.2153 Acc: 0.9416
Epoch finished in 0m 39s
Best validation accuracy: 0.9415747515561865
Model Test Accuracy:  0.9514827904118007
Pruning Epoch 12
++++++++++++++++++
number of weights to prune:  4598.0
Sparsity of Pruned Mask:  tensor(0.9313)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.9609 Acc: 0.3481
val Loss: 2.2058 Acc: 0.2421
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.6711 Acc: 0.8186
val Loss: 0.3309 Acc: 0.8995
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2709 Acc: 0.9202
val Loss: 0.2823 Acc: 0.9172
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2446 Acc: 0.9302
val Loss: 0.2585 Acc: 0.9262
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2269 Acc: 0.9342
val Loss: 0.2600 Acc: 0.9244
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2203 Acc: 0.9356
val Loss: 0.2473 Acc: 0.9290
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2136 Acc: 0.9375
val Loss: 0.3355 Acc: 0.9142
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2111 Acc: 0.9384
val Loss: 0.2731 Acc: 0.9209
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2081 Acc: 0.9384
val Loss: 0.2806 Acc: 0.9244
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2058 Acc: 0.9390
val Loss: 0.2566 Acc: 0.9231
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2061 Acc: 0.9385
val Loss: 0.2543 Acc: 0.9291
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2047 Acc: 0.9402
val Loss: 0.2596 Acc: 0.9252
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2043 Acc: 0.9387
val Loss: 0.2781 Acc: 0.9167
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2038 Acc: 0.9398
val Loss: 0.2786 Acc: 0.9276
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2020 Acc: 0.9395
val Loss: 0.2435 Acc: 0.9328
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2037 Acc: 0.9403
val Loss: 0.2487 Acc: 0.9275
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2008 Acc: 0.9403
val Loss: 0.2305 Acc: 0.9338
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1798 Acc: 0.9464
val Loss: 0.2214 Acc: 0.9363
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1735 Acc: 0.9498
val Loss: 0.2179 Acc: 0.9374
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1691 Acc: 0.9511
val Loss: 0.2165 Acc: 0.9395
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1678 Acc: 0.9514
val Loss: 0.2181 Acc: 0.9389
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1684 Acc: 0.9520
val Loss: 0.2173 Acc: 0.9390
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1659 Acc: 0.9525
val Loss: 0.2167 Acc: 0.9390
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1659 Acc: 0.9522
val Loss: 0.2153 Acc: 0.9394
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1670 Acc: 0.9520
val Loss: 0.2132 Acc: 0.9399
Epoch finished in 0m 39s
Best validation accuracy: 0.9399366604783226
Model Test Accuracy:  0.9486017209588198
Pruning Epoch 13
++++++++++++++++++
number of weights to prune:  3678.0
Sparsity of Pruned Mask:  tensor(0.9450)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.8853 Acc: 0.3772
val Loss: 1.7004 Acc: 0.5276
Epoch finished in 2m 58s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5642 Acc: 0.8406
val Loss: 0.3613 Acc: 0.8979
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.2867 Acc: 0.9148
val Loss: 0.3230 Acc: 0.9136
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2513 Acc: 0.9261
val Loss: 0.2698 Acc: 0.9222
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2349 Acc: 0.9305
val Loss: 0.2951 Acc: 0.9177
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2285 Acc: 0.9327
val Loss: 0.2590 Acc: 0.9260
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2247 Acc: 0.9328
val Loss: 0.2615 Acc: 0.9256
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2200 Acc: 0.9352
val Loss: 0.2595 Acc: 0.9244
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2206 Acc: 0.9349
val Loss: 0.2444 Acc: 0.9286
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2187 Acc: 0.9372
val Loss: 0.2753 Acc: 0.9246
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2168 Acc: 0.9355
val Loss: 0.3112 Acc: 0.9109
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2144 Acc: 0.9375
val Loss: 0.2575 Acc: 0.9317
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2165 Acc: 0.9366
val Loss: 0.2778 Acc: 0.9180
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2144 Acc: 0.9360
val Loss: 0.2437 Acc: 0.9289
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2172 Acc: 0.9358
val Loss: 0.2628 Acc: 0.9253
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2126 Acc: 0.9376
val Loss: 0.2659 Acc: 0.9242
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2127 Acc: 0.9378
val Loss: 0.2336 Acc: 0.9325
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1878 Acc: 0.9459
val Loss: 0.2252 Acc: 0.9367
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1834 Acc: 0.9465
val Loss: 0.2221 Acc: 0.9376
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1804 Acc: 0.9470
val Loss: 0.2185 Acc: 0.9386
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1768 Acc: 0.9489
val Loss: 0.2210 Acc: 0.9388
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1758 Acc: 0.9489
val Loss: 0.2191 Acc: 0.9392
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1758 Acc: 0.9492
val Loss: 0.2205 Acc: 0.9369
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1755 Acc: 0.9491
val Loss: 0.2211 Acc: 0.9392
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1750 Acc: 0.9495
val Loss: 0.2200 Acc: 0.9384
Epoch finished in 0m 39s
Best validation accuracy: 0.9384077754723162
Model Test Accuracy:  0.9494468346650276
Pruning Epoch 14
++++++++++++++++++
number of weights to prune:  2943.0
Sparsity of Pruned Mask:  tensor(0.9560)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 1.8932 Acc: 0.3527
val Loss: 1.9607 Acc: 0.3799
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.5405 Acc: 0.8426
val Loss: 0.3515 Acc: 0.8966
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3035 Acc: 0.9087
val Loss: 0.3426 Acc: 0.9108
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2667 Acc: 0.9213
val Loss: 0.3033 Acc: 0.9166
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2521 Acc: 0.9260
val Loss: 0.2825 Acc: 0.9183
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2429 Acc: 0.9290
val Loss: 0.2666 Acc: 0.9226
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2350 Acc: 0.9307
val Loss: 0.2895 Acc: 0.9145
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2346 Acc: 0.9300
val Loss: 0.2715 Acc: 0.9224
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2307 Acc: 0.9316
val Loss: 0.3048 Acc: 0.9135
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2317 Acc: 0.9320
val Loss: 0.3256 Acc: 0.9180
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2280 Acc: 0.9328
val Loss: 0.3328 Acc: 0.9160
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2266 Acc: 0.9330
val Loss: 0.3102 Acc: 0.9116
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2285 Acc: 0.9328
val Loss: 0.3118 Acc: 0.9188
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2267 Acc: 0.9334
val Loss: 0.2727 Acc: 0.9209
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2219 Acc: 0.9349
val Loss: 0.2983 Acc: 0.9157
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2253 Acc: 0.9328
val Loss: 0.2593 Acc: 0.9261
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2207 Acc: 0.9358
val Loss: 0.2475 Acc: 0.9292
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.1999 Acc: 0.9410
val Loss: 0.2325 Acc: 0.9338
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.1930 Acc: 0.9436
val Loss: 0.2274 Acc: 0.9353
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.1892 Acc: 0.9445
val Loss: 0.2294 Acc: 0.9364
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1871 Acc: 0.9455
val Loss: 0.2284 Acc: 0.9352
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.1890 Acc: 0.9445
val Loss: 0.2296 Acc: 0.9357
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1864 Acc: 0.9456
val Loss: 0.2292 Acc: 0.9355
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1856 Acc: 0.9460
val Loss: 0.2270 Acc: 0.9361
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1877 Acc: 0.9451
val Loss: 0.2300 Acc: 0.9357
Epoch finished in 0m 39s
Best validation accuracy: 0.9356776236758764
Model Test Accuracy:  0.9455669944683466
Pruning Epoch 15
++++++++++++++++++
number of weights to prune:  2354.0
Sparsity of Pruned Mask:  tensor(0.9648)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1472 Acc: 0.2273
val Loss: 1.8560 Acc: 0.3222
Epoch finished in 2m 58s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.9606 Acc: 0.7108
val Loss: 0.5236 Acc: 0.8689
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3331 Acc: 0.9018
val Loss: 0.3097 Acc: 0.9076
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.2831 Acc: 0.9164
val Loss: 0.2924 Acc: 0.9165
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2625 Acc: 0.9220
val Loss: 0.3046 Acc: 0.9136
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2537 Acc: 0.9249
val Loss: 0.2759 Acc: 0.9185
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2496 Acc: 0.9263
val Loss: 0.2874 Acc: 0.9156
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2453 Acc: 0.9273
val Loss: 0.2840 Acc: 0.9156
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2436 Acc: 0.9279
val Loss: 0.3165 Acc: 0.9179
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2440 Acc: 0.9283
val Loss: 0.2686 Acc: 0.9220
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2415 Acc: 0.9292
val Loss: 0.3100 Acc: 0.9187
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2386 Acc: 0.9298
val Loss: 0.2871 Acc: 0.9188
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2383 Acc: 0.9294
val Loss: 0.2762 Acc: 0.9183
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2388 Acc: 0.9297
val Loss: 0.2601 Acc: 0.9252
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2380 Acc: 0.9297
val Loss: 0.2535 Acc: 0.9280
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2377 Acc: 0.9293
val Loss: 0.3041 Acc: 0.9145
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2319 Acc: 0.9309
val Loss: 0.2477 Acc: 0.9291
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2097 Acc: 0.9388
val Loss: 0.2364 Acc: 0.9325
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2036 Acc: 0.9410
val Loss: 0.2367 Acc: 0.9328
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2008 Acc: 0.9411
val Loss: 0.2308 Acc: 0.9355
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.1990 Acc: 0.9418
val Loss: 0.2298 Acc: 0.9351
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2000 Acc: 0.9414
val Loss: 0.2320 Acc: 0.9358
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.1968 Acc: 0.9427
val Loss: 0.2345 Acc: 0.9342
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.1974 Acc: 0.9426
val Loss: 0.2329 Acc: 0.9341
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.1992 Acc: 0.9422
val Loss: 0.2298 Acc: 0.9355
Epoch finished in 0m 39s
Best validation accuracy: 0.9354592115321612
Model Test Accuracy:  0.9415719114935464
Pruning Epoch 16
++++++++++++++++++
number of weights to prune:  1883.0
Sparsity of Pruned Mask:  tensor(0.9719)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1453 Acc: 0.2313
val Loss: 2.0987 Acc: 0.2832
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 0.9430 Acc: 0.6977
val Loss: 0.5053 Acc: 0.8674
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.3586 Acc: 0.8921
val Loss: 0.3496 Acc: 0.8946
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3016 Acc: 0.9091
val Loss: 0.3522 Acc: 0.8954
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.2828 Acc: 0.9159
val Loss: 0.3373 Acc: 0.9053
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2725 Acc: 0.9194
val Loss: 0.3030 Acc: 0.9108
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2695 Acc: 0.9197
val Loss: 0.2905 Acc: 0.9129
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2624 Acc: 0.9228
val Loss: 0.3022 Acc: 0.9108
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2613 Acc: 0.9224
val Loss: 0.2876 Acc: 0.9137
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2556 Acc: 0.9244
val Loss: 0.3109 Acc: 0.9157
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2567 Acc: 0.9241
val Loss: 0.2823 Acc: 0.9154
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2510 Acc: 0.9260
val Loss: 0.2868 Acc: 0.9172
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2499 Acc: 0.9258
val Loss: 0.2834 Acc: 0.9190
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2536 Acc: 0.9243
val Loss: 0.3518 Acc: 0.9007
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2503 Acc: 0.9263
val Loss: 0.3096 Acc: 0.9148
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2492 Acc: 0.9270
val Loss: 0.3459 Acc: 0.9133
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2484 Acc: 0.9255
val Loss: 0.2596 Acc: 0.9261
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2255 Acc: 0.9329
val Loss: 0.2496 Acc: 0.9275
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2150 Acc: 0.9376
val Loss: 0.2433 Acc: 0.9306
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2093 Acc: 0.9392
val Loss: 0.2463 Acc: 0.9301
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2089 Acc: 0.9380
val Loss: 0.2408 Acc: 0.9313
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2115 Acc: 0.9383
val Loss: 0.2423 Acc: 0.9291
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2106 Acc: 0.9377
val Loss: 0.2441 Acc: 0.9304
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2094 Acc: 0.9393
val Loss: 0.2454 Acc: 0.9295
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2118 Acc: 0.9392
val Loss: 0.2417 Acc: 0.9304
Epoch finished in 0m 39s
Best validation accuracy: 0.9304357322267118
Model Test Accuracy:  0.9356177012907191
Pruning Epoch 17
++++++++++++++++++
number of weights to prune:  1506.0
Sparsity of Pruned Mask:  tensor(0.9775)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2204 Acc: 0.1862
val Loss: 1.9851 Acc: 0.3030
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.3072 Acc: 0.5735
val Loss: 0.5431 Acc: 0.8421
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4713 Acc: 0.8646
val Loss: 0.4080 Acc: 0.8783
Epoch finished in 0m 39s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3406 Acc: 0.8975
val Loss: 0.3394 Acc: 0.8983
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3058 Acc: 0.9096
val Loss: 0.3392 Acc: 0.9023
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.2954 Acc: 0.9117
val Loss: 0.3060 Acc: 0.9108
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.2849 Acc: 0.9164
val Loss: 0.3272 Acc: 0.9025
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.2797 Acc: 0.9178
val Loss: 0.4029 Acc: 0.9061
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2752 Acc: 0.9183
val Loss: 0.3040 Acc: 0.9102
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2745 Acc: 0.9185
val Loss: 0.3359 Acc: 0.9106
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2684 Acc: 0.9201
val Loss: 0.3067 Acc: 0.9148
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2698 Acc: 0.9212
val Loss: 0.3086 Acc: 0.9092
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2667 Acc: 0.9210
val Loss: 0.3071 Acc: 0.9068
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2693 Acc: 0.9203
val Loss: 0.2907 Acc: 0.9148
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2636 Acc: 0.9221
val Loss: 0.2814 Acc: 0.9174
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2605 Acc: 0.9242
val Loss: 0.2804 Acc: 0.9179
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2593 Acc: 0.9229
val Loss: 0.2699 Acc: 0.9202
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2344 Acc: 0.9308
val Loss: 0.2548 Acc: 0.9260
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2293 Acc: 0.9326
val Loss: 0.2585 Acc: 0.9261
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2255 Acc: 0.9336
val Loss: 0.2513 Acc: 0.9272
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2213 Acc: 0.9351
val Loss: 0.2523 Acc: 0.9262
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2227 Acc: 0.9349
val Loss: 0.2571 Acc: 0.9266
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2231 Acc: 0.9350
val Loss: 0.2473 Acc: 0.9304
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2238 Acc: 0.9346
val Loss: 0.2493 Acc: 0.9284
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2229 Acc: 0.9335
val Loss: 0.2506 Acc: 0.9274
Epoch finished in 0m 39s
Best validation accuracy: 0.9273779622146991
Model Test Accuracy:  0.9361939151813152
Pruning Epoch 18
++++++++++++++++++
number of weights to prune:  1205.0
Sparsity of Pruned Mask:  tensor(0.9820)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1384 Acc: 0.2284
val Loss: 2.1581 Acc: 0.2879
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.2704 Acc: 0.5817
val Loss: 0.6505 Acc: 0.8097
Epoch finished in 2m 24s
Training Epoch 2/24
********************
Warmup
train Loss: 0.4690 Acc: 0.8591
val Loss: 0.4484 Acc: 0.8693
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.3848 Acc: 0.8840
val Loss: 0.3979 Acc: 0.8822
Epoch finished in 0m 39s
Training Epoch 4/24
********************
Warmup
train Loss: 0.3532 Acc: 0.8944
val Loss: 0.3536 Acc: 0.8961
Epoch finished in 0m 39s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3264 Acc: 0.9025
val Loss: 0.3432 Acc: 0.9003
Epoch finished in 0m 39s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3140 Acc: 0.9057
val Loss: 0.3853 Acc: 0.8935
Epoch finished in 0m 39s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3065 Acc: 0.9074
val Loss: 0.3140 Acc: 0.9083
Epoch finished in 0m 39s
Training Epoch 8/24
********************
Warmup
train Loss: 0.2978 Acc: 0.9109
val Loss: 0.3115 Acc: 0.9081
Epoch finished in 0m 39s
Training Epoch 9/24
********************
Warmup
train Loss: 0.2952 Acc: 0.9125
val Loss: 0.3167 Acc: 0.9050
Epoch finished in 0m 39s
Training Epoch 10/24
********************
Warmup
train Loss: 0.2918 Acc: 0.9126
val Loss: 0.3074 Acc: 0.9091
Epoch finished in 0m 39s
Training Epoch 11/24
********************
Warmup
train Loss: 0.2876 Acc: 0.9155
val Loss: 0.3203 Acc: 0.9061
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.2866 Acc: 0.9142
val Loss: 0.3305 Acc: 0.9044
Epoch finished in 0m 39s
Training Epoch 13/24
********************
Warmup
train Loss: 0.2820 Acc: 0.9157
val Loss: 0.3050 Acc: 0.9117
Epoch finished in 0m 39s
Training Epoch 14/24
********************
Warmup
train Loss: 0.2811 Acc: 0.9179
val Loss: 0.3070 Acc: 0.9098
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.2816 Acc: 0.9171
val Loss: 0.3081 Acc: 0.9105
Epoch finished in 0m 39s
Training Epoch 16/24
********************
Warmup
train Loss: 0.2780 Acc: 0.9177
val Loss: 0.2834 Acc: 0.9151
Epoch finished in 0m 39s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2514 Acc: 0.9247
val Loss: 0.2741 Acc: 0.9208
Epoch finished in 0m 39s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2472 Acc: 0.9273
val Loss: 0.2712 Acc: 0.9212
Epoch finished in 0m 39s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2402 Acc: 0.9290
val Loss: 0.2684 Acc: 0.9210
Epoch finished in 0m 39s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2405 Acc: 0.9290
val Loss: 0.2637 Acc: 0.9235
Epoch finished in 0m 39s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2410 Acc: 0.9290
val Loss: 0.2667 Acc: 0.9231
Epoch finished in 0m 39s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2381 Acc: 0.9304
val Loss: 0.2611 Acc: 0.9242
Epoch finished in 0m 39s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2393 Acc: 0.9289
val Loss: 0.2679 Acc: 0.9217
Epoch finished in 0m 39s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2390 Acc: 0.9301
val Loss: 0.2660 Acc: 0.9214
Epoch finished in 0m 39s
Best validation accuracy: 0.9214262312984602
Model Test Accuracy:  0.9290104486785494
Pruning Epoch 19
++++++++++++++++++
number of weights to prune:  963.0
Sparsity of Pruned Mask:  tensor(0.9856)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2450 Acc: 0.1730
val Loss: 2.2338 Acc: 0.1909
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.0759 Acc: 0.2667
val Loss: 2.0922 Acc: 0.2510
Epoch finished in 2m 23s
Training Epoch 2/24
********************
Warmup
train Loss: 1.6819 Acc: 0.4325
val Loss: 1.0549 Acc: 0.6704
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.6660 Acc: 0.7990
val Loss: 0.4899 Acc: 0.8503
Epoch finished in 0m 38s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4465 Acc: 0.8630
val Loss: 0.4692 Acc: 0.8610
Epoch finished in 0m 38s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3951 Acc: 0.8800
val Loss: 0.3897 Acc: 0.8843
Epoch finished in 0m 38s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3735 Acc: 0.8875
val Loss: 0.3815 Acc: 0.8847
Epoch finished in 0m 38s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3542 Acc: 0.8938
val Loss: 0.3946 Acc: 0.8834
Epoch finished in 0m 38s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3478 Acc: 0.8948
val Loss: 0.3540 Acc: 0.8920
Epoch finished in 0m 38s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3386 Acc: 0.8988
val Loss: 0.3608 Acc: 0.8925
Epoch finished in 0m 38s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3332 Acc: 0.9001
val Loss: 0.3708 Acc: 0.8904
Epoch finished in 0m 38s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3302 Acc: 0.8998
val Loss: 0.3339 Acc: 0.8986
Epoch finished in 0m 39s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3230 Acc: 0.9034
val Loss: 0.3310 Acc: 0.8999
Epoch finished in 0m 38s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3190 Acc: 0.9033
val Loss: 0.3528 Acc: 0.8917
Epoch finished in 0m 38s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3167 Acc: 0.9059
val Loss: 0.3616 Acc: 0.9020
Epoch finished in 0m 38s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3127 Acc: 0.9065
val Loss: 0.3592 Acc: 0.9035
Epoch finished in 0m 38s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3058 Acc: 0.9080
val Loss: 0.3023 Acc: 0.9116
Epoch finished in 0m 38s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2820 Acc: 0.9149
val Loss: 0.2966 Acc: 0.9128
Epoch finished in 0m 38s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2766 Acc: 0.9176
val Loss: 0.2922 Acc: 0.9135
Epoch finished in 0m 38s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2724 Acc: 0.9188
val Loss: 0.2871 Acc: 0.9176
Epoch finished in 0m 38s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2727 Acc: 0.9184
val Loss: 0.2877 Acc: 0.9150
Epoch finished in 0m 38s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2696 Acc: 0.9204
val Loss: 0.2884 Acc: 0.9172
Epoch finished in 0m 38s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2697 Acc: 0.9206
val Loss: 0.2887 Acc: 0.9143
Epoch finished in 0m 38s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2693 Acc: 0.9209
val Loss: 0.2905 Acc: 0.9153
Epoch finished in 0m 38s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2665 Acc: 0.9218
val Loss: 0.2863 Acc: 0.9161
Epoch finished in 0m 38s
Best validation accuracy: 0.916075133777438
Model Test Accuracy:  0.9262830362630607
Pruning Epoch 20
++++++++++++++++++
number of weights to prune:  771.0
Sparsity of Pruned Mask:  tensor(0.9885)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.1274 Acc: 0.2293
val Loss: 2.0188 Acc: 0.3801
Epoch finished in 2m 59s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.7072 Acc: 0.4229
val Loss: 1.2391 Acc: 0.6480
Epoch finished in 2m 25s
Training Epoch 2/24
********************
Warmup
train Loss: 0.6393 Acc: 0.8040
val Loss: 0.5467 Acc: 0.8433
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 0.4518 Acc: 0.8626
val Loss: 0.4243 Acc: 0.8686
Epoch finished in 0m 38s
Training Epoch 4/24
********************
Warmup
train Loss: 0.4082 Acc: 0.8773
val Loss: 0.3970 Acc: 0.8818
Epoch finished in 0m 38s
Training Epoch 5/24
********************
Warmup
train Loss: 0.3860 Acc: 0.8833
val Loss: 0.4394 Acc: 0.8628
Epoch finished in 0m 38s
Training Epoch 6/24
********************
Warmup
train Loss: 0.3746 Acc: 0.8880
val Loss: 0.3758 Acc: 0.8845
Epoch finished in 0m 38s
Training Epoch 7/24
********************
Warmup
train Loss: 0.3601 Acc: 0.8906
val Loss: 0.3856 Acc: 0.8904
Epoch finished in 0m 38s
Training Epoch 8/24
********************
Warmup
train Loss: 0.3558 Acc: 0.8942
val Loss: 0.3801 Acc: 0.8891
Epoch finished in 0m 38s
Training Epoch 9/24
********************
Warmup
train Loss: 0.3499 Acc: 0.8960
val Loss: 0.3794 Acc: 0.8878
Epoch finished in 0m 38s
Training Epoch 10/24
********************
Warmup
train Loss: 0.3431 Acc: 0.8971
val Loss: 0.3525 Acc: 0.8925
Epoch finished in 0m 38s
Training Epoch 11/24
********************
Warmup
train Loss: 0.3371 Acc: 0.8983
val Loss: 0.3569 Acc: 0.8960
Epoch finished in 0m 38s
Training Epoch 12/24
********************
Warmup
train Loss: 0.3312 Acc: 0.9005
val Loss: 0.3605 Acc: 0.8942
Epoch finished in 0m 38s
Training Epoch 13/24
********************
Warmup
train Loss: 0.3290 Acc: 0.9019
val Loss: 0.3630 Acc: 0.8913
Epoch finished in 0m 38s
Training Epoch 14/24
********************
Warmup
train Loss: 0.3293 Acc: 0.9015
val Loss: 0.3607 Acc: 0.8898
Epoch finished in 0m 38s
Training Epoch 15/24
********************
Warmup
train Loss: 0.3263 Acc: 0.9033
val Loss: 0.3452 Acc: 0.8969
Epoch finished in 0m 38s
Training Epoch 16/24
********************
Warmup
train Loss: 0.3157 Acc: 0.9056
val Loss: 0.3184 Acc: 0.9061
Epoch finished in 0m 38s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.2924 Acc: 0.9124
val Loss: 0.3042 Acc: 0.9110
Epoch finished in 0m 38s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.2888 Acc: 0.9136
val Loss: 0.3019 Acc: 0.9107
Epoch finished in 0m 38s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.2834 Acc: 0.9163
val Loss: 0.2954 Acc: 0.9142
Epoch finished in 0m 38s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.2800 Acc: 0.9157
val Loss: 0.3022 Acc: 0.9106
Epoch finished in 0m 38s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.2781 Acc: 0.9176
val Loss: 0.2965 Acc: 0.9135
Epoch finished in 0m 38s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.2817 Acc: 0.9168
val Loss: 0.2956 Acc: 0.9135
Epoch finished in 0m 38s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.2784 Acc: 0.9170
val Loss: 0.2953 Acc: 0.9102
Epoch finished in 0m 38s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.2795 Acc: 0.9168
val Loss: 0.2919 Acc: 0.9150
Epoch finished in 0m 38s
Best validation accuracy: 0.9150376760947909
Model Test Accuracy:  0.922057467732022
Pruning Epoch 21
++++++++++++++++++
number of weights to prune:  616.0
Sparsity of Pruned Mask:  tensor(0.9908)
[10, 15, 20]
Warmup
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Training Epoch 0/24
********************
train Loss: 2.2670 Acc: 0.1614
val Loss: 2.2343 Acc: 0.1924
Epoch finished in 3m 4s
Training Epoch 1/24
********************
Warmup
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.2359 Acc: 0.1879
val Loss: 2.2345 Acc: 0.1924
Epoch finished in 2m 29s
Training Epoch 2/24
********************
Warmup
train Loss: 2.2361 Acc: 0.1880
val Loss: 2.2343 Acc: 0.1925
Epoch finished in 0m 38s
Training Epoch 3/24
********************
Warmup
train Loss: 2.2362 Acc: 0.1880
val Loss: 2.2359 Acc: 0.1923
Epoch finished in 0m 38s
Training Epoch 4/24
********************
Warmup
train Loss: 2.2353 Acc: 0.1880
val Loss: 2.2314 Acc: 0.1924
Epoch finished in 0m 38s
Training Epoch 5/24
********************
Warmup
train Loss: 2.2290 Acc: 0.1947
val Loss: 2.2343 Acc: 0.1925
Epoch finished in 0m 38s
Training Epoch 6/24
********************
Warmup
train Loss: 2.2343 Acc: 0.1877
val Loss: 2.2249 Acc: 0.1922
Epoch finished in 0m 38s
Training Epoch 7/24
********************
Warmup
train Loss: 2.0723 Acc: 0.2631
val Loss: 1.8952 Acc: 0.3130
Epoch finished in 0m 38s
Training Epoch 8/24
********************
Warmup
train Loss: 1.6254 Acc: 0.4320
val Loss: 1.6630 Acc: 0.4347
Epoch finished in 0m 38s
Training Epoch 9/24
********************
Warmup
train Loss: 1.0847 Acc: 0.6413
val Loss: 1.0958 Acc: 0.6541
Epoch finished in 0m 38s
Training Epoch 10/24
********************
Warmup
train Loss: 0.7637 Acc: 0.7573
val Loss: 0.8723 Acc: 0.7348
Epoch finished in 0m 38s
Training Epoch 11/24
********************
Warmup
train Loss: 0.6272 Acc: 0.8014
val Loss: 0.7440 Acc: 0.7641
Epoch finished in 0m 38s
Training Epoch 12/24
********************
Warmup
train Loss: 0.5659 Acc: 0.8234
val Loss: 0.5420 Acc: 0.8320
Epoch finished in 0m 38s
Training Epoch 13/24
********************
Warmup
train Loss: 0.5304 Acc: 0.8342
val Loss: 0.5618 Acc: 0.8222
Epoch finished in 0m 38s
Training Epoch 14/24
********************
Warmup
train Loss: 0.5139 Acc: 0.8425
val Loss: 0.5503 Acc: 0.8284
Epoch finished in 0m 39s
Training Epoch 15/24
********************
Warmup
train Loss: 0.4970 Acc: 0.8463
val Loss: 0.5353 Acc: 0.8336
Epoch finished in 0m 38s
Training Epoch 16/24
********************
Warmup
train Loss: 0.4728 Acc: 0.8526
val Loss: 0.4435 Acc: 0.8622
Epoch finished in 0m 38s
Training Epoch 17/24
********************
Milestone 2: 0.01
train Loss: 0.4260 Acc: 0.8675
val Loss: 0.4227 Acc: 0.8691
Epoch finished in 0m 38s
Training Epoch 18/24
********************
Milestone 2: 0.01
train Loss: 0.4142 Acc: 0.8713
val Loss: 0.4237 Acc: 0.8674
Epoch finished in 0m 38s
Training Epoch 19/24
********************
Milestone 2: 0.01
train Loss: 0.4113 Acc: 0.8747
val Loss: 0.4137 Acc: 0.8704
Epoch finished in 0m 38s
Training Epoch 20/24
********************
Milestone 3: 0.001
train Loss: 0.4082 Acc: 0.8743
val Loss: 0.4160 Acc: 0.8715
Epoch finished in 0m 38s
Training Epoch 21/24
********************
Milestone 3: 0.001
train Loss: 0.4064 Acc: 0.8738
val Loss: 0.4164 Acc: 0.8686
Epoch finished in 0m 38s
Training Epoch 22/24
********************
Milestone 3: 0.001
train Loss: 0.4081 Acc: 0.8759
val Loss: 0.4119 Acc: 0.8713
Epoch finished in 0m 38s
Training Epoch 23/24
********************
Milestone 3: 0.001
train Loss: 0.4060 Acc: 0.8757
val Loss: 0.4126 Acc: 0.8716
Epoch finished in 0m 38s
Training Epoch 24/24
********************
Milestone 3: 0.001
train Loss: 0.4064 Acc: 0.8739
val Loss: 0.4150 Acc: 0.8698
Epoch finished in 0m 38s
Best validation accuracy: 0.8697717593098176
Model Test Accuracy:  0.8794944683466502
conv_layer_1.weight
x:  16
y:  3
layer1.0.conv_layer_1.weight
x:  16
y:  16
layer1.0.conv_layer_2.weight
x:  16
y:  16
layer1.1.conv_layer_1.weight
x:  16
y:  16
layer1.1.conv_layer_2.weight
x:  16
y:  16
layer1.2.conv_layer_1.weight
x:  16
y:  16
layer1.2.conv_layer_2.weight
x:  16
y:  16
layer2.0.conv_layer_1.weight
x:  32
y:  16
layer2.0.conv_layer_2.weight
x:  32
y:  32
layer2.1.conv_layer_1.weight
x:  32
y:  32
layer2.1.conv_layer_2.weight
x:  32
y:  32
layer2.2.conv_layer_1.weight
x:  32
y:  32
layer2.2.conv_layer_2.weight
x:  32
y:  32
layer3.0.conv_layer_1.weight
x:  64
y:  32
layer3.0.conv_layer_2.weight
x:  64
y:  64
layer3.1.conv_layer_1.weight
x:  64
y:  64
layer3.1.conv_layer_2.weight
x:  64
y:  64
layer3.2.conv_layer_1.weight
x:  64
y:  64
layer3.2.conv_layer_2.weight
x:  64
y:  64
conv_layer_1.weight
27.209302325581394
x:  16
y:  3
layer1.0.conv_layer_1.weight
12.684622067767158
x:  16
y:  16
layer1.0.conv_layer_2.weight
9.035621198957429
x:  16
y:  16
layer1.1.conv_layer_1.weight
9.035621198957429
x:  16
y:  16
layer1.1.conv_layer_2.weight
9.513466550825369
x:  16
y:  16
layer1.2.conv_layer_1.weight
10.165073848827108
x:  16
y:  16
layer1.2.conv_layer_2.weight
7.775847089487402
x:  16
y:  16
layer2.0.conv_layer_1.weight
3.321754233608337
x:  32
y:  16
layer2.0.conv_layer_2.weight
2.3985239852398523
x:  32
y:  31
layer2.1.conv_layer_1.weight
2.376817885825917
x:  32
y:  32
layer2.1.conv_layer_2.weight
2.2682873887562405
x:  31
y:  32
layer2.2.conv_layer_1.weight
2.1271977425656607
x:  32
y:  32
layer2.2.conv_layer_2.weight
1.551986108096375
x:  32
y:  32
layer3.0.conv_layer_1.weight
0.5588714053174173
x:  41
y:  28
layer3.0.conv_layer_2.weight
0.2929846454343226
x:  49
y:  43
layer3.1.conv_layer_1.weight
0.35266670283761054
x:  40
y:  55
layer3.1.conv_layer_2.weight
0.13835386034398567
x:  26
y:  31
layer3.2.conv_layer_1.weight
0.11665129401551734
x:  27
y:  32
layer3.2.conv_layer_2.weight
0.021702566328468342
x:  8
y:  8
conv_layer_1.weight
16.511627906976745
x:  15
y:  3
layer1.0.conv_layer_1.weight
7.90616854908775
x:  16
y:  16
layer1.0.conv_layer_2.weight
5.212858384013901
x:  16
y:  16
layer1.1.conv_layer_1.weight
4.344048653344918
x:  16
y:  16
layer1.1.conv_layer_2.weight
4.474370112945265
x:  16
y:  16
layer1.2.conv_layer_1.weight
4.8653344917463075
x:  16
y:  16
layer1.2.conv_layer_2.weight
3.5621198957428324
x:  16
y:  16
layer2.0.conv_layer_1.weight
1.0638297872340425
x:  22
y:  16
layer2.0.conv_layer_2.weight
0.6728890818319948
x:  26
y:  25
layer2.1.conv_layer_1.weight
1.0961580204037336
x:  30
y:  28
layer2.1.conv_layer_2.weight
0.9550683742131539
x:  26
y:  28
layer2.2.conv_layer_1.weight
1.1287171695246365
x:  28
y:  27
layer2.2.conv_layer_2.weight
1.1178641198176689
x:  30
y:  30
layer3.0.conv_layer_1.weight
0.1519262072707542
x:  18
y:  22
layer3.0.conv_layer_2.weight
0.062394878194346484
x:  15
y:  17
layer3.1.conv_layer_1.weight
0.2604307959416201
x:  36
y:  50
layer3.1.conv_layer_2.weight
0.2224513048668005
x:  35
y:  39
layer3.2.conv_layer_1.weight
0.043405132656936685
x:  8
y:  13
layer3.2.conv_layer_2.weight
0.035266670283761056
x:  11
y:  14
conv_layer_1.weight
13.953488372093023
x:  16
y:  3
layer1.0.conv_layer_1.weight
9.165942658557777
x:  16
y:  16
layer1.0.conv_layer_2.weight
9.643788010425716
x:  16
y:  16
layer1.1.conv_layer_1.weight
7.298001737619462
x:  16
y:  16
layer1.1.conv_layer_2.weight
7.037358818418766
x:  16
y:  16
layer1.2.conv_layer_1.weight
6.429192006950478
x:  16
y:  16
layer1.2.conv_layer_2.weight
6.125108601216334
x:  16
y:  16
layer2.0.conv_layer_1.weight
1.9539730785931393
x:  30
y:  16
layer2.0.conv_layer_2.weight
1.4651617104406338
x:  32
y:  31
layer2.1.conv_layer_1.weight
1.3566312133709573
x:  31
y:  32
layer2.1.conv_layer_2.weight
1.551986108096375
x:  32
y:  32
layer2.2.conv_layer_1.weight
1.7256349034078575
x:  32
y:  31
layer2.2.conv_layer_2.weight
1.5085739092685044
x:  32
y:  32
layer3.0.conv_layer_1.weight
0.4232230059685296
x:  38
y:  28
layer3.0.conv_layer_2.weight
0.21973848407574195
x:  39
y:  38
layer3.1.conv_layer_1.weight
0.4883077423905377
x:  50
y:  59
layer3.1.conv_layer_2.weight
0.37708208995713743
x:  48
y:  53
layer3.2.conv_layer_1.weight
0.06782051977646357
x:  18
y:  19
layer3.2.conv_layer_2.weight
0.04883077423905377
x:  18
y:  16
                         Layer 0      Layer 1  ...                       
                                 BasicBlock 0  ... BasicBlock 2          
                         conv. 0      conv. 0  ...      conv. 0   conv. 1
Original Model           [16, 3]     [16, 16]  ...     [64, 64]  [64, 64]
ReLU ResNet20            [16, 3]     [16, 16]  ...     [27, 32]    [8, 8]
univ. rational ResNet20  [15, 3]     [16, 16]  ...      [8, 13]  [11, 14]
mix. exp. ResNet20       [16, 3]     [16, 16]  ...     [18, 19]  [18, 16]

[4 rows x 19 columns]
                        Layer 0      Layer 1  ...                            
                                BasicBlock 0  ... Total weights Remained in %
                        conv. 0      conv. 0  ...                            
Original Model              430         2302  ...        267658    100.000000
ReLU ResNet20               117          292  ...          3041      1.136151
univ. rational ResNet20      71          182  ...          1535      0.573493
mix. exp. ResNet20           60          211  ...          2424      0.905633

[4 rows x 21 columns]
                           Layer 0      Layer 1  ...                       
                                   BasicBlock 0  ... BasicBlock 2          
                           conv. 0      conv. 0  ...      conv. 0   conv. 1
ReLU ResNet20            27.209302    12.684622  ...     0.116651  0.021703
univ. rational ResNet20  16.511628     7.906169  ...     0.043405  0.035267
mix. exp. ResNet20       13.953488     9.165943  ...     0.067821  0.048831

[3 rows x 19 columns]
time needed: 676m 12s
