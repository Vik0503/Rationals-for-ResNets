Using downloaded and verified file: ../data/SVHN/train_32x32.mat
Using downloaded and verified file: ../data/SVHN/test_32x32.mat
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a21550
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a21460
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a21be0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a380f0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a384b0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a21cd0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a21d70
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a38370
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a38280
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a38230
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a383c0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a46230
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a46280
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a46190
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a46820
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a461e0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a46140
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a460a0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a466e0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a46960
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a46aa0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e2398b820
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e2398b870
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e2398bd20
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e2399c370
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e2398b7d0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e2398b730
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e2398b6e0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e2398be60
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e2399c0f0
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e2399c280
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e2399ceb0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239a8690
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239a8230
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239a8550
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e2399cf50
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e29643dc0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239a8050
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239a87d0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239a86e0
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239a80a0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239af640
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239af5a0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239afc30
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239afaf0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239af5f0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23a1da00
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239af500
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239afe60
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239afd70
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239c2370
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239c2280
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239c2c80
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23ad5640
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23ad5690
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239c2cd0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239c2d70
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e239c2b90
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23ad5320
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f5e23ad5780
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
[10, 15, 20]
Milestone 0: 1
Epoch 0/24
**********
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 2.0748 Acc: 0.2571
val Loss: 1.5232 Acc: 0.4624
test Loss: 1.4557 Acc: 0.4739
tensor([[ 8,  1,  1,  0,  1,  0,  0,  1,  0,  0],
        [ 0, 16,  2,  1,  2,  0,  0,  2,  0,  1],
        [ 0,  0, 12,  4,  0,  1,  0,  0,  0,  0],
        [ 0,  0,  4,  9,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  6,  1,  3,  0,  0,  0,  0,  1],
        [ 0,  0,  3,  5,  0,  5,  0,  0,  0,  0],
        [ 0,  0,  1,  2,  0,  5,  2,  1,  0,  0],
        [ 1,  1,  0,  4,  0,  1,  0,  3,  0,  0],
        [ 0,  0,  0,  4,  0,  1,  1,  0,  0,  0],
        [ 0,  0,  5,  4,  1,  0,  0,  0,  0,  1]])
Epoch finished in 0m 30s
Epoch 1/24
**********
Milestone 0: 1
train Loss: 0.6842 Acc: 0.7829
val Loss: 0.4786 Acc: 0.8461
test Loss: 0.4353 Acc: 0.8635
tensor([[10,  0,  0,  0,  1,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  1,  1,  8,  1,  0,  0,  0,  2,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  1,  0,  0, 10,  2,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 1,  3,  0,  0,  0,  1,  0,  5,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  1,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  2,  8]])
Epoch finished in 0m 30s
Epoch 2/24
**********
Milestone 0: 1
train Loss: 0.4117 Acc: 0.8753
val Loss: 0.3998 Acc: 0.8775
test Loss: 0.4154 Acc: 0.8696
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 23,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 13,  0,  2,  1,  0,  0,  0,  1],
        [ 1,  1,  1,  8,  0,  0,  0,  0,  2,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 10,  0,  0,  1],
        [ 0,  0,  0,  1,  0,  1,  0,  8,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  1,  0,  4,  0],
        [ 0,  0,  0,  0,  0,  1,  0,  1,  0,  9]])
Epoch finished in 0m 30s
Epoch 3/24
**********
Milestone 0: 1
train Loss: 0.3458 Acc: 0.8954
val Loss: 0.3540 Acc: 0.8918
test Loss: 0.3585 Acc: 0.8904
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 23,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  1, 15,  0,  0,  0,  0,  0,  1,  0],
        [ 0,  2,  1,  8,  0,  0,  0,  0,  2,  0],
        [ 0,  0,  0,  0,  9,  0,  0,  0,  2,  0],
        [ 0,  0,  0,  0,  0, 11,  2,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  4,  0,  0,  0,  0,  0,  6,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  1,  1,  0,  0,  0,  1,  0,  0,  8]])
Epoch finished in 0m 30s
Epoch 4/24
**********
Milestone 0: 1
train Loss: 0.3144 Acc: 0.9061
val Loss: 0.3365 Acc: 0.9002
test Loss: 0.3013 Acc: 0.9083
tensor([[11,  1,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 17,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  3,  0,  9,  0,  0,  0,  0,  1,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  1,  0,  0, 12,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  1,  1,  0,  0,  0,  0,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  1,  0,  5,  0],
        [ 0,  1,  2,  0,  0,  0,  1,  0,  0,  7]])
Epoch finished in 0m 30s
Epoch 5/24
**********
Milestone 0: 1
train Loss: 0.2950 Acc: 0.9116
val Loss: 0.3138 Acc: 0.9068
test Loss: 0.3245 Acc: 0.8990
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 21,  0,  0,  0,  0,  0,  2,  0,  0],
        [ 0,  0, 16,  0,  0,  1,  0,  0,  0,  0],
        [ 0,  0,  0, 11,  2,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  1,  0,  0, 11,  1,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0, 10,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  1,  0,  4,  0],
        [ 0,  0,  1,  0,  0,  0,  1,  1,  0,  8]])
Epoch finished in 0m 30s
Epoch 6/24
**********
Milestone 0: 1
train Loss: 0.2768 Acc: 0.9177
val Loss: 0.3024 Acc: 0.9090
test Loss: 0.2731 Acc: 0.9190
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 17,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  1,  0, 12,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  1,  0,  4,  0],
        [ 0,  0,  2,  0,  0,  0,  0,  1,  0,  8]])
Epoch finished in 0m 30s
Epoch 7/24
**********
Milestone 0: 1
train Loss: 0.2642 Acc: 0.9207
val Loss: 0.2948 Acc: 0.9120
test Loss: 0.2484 Acc: 0.9249
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 23,  0,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  1,  0],
        [ 0,  0,  0, 11,  1,  0,  0,  0,  1,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  1,  0,  4,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 8/24
**********
Milestone 0: 1
train Loss: 0.2541 Acc: 0.9243
val Loss: 0.2724 Acc: 0.9218
test Loss: 0.2429 Acc: 0.9311
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  0,  0,  0,  0,  1,  0,  1],
        [ 0,  0, 16,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  2,  0, 10,  0,  0,  0,  1,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  0,  5,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 11]])
Epoch finished in 0m 30s
Epoch 9/24
**********
Milestone 0: 1
train Loss: 0.2447 Acc: 0.9265
val Loss: 0.2908 Acc: 0.9147
test Loss: 0.2624 Acc: 0.9216
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 15,  0,  0,  1,  0,  0,  1,  0],
        [ 0,  0,  0, 12,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  1,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 10/24
**********
Milestone 1: 0.1
train Loss: 0.1993 Acc: 0.9421
val Loss: 0.2213 Acc: 0.9366
test Loss: 0.1947 Acc: 0.9447
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 17,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  1,  0, 12,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 11/24
**********
Milestone 1: 0.1
train Loss: 0.1803 Acc: 0.9483
val Loss: 0.2238 Acc: 0.9374
test Loss: 0.1965 Acc: 0.9445
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  1,  0, 12,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 12/24
**********
Milestone 1: 0.1
train Loss: 0.1787 Acc: 0.9477
val Loss: 0.2216 Acc: 0.9393
test Loss: 0.1983 Acc: 0.9438
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 23,  0,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  0, 17,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  1,  0, 12,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 13/24
**********
Milestone 1: 0.1
train Loss: 0.1721 Acc: 0.9513
val Loss: 0.2172 Acc: 0.9391
test Loss: 0.1928 Acc: 0.9462
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 17,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  2,  0, 11,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 14/24
**********
Milestone 1: 0.1
train Loss: 0.1704 Acc: 0.9514
val Loss: 0.2207 Acc: 0.9368
test Loss: 0.1977 Acc: 0.9451
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 23,  0,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  1,  0, 12,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 15/24
**********
Milestone 2: 0.01
train Loss: 0.1639 Acc: 0.9522
val Loss: 0.2178 Acc: 0.9395
test Loss: 0.1970 Acc: 0.9456
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 23,  0,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  1,  0, 12,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 16/24
**********
Milestone 2: 0.01
train Loss: 0.1586 Acc: 0.9542
val Loss: 0.2196 Acc: 0.9383
test Loss: 0.1974 Acc: 0.9460
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  1,  0, 12,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 17/24
**********
Milestone 2: 0.01
train Loss: 0.1628 Acc: 0.9538
val Loss: 0.2160 Acc: 0.9398
test Loss: 0.1965 Acc: 0.9462
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 23,  0,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  1,  0, 12,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 18/24
**********
Milestone 2: 0.01
train Loss: 0.1586 Acc: 0.9548
val Loss: 0.2106 Acc: 0.9413
test Loss: 0.1972 Acc: 0.9453
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 17,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  2,  0, 11,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 19/24
**********
Milestone 2: 0.01
train Loss: 0.1591 Acc: 0.9546
val Loss: 0.2136 Acc: 0.9420
test Loss: 0.1976 Acc: 0.9456
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 23,  0,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  1,  0, 12,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 20/24
**********
Milestone 3: 0.001
train Loss: 0.1579 Acc: 0.9554
val Loss: 0.2161 Acc: 0.9398
test Loss: 0.1959 Acc: 0.9464
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 17,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  1,  0, 12,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 21/24
**********
Milestone 3: 0.001
train Loss: 0.1601 Acc: 0.9541
val Loss: 0.2213 Acc: 0.9398
test Loss: 0.1971 Acc: 0.9458
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 17,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  1,  0, 12,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 22/24
**********
Milestone 3: 0.001
train Loss: 0.1591 Acc: 0.9543
val Loss: 0.2179 Acc: 0.9394
test Loss: 0.1965 Acc: 0.9461
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  2,  0, 11,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 23/24
**********
Milestone 3: 0.001
train Loss: 0.1564 Acc: 0.9552
val Loss: 0.2167 Acc: 0.9406
test Loss: 0.1969 Acc: 0.9455
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  2,  0, 11,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Epoch 24/24
**********
Milestone 3: 0.001
train Loss: 0.1576 Acc: 0.9551
val Loss: 0.2179 Acc: 0.9397
test Loss: 0.1964 Acc: 0.9456
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  1,  0, 12,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 30s
Training complete in 12m 34s
Best test Acc: 0.946374
