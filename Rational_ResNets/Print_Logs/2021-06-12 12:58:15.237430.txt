Using downloaded and verified file: ../data/SVHN/train_32x32.mat
Using downloaded and verified file: ../data/SVHN/test_32x32.mat
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf29f320
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf29f370
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf29fb90
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2b5370
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2b5280
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf29fbe0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dcaf24460
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf29fcd0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2b5140
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2b54b0
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2b5050
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2b5f00
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2ba050
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2ba0a0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2ba6e0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2b5f50
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2ba550
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2ba5a0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2ba140
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf299910
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2bae10
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf206640
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf206460
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf206d20
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf206f50
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2065a0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf206500
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf206a50
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf206e60
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf206e10
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf215370
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf215280
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf215e10
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2240f0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2244b0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf215f50
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2153c0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf224370
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf224280
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf224230
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf2243c0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf22e410
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf22e460
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf22e370
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf22eaa0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf22e3c0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf22e320
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf22e280
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf22e960
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf22ed20
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf22ee60
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf23f140
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf23f8c0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1db1b2c2d0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1db1b2c1e0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf23f9b0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf23f960
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1dbf23fb90
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1db1b2c050
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7f1db1b2c410
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
Retrieving input from now on.
[10, 15, 20]
Milestone 0: 1
Epoch 0/24
**********
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
Training mode, no longer retrieving the input.
train Loss: 1.6347 Acc: 0.4242
val Loss: 1.0216 Acc: 0.6697
test Loss: 0.9457 Acc: 0.6891
tensor([[11,  0,  0,  0,  0,  1,  0,  0,  0,  0],
        [ 0, 22,  0,  0,  0,  0,  1,  1,  0,  0],
        [ 0,  1, 15,  0,  0,  0,  0,  1,  0,  0],
        [ 0,  1,  3,  3,  0,  2,  1,  1,  2,  0],
        [ 0,  4,  4,  0,  2,  0,  0,  0,  0,  1],
        [ 0,  0,  0,  0,  0, 11,  0,  0,  0,  2],
        [ 0,  0,  0,  0,  0,  0,  9,  0,  1,  1],
        [ 0,  1,  2,  0,  0,  0,  0,  7,  0,  0],
        [ 0,  0,  0,  0,  0,  2,  2,  0,  2,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  0,  1,  9]])
Epoch finished in 0m 35s
Epoch 1/24
**********
Milestone 0: 1
train Loss: 0.5246 Acc: 0.8368
val Loss: 0.5164 Acc: 0.8379
test Loss: 0.5157 Acc: 0.8384
tensor([[ 9,  0,  0,  0,  1,  1,  1,  0,  0,  0],
        [ 0, 23,  0,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0, 14,  0,  0,  3,  0,  0,  0,  0],
        [ 0,  0,  0, 10,  2,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 10,  1,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  2,  8,  0,  1,  0],
        [ 0,  0,  0,  0,  0,  1,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  1,  1,  0,  4,  0],
        [ 0,  1,  2,  0,  0,  2,  0,  0,  0,  6]])
Epoch finished in 0m 34s
Epoch 2/24
**********
Milestone 0: 1
train Loss: 0.3980 Acc: 0.8790
val Loss: 0.4707 Acc: 0.8563
test Loss: 0.4756 Acc: 0.8630
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 19,  1,  0,  0,  0,  1,  1,  0,  1],
        [ 0,  0, 14,  1,  0,  1,  0,  0,  1,  0],
        [ 2,  0,  0,  9,  0,  0,  0,  0,  2,  0],
        [ 0,  0,  0,  1,  9,  0,  0,  0,  1,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  2,  0,  0,  0,  7,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  1,  0,  0,  0,  0,  1,  0,  0,  9]])
Epoch finished in 0m 34s
Epoch 3/24
**********
Milestone 0: 1
train Loss: 0.3533 Acc: 0.8943
val Loss: 0.3890 Acc: 0.8843
test Loss: 0.3556 Acc: 0.8948
tensor([[ 9,  0,  0,  0,  1,  0,  1,  0,  0,  1],
        [ 0, 21,  0,  0,  1,  0,  0,  2,  0,  0],
        [ 0,  0, 15,  0,  0,  1,  0,  0,  0,  1],
        [ 0,  0,  1, 10,  2,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0, 10,  0,  0],
        [ 0,  0,  0,  0,  0,  1,  2,  0,  3,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  1,  0, 10]])
Epoch finished in 0m 35s
Epoch 4/24
**********
Milestone 0: 1
train Loss: 0.3275 Acc: 0.9033
val Loss: 0.4013 Acc: 0.8833
test Loss: 0.3779 Acc: 0.8856
tensor([[12,  0,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0, 22,  0,  0,  0,  0,  0,  2,  0,  0],
        [ 0,  0, 15,  1,  0,  0,  0,  0,  1,  0],
        [ 0,  2,  0, 10,  0,  0,  0,  0,  1,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 1,  1,  0,  0,  0,  0,  0,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  1,  1,  0,  4,  0],
        [ 0,  1,  1,  0,  0,  0,  0,  0,  0,  9]])
Epoch finished in 0m 35s
Epoch 5/24
**********
Milestone 0: 1
train Loss: 0.3174 Acc: 0.9048
val Loss: 0.3353 Acc: 0.9010
test Loss: 0.3373 Acc: 0.8996
tensor([[ 9,  0,  0,  0,  1,  0,  1,  0,  0,  1],
        [ 0, 23,  0,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0, 15,  0,  0,  1,  0,  0,  1,  0],
        [ 0,  1,  0,  9,  2,  0,  0,  0,  1,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 6/24
**********
Milestone 0: 1
train Loss: 0.3040 Acc: 0.9114
val Loss: 0.3289 Acc: 0.9038
test Loss: 0.3151 Acc: 0.9106
tensor([[10,  0,  0,  0,  1,  0,  1,  0,  0,  0],
        [ 0, 20,  0,  0,  2,  0,  0,  2,  0,  0],
        [ 0,  0, 15,  0,  0,  1,  0,  0,  0,  1],
        [ 0,  0,  0, 10,  1,  0,  1,  0,  1,  0],
        [ 0,  0,  0,  1, 10,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  1,  0,  0,  5,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 11]])
Epoch finished in 0m 35s
Epoch 7/24
**********
Milestone 0: 1
train Loss: 0.2936 Acc: 0.9135
val Loss: 0.4032 Acc: 0.8879
test Loss: 0.3395 Acc: 0.9048
tensor([[10,  0,  0,  0,  2,  0,  0,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 16,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 11,  2,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  1,  1,  0,  0,  0,  0,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  1,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 8/24
**********
Milestone 0: 1
train Loss: 0.2841 Acc: 0.9165
val Loss: 0.3231 Acc: 0.9061
test Loss: 0.2921 Acc: 0.9121
tensor([[10,  0,  0,  0,  0,  0,  1,  0,  0,  1],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  0,  0, 10,  1,  1,  0,  0,  1,  0],
        [ 0,  0,  0,  1, 10,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  0,  1],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  1,  0,  0,  0,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  1,  1,  0,  4,  0],
        [ 0,  1,  0,  1,  0,  0,  0,  0,  0,  9]])
Epoch finished in 0m 35s
Epoch 9/24
**********
Milestone 0: 1
train Loss: 0.2837 Acc: 0.9165
val Loss: 0.3025 Acc: 0.9094
test Loss: 0.2724 Acc: 0.9208
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 24,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  1, 15,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  2,  0,  8,  1,  0,  0,  0,  1,  1],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  1,  0, 10]])
Epoch finished in 0m 35s
Epoch 10/24
**********
Milestone 1: 0.1
train Loss: 0.2259 Acc: 0.9359
val Loss: 0.2485 Acc: 0.9284
test Loss: 0.2120 Acc: 0.9414
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 22,  0,  0,  0,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  1,  0, 11,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  1,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 11/24
**********
Milestone 1: 0.1
train Loss: 0.2097 Acc: 0.9402
val Loss: 0.2436 Acc: 0.9304
test Loss: 0.2163 Acc: 0.9388
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 23,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0, 11,  1,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 12/24
**********
Milestone 1: 0.1
train Loss: 0.2062 Acc: 0.9409
val Loss: 0.2386 Acc: 0.9311
test Loss: 0.2122 Acc: 0.9398
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 22,  0,  0,  0,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  1,  0, 11,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 13/24
**********
Milestone 1: 0.1
train Loss: 0.2023 Acc: 0.9423
val Loss: 0.2330 Acc: 0.9331
test Loss: 0.2092 Acc: 0.9397
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 22,  0,  0,  0,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  1,  0, 11,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  1,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 14/24
**********
Milestone 1: 0.1
train Loss: 0.1984 Acc: 0.9428
val Loss: 0.2345 Acc: 0.9320
test Loss: 0.2115 Acc: 0.9393
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 23,  0,  0,  0,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  1,  0, 11,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 15/24
**********
Milestone 2: 0.01
train Loss: 0.1922 Acc: 0.9444
val Loss: 0.2369 Acc: 0.9313
test Loss: 0.2099 Acc: 0.9405
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  1,  0, 11,  0,  0,  0,  0,  1,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 16/24
**********
Milestone 2: 0.01
train Loss: 0.1911 Acc: 0.9455
val Loss: 0.2367 Acc: 0.9331
test Loss: 0.2096 Acc: 0.9406
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  1,  0, 11,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 17/24
**********
Milestone 2: 0.01
train Loss: 0.1910 Acc: 0.9452
val Loss: 0.2348 Acc: 0.9335
test Loss: 0.2094 Acc: 0.9404
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  1,  0, 11,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 18/24
**********
Milestone 2: 0.01
train Loss: 0.1908 Acc: 0.9465
val Loss: 0.2377 Acc: 0.9330
test Loss: 0.2086 Acc: 0.9408
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  1,  0, 11,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 19/24
**********
Milestone 2: 0.01
train Loss: 0.1906 Acc: 0.9454
val Loss: 0.2336 Acc: 0.9332
test Loss: 0.2087 Acc: 0.9406
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  1,  0, 11,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 20/24
**********
Milestone 3: 0.001
train Loss: 0.1880 Acc: 0.9475
val Loss: 0.2317 Acc: 0.9336
test Loss: 0.2085 Acc: 0.9411
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  1,  0, 11,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 21/24
**********
Milestone 3: 0.001
train Loss: 0.1861 Acc: 0.9475
val Loss: 0.2328 Acc: 0.9340
test Loss: 0.2096 Acc: 0.9405
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0, 11,  1,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 22/24
**********
Milestone 3: 0.001
train Loss: 0.1884 Acc: 0.9461
val Loss: 0.2343 Acc: 0.9344
test Loss: 0.2094 Acc: 0.9405
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0, 11,  1,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 23/24
**********
Milestone 3: 0.001
train Loss: 0.1898 Acc: 0.9458
val Loss: 0.2347 Acc: 0.9325
test Loss: 0.2073 Acc: 0.9413
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  1,  0, 11,  0,  0,  1,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Epoch 24/24
**********
Milestone 3: 0.001
train Loss: 0.1874 Acc: 0.9459
val Loss: 0.2320 Acc: 0.9341
test Loss: 0.2076 Acc: 0.9415
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  1,  0, 11,  0,  0,  0,  0,  1,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 35s
Training complete in 14m 25s
Best test Acc: 0.941495
