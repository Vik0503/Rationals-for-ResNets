Using downloaded and verified file: ../data/SVHN/train_32x32.mat
Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): BasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): BasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0092c67d0
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff00c3cad20
    (shortcut): Sequential()
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0092d2f00
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0092dc410
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0092dc820
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0092dcc80
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0092e7190
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0092e75f0
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0092e7aa0
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0092f0190
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0092f0640
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0092f0eb0
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0092f0fa0
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff009303460
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff0093038c0
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff00930d190
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff00930d7d0
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (rational_2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
    cuda:0: 0x7ff00930ddc0
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7ff009318b40
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7ff009322910
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7ff009322960
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7ff009322c80
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa98d2d0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7ff0093228c0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7ff009322820
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7ff009322780
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7ff009322dc0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa98d050
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa98d1e0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9981e0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9980f0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa998140
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa998050
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa98dfa0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9980a0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9985f0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa998640
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa998870
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9989b0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9a4af0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9a4960
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9ac2d0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9ac1e0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9a4a50
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9a4a00
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9a49b0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9ac050
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9ac410
    )
    (conv_layer_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9ac190
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9b8460
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9b84b0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9b83c0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9b8aa0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9b8410
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9b8370
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9b82d0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9b8960
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9b8d20
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9b8e60
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa94d1e0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa94d230
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa94d140
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa94d870
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa94d190
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa94d0f0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa94d050
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa94d730
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa94d9b0
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa94de60
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa957be0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa957a50
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9630a0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa963460
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa957b90
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa957c30
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa963320
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa963230
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9631e0
    )
    (conv_layer_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Sequential(
  (0): RationalBasicBlock(
    (conv_layer_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa963370
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa96b8c0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa96b3c0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa96b870
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa96bd70
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa96b370
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa96b820
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa96b730
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa96be60
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa96bc30
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9783c0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa980370
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9803c0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9802d0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa980d20
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa980320
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa980280
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9801e0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa980be0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa980f50
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (2): RationalBasicBlock(
    (conv_layer_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (softmax): Softmax(dim=0)
    (rational_expert_group_1): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa980af0
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa90ddc0
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa90dc30
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa916320
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9166e0
    )
    (rational_expert_group_2): Sequential(
      (0): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa90dd70
      (1): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa90de10
      (2): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9165a0
      (3): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa9164b0
      (4): Rational Activation Function (PYTORCH version A) of degrees (5, 4) running on cuda
      cuda:0: 0x7feffa916460
    )
    (conv_layer_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
[10, 15, 20]
Milestone 0: 1
Epoch 0/9
**********
train Loss: 1.6366 Acc: 0.4345
val Loss: 0.7725 Acc: 0.7507
test Loss: 0.7333 Acc: 0.7616
tensor([[ 9,  0,  0,  1,  0,  0,  1,  1,  0,  0],
        [ 0, 21,  0,  0,  2,  0,  0,  1,  0,  0],
        [ 0,  0, 13,  2,  2,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 12,  0,  1,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  2,  1,  9,  0,  0,  0,  1],
        [ 0,  1,  0,  0,  0,  2,  7,  0,  0,  1],
        [ 0,  1,  1,  0,  0,  1,  0,  7,  0,  0],
        [ 0,  0,  0,  1,  0,  1,  0,  0,  2,  2],
        [ 0,  0,  0,  0,  0,  1,  0,  1,  0,  9]])
Epoch finished in 0m 10s
Epoch 1/9
**********
Milestone 0: 1
train Loss: 0.4518 Acc: 0.8623
val Loss: 0.3647 Acc: 0.8875
test Loss: 0.3929 Acc: 0.8744
tensor([[ 8,  0,  0,  0,  0,  0,  2,  0,  0,  2],
        [ 0, 20,  0,  0,  2,  0,  0,  2,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  0,  1,  9,  0,  1,  0,  0,  0,  2],
        [ 0,  0,  0,  0, 10,  0,  0,  0,  0,  1],
        [ 0,  0,  0,  1,  0, 11,  0,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  1,  0,  0,  0,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  5,  1],
        [ 0,  0,  0,  0,  1,  0,  0,  0,  0, 10]])
Epoch finished in 0m 10s
Epoch 2/9
**********
Milestone 0: 1
train Loss: 0.3033 Acc: 0.9092
val Loss: 0.2961 Acc: 0.9078
test Loss: 0.3023 Acc: 0.9085
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 21,  0,  1,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  1,  0],
        [ 0,  0,  0, 11,  1,  0,  0,  0,  1,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  2,  0, 10,  0,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  1,  1,  0,  0,  0,  0,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  1,  9]])
Epoch finished in 0m 10s
Epoch 3/9
**********
Milestone 0: 1
train Loss: 0.2517 Acc: 0.9252
val Loss: 0.2695 Acc: 0.9198
test Loss: 0.3042 Acc: 0.9036
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 21,  0,  0,  2,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 10,  1,  1,  0,  0,  0,  1],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  0,  0,  1,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  1,  0,  4,  0],
        [ 0,  1,  0,  1,  0,  0,  0,  0,  0,  9]])
Epoch finished in 0m 10s
Epoch 4/9
**********
Milestone 0: 1
train Loss: 0.2215 Acc: 0.9340
val Loss: 0.2202 Acc: 0.9346
test Loss: 0.2627 Acc: 0.9206
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 19,  0,  0,  2,  0,  0,  3,  0,  0],
        [ 0,  0, 16,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  9,  1,  1,  0,  0,  1,  1],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  1,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 10s
Epoch 5/9
**********
Milestone 0: 1
train Loss: 0.1973 Acc: 0.9428
val Loss: 0.2059 Acc: 0.9399
test Loss: 0.2500 Acc: 0.9248
tensor([[11,  0,  0,  0,  1,  0,  0,  0,  0,  0],
        [ 0, 20,  0,  0,  2,  0,  0,  2,  0,  0],
        [ 0,  0, 16,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  9,  2,  0,  0,  0,  1,  1],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 11s
Epoch 6/9
**********
Milestone 0: 1
train Loss: 0.1795 Acc: 0.9476
val Loss: 0.2647 Acc: 0.9195
test Loss: 0.3357 Acc: 0.8941
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 2, 17,  0,  0,  2,  0,  0,  3,  0,  0],
        [ 0,  0, 16,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  7,  2,  1,  1,  0,  1,  1],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 11,  2,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0, 10,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  5,  1],
        [ 1,  1,  0,  0,  0,  0,  0,  0,  0,  9]])
Epoch finished in 0m 11s
Epoch 7/9
**********
Milestone 0: 1
train Loss: 0.1642 Acc: 0.9516
val Loss: 0.2398 Acc: 0.9257
test Loss: 0.3081 Acc: 0.9055
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 21,  0,  0,  1,  0,  0,  2,  0,  0],
        [ 0,  0, 16,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 12,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  2,  9,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  2,  0, 10,  0,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  1,  0,  1,  0,  0,  0,  0,  0,  9]])
Epoch finished in 0m 11s
Epoch 8/9
**********
Milestone 0: 1
train Loss: 0.1465 Acc: 0.9573
val Loss: 0.2211 Acc: 0.9335
test Loss: 0.3123 Acc: 0.9085
tensor([[10,  0,  0,  0,  0,  0,  1,  0,  0,  1],
        [ 0, 20,  0,  0,  2,  1,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 10,  1,  0,  0,  0,  1,  1],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 11,  1,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  1,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 11s
Epoch 9/9
**********
Milestone 0: 1
train Loss: 0.1322 Acc: 0.9623
val Loss: 0.2327 Acc: 0.9305
test Loss: 0.3364 Acc: 0.9029
tensor([[11,  0,  0,  0,  0,  0,  0,  1,  0,  0],
        [ 1, 18,  0,  0,  2,  0,  1,  2,  0,  0],
        [ 0,  0, 16,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  1,  7,  2,  1,  0,  0,  1,  1],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 11,  1,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  1,  0,  5,  0],
        [ 0,  0,  0,  0,  1,  0,  0,  0,  0, 10]])
Epoch finished in 0m 10s
Training complete in 1m 44s
Best test Acc: 0.924785
[10, 15, 20]
Milestone 0: 1
Epoch 0/9
**********
train Loss: 1.4877 Acc: 0.4850
val Loss: 0.5289 Acc: 0.8385
test Loss: 0.5260 Acc: 0.8437
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 19,  0,  0,  1,  0,  0,  2,  1,  0],
        [ 1,  0, 15,  0,  0,  0,  0,  0,  1,  0],
        [ 0,  1,  0, 11,  0,  0,  0,  0,  1,  0],
        [ 0,  1,  0,  1,  9,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  2,  0,  9,  1,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  0,  9,  1,  0,  0],
        [ 0,  1,  1,  0,  0,  0,  0,  8,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  0,  0,  0,  0,  0,  1,  1,  0,  9]])
Epoch finished in 0m 14s
Epoch 1/9
**********
Milestone 0: 1
train Loss: 0.3531 Acc: 0.8934
val Loss: 0.2953 Acc: 0.9090
test Loss: 0.3283 Acc: 0.9005
tensor([[10,  0,  0,  0,  0,  0,  1,  0,  0,  1],
        [ 1, 19,  0,  0,  3,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  0,  0,  8,  2,  1,  0,  0,  1,  1],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  0,  1],
        [ 0,  0,  0,  0,  0,  0, 10,  0,  0,  1],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  4,  1],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 11]])
Epoch finished in 0m 14s
Epoch 2/9
**********
Milestone 0: 1
train Loss: 0.2562 Acc: 0.9248
val Loss: 0.2811 Acc: 0.9148
test Loss: 0.3272 Acc: 0.8994
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 21,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 1,  0, 16,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  1,  0, 11,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  1,  1,  0,  0,  0,  0,  8]])
Epoch finished in 0m 14s
Epoch 3/9
**********
Milestone 0: 1
train Loss: 0.2109 Acc: 0.9383
val Loss: 0.2336 Acc: 0.9329
test Loss: 0.2900 Acc: 0.9161
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 20,  0,  0,  1,  0,  1,  1,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  1,  0],
        [ 0,  0,  0, 11,  2,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  2,  0, 10,  0,  0,  1,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  1,  2,  8]])
Epoch finished in 0m 14s
Epoch 4/9
**********
Milestone 0: 1
train Loss: 0.1790 Acc: 0.9482
val Loss: 0.1795 Acc: 0.9518
test Loss: 0.2632 Acc: 0.9289
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 21,  0,  0,  2,  0,  0,  1,  0,  0],
        [ 1,  0, 16,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 11,  2,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  1,  0,  0,  1,  0,  0,  0,  0,  9]])
Epoch finished in 0m 14s
Epoch 5/9
**********
Milestone 0: 1
train Loss: 0.1511 Acc: 0.9547
val Loss: 0.1583 Acc: 0.9547
test Loss: 0.2485 Acc: 0.9304
tensor([[12,  0,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 1, 21,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 1,  0, 16,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 11,  2,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  2,  0,  0,  0,  0,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 1,  0,  0,  0,  0,  0,  0,  1,  0,  9]])
Epoch finished in 0m 14s
Epoch 6/9
**********
Milestone 0: 1
train Loss: 0.1259 Acc: 0.9628
val Loss: 0.1923 Acc: 0.9429
test Loss: 0.3221 Acc: 0.9074
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 21,  0,  0,  2,  0,  0,  0,  1,  0],
        [ 1,  0, 15,  0,  0,  0,  0,  0,  1,  0],
        [ 0,  2,  0,  8,  1,  1,  0,  0,  1,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 11,  1,  0,  1,  0],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  1,  1,  0,  0,  0,  0,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 1,  1,  0,  0,  0,  0,  0,  0,  0,  9]])
Epoch finished in 0m 14s
Epoch 7/9
**********
Milestone 0: 1
train Loss: 0.1076 Acc: 0.9665
val Loss: 0.1614 Acc: 0.9563
test Loss: 0.2735 Acc: 0.9211
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 20,  1,  0,  1,  0,  0,  1,  0,  1],
        [ 1,  0, 16,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  1,  0, 10,  1,  1,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  0,  1],
        [ 0,  0,  0,  0,  0,  0, 11,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  4,  2],
        [ 0,  0,  0,  0,  0,  0,  0,  1,  0, 10]])
Epoch finished in 0m 14s
Epoch 8/9
**********
Milestone 0: 1
train Loss: 0.0933 Acc: 0.9701
val Loss: 0.1390 Acc: 0.9642
test Loss: 0.3250 Acc: 0.9251
tensor([[10,  0,  0,  0,  0,  0,  1,  0,  0,  1],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 1,  0, 15,  0,  0,  0,  0,  0,  1,  0],
        [ 0,  0,  0, 10,  2,  1,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  5,  1],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 14s
Epoch 9/9
**********
Milestone 0: 1
train Loss: 0.0763 Acc: 0.9759
val Loss: 0.1703 Acc: 0.9568
test Loss: 0.3811 Acc: 0.9146
tensor([[10,  0,  0,  0,  0,  0,  1,  0,  0,  1],
        [ 0, 20,  1,  0,  2,  0,  0,  1,  0,  0],
        [ 0,  0, 17,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 10,  2,  1,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 10,  0,  0,  1],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  1,  0,  0,  0,  0,  5,  0],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 14s
Training complete in 2m 17s
Best test Acc: 0.930393
[10, 15, 20]
Milestone 0: 1
Epoch 0/9
**********
train Loss: 2.2253 Acc: 0.1961
val Loss: 2.1850 Acc: 0.2368
test Loss: 2.1764 Acc: 0.2480
tensor([[ 1,  2,  8,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 10, 12,  0,  0,  0,  1,  0,  0,  0],
        [ 1,  2, 13,  0,  0,  1,  0,  0,  0,  0],
        [ 1,  1, 11,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  2,  9,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  1, 10,  1,  0,  1,  0,  0,  0,  0],
        [ 0,  1,  7,  0,  0,  3,  0,  0,  0,  0],
        [ 0,  2,  7,  0,  0,  0,  1,  0,  0,  0],
        [ 0,  1,  4,  0,  0,  1,  0,  0,  0,  0],
        [ 0,  1,  7,  0,  0,  2,  1,  0,  0,  0]])
Epoch finished in 0m 44s
Epoch 1/9
**********
Milestone 0: 1
train Loss: 1.0082 Acc: 0.6673
val Loss: 0.4027 Acc: 0.8789
test Loss: 0.4525 Acc: 0.8595
tensor([[12,  0,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 1, 18,  0,  1,  2,  0,  0,  2,  0,  0],
        [ 1,  0, 15,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 12,  0,  1,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 10,  0,  0,  0,  0,  1],
        [ 0,  0,  0,  1,  0, 11,  0,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  1,  9,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  2,  0,  1,  0,  0,  2,  1],
        [ 0,  0,  0,  0,  0,  0,  0,  1,  0, 10]])
Epoch finished in 0m 45s
Epoch 2/9
**********
Milestone 0: 1
train Loss: 0.3286 Acc: 0.9011
val Loss: 0.2975 Acc: 0.9143
test Loss: 0.3281 Acc: 0.9025
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 19,  0,  1,  1,  0,  0,  2,  0,  0],
        [ 1,  0, 16,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  1,  9,  0,  1,  0,  0,  1,  1],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  0,  1],
        [ 0,  0,  0,  0,  0,  0, 10,  0,  0,  1],
        [ 0,  0,  1,  0,  0,  0,  1,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 1,  0,  0,  0,  0,  1,  0,  0,  0,  9]])
Epoch finished in 0m 44s
Epoch 3/9
**********
Milestone 0: 1
train Loss: 0.2487 Acc: 0.9267
val Loss: 0.2440 Acc: 0.9385
test Loss: 0.2850 Acc: 0.9259
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 1, 21,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  1,  0, 10,  0,  0,  0,  1,  1,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 11]])
Epoch finished in 0m 43s
Epoch 4/9
**********
Milestone 0: 1
train Loss: 0.2015 Acc: 0.9420
val Loss: 0.1770 Acc: 0.9509
test Loss: 0.2502 Acc: 0.9312
tensor([[10,  0,  0,  0,  1,  0,  1,  0,  0,  0],
        [ 0, 21,  0,  1,  2,  0,  0,  0,  0,  0],
        [ 1,  0, 16,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 12,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  1,  0,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 1,  1,  0,  0,  0,  0,  0,  0,  0,  9]])
Epoch finished in 0m 43s
Epoch 5/9
**********
Milestone 0: 1
train Loss: 0.1662 Acc: 0.9517
val Loss: 0.1873 Acc: 0.9449
test Loss: 0.2776 Acc: 0.9208
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  0,  1,  0,  0,  1,  0,  0],
        [ 0,  0, 16,  0,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 12,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  1,  0],
        [ 0,  0,  0,  0,  0,  0, 10,  0,  1,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  0,  0,  0,  1,  0,  0,  0,  1,  9]])
Epoch finished in 0m 43s
Epoch 6/9
**********
Milestone 0: 1
train Loss: 0.1408 Acc: 0.9571
val Loss: 0.1640 Acc: 0.9540
test Loss: 0.3038 Acc: 0.9191
tensor([[11,  0,  0,  0,  1,  0,  0,  0,  0,  0],
        [ 1, 23,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 1,  0, 16,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  1,  0, 11,  1,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  1,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  0,  0,  9,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 11]])
Epoch finished in 0m 43s
Epoch 7/9
**********
Milestone 0: 1
train Loss: 0.1161 Acc: 0.9644
val Loss: 0.1499 Acc: 0.9573
test Loss: 0.3193 Acc: 0.9115
tensor([[11,  0,  0,  0,  1,  0,  0,  0,  0,  0],
        [ 1, 21,  0,  0,  2,  0,  0,  0,  0,  0],
        [ 0,  0, 16,  0,  0,  0,  0,  0,  0,  1],
        [ 0,  0,  0, 11,  1,  1,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  0,  1],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  1,  0,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  5,  1],
        [ 0,  1,  0,  0,  0,  0,  0,  0,  0, 10]])
Epoch finished in 0m 43s
Epoch 8/9
**********
Milestone 0: 1
train Loss: 0.0964 Acc: 0.9692
val Loss: 0.1407 Acc: 0.9624
test Loss: 0.3149 Acc: 0.9189
tensor([[10,  0,  0,  0,  0,  0,  2,  0,  0,  0],
        [ 0, 23,  0,  1,  0,  0,  0,  0,  0,  0],
        [ 0,  0, 17,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 10,  1,  1,  0,  0,  1,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 13,  0,  0,  0,  0],
        [ 0,  0,  0,  1,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  0,  0,  1,  1,  0,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  0,  0,  0,  0,  0,  1,  0,  0, 10]])
Epoch finished in 0m 43s
Epoch 9/9
**********
Milestone 0: 1
train Loss: 0.0818 Acc: 0.9730
val Loss: 0.1368 Acc: 0.9676
test Loss: 0.3324 Acc: 0.9239
tensor([[11,  0,  0,  0,  0,  0,  1,  0,  0,  0],
        [ 0, 22,  0,  1,  1,  0,  0,  0,  0,  0],
        [ 0,  0, 17,  0,  0,  0,  0,  0,  0,  0],
        [ 0,  0,  0, 11,  1,  1,  0,  0,  0,  0],
        [ 0,  0,  0,  0, 11,  0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0, 12,  0,  0,  1,  0],
        [ 1,  0,  0,  0,  0,  0, 10,  0,  0,  0],
        [ 0,  0,  1,  0,  0,  1,  0,  8,  0,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0],
        [ 0,  0,  0,  0,  1,  0,  0,  0,  0, 10]])
Epoch finished in 0m 45s
Training complete in 7m 14s
Best test Acc: 0.931238
