{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import time\n",
    "from typing import Type, Any, Callable, List, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from rational.torch import Rational\n",
    "# from rtpt import RTPT\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import Tensor, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RationalBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self,\n",
    "                 planes_in,\n",
    "                 planes_out,\n",
    "                 stride: int = 1,\n",
    "                 downsample: Optional[nn.Module] = None,\n",
    "                 groups: int = 1,\n",
    "                 base_width: int = 64,\n",
    "                 dilation: int = 1,\n",
    "                 norm_layer: Optional[Callable[..., nn.Module]] = None):\n",
    "        super(RationalBasicBlock, self).__init__()\n",
    "        self.downsample = downsample\n",
    "\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.conv_layer_1 = conv3x3(planes_in, planes_out, stride)\n",
    "        self.batch_norm_1 = norm_layer(planes_out)\n",
    "        if torch.cuda.is_available():  # use Rationals instead of reLu activation function\n",
    "            self.rational = Rational().cuda()\n",
    "        else:\n",
    "            self.rational = Rational()\n",
    "        self.conv_layer_2 = conv3x3(planes_out, planes_out)\n",
    "        self.batch_norm_2 = norm_layer(planes_out)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args: identity: Tensor\n",
    "        \"\"\"\n",
    "        identity = x\n",
    "        out = self.conv_layer_1(x)\n",
    "        out = self.batch_norm_1(out)\n",
    "        out = self.rational(out)\n",
    "        out = self.conv_layer_2(out)\n",
    "        out = self.batch_norm_2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.rational(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class RationalResNetLayer(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block: Type[RationalBasicBlock],\n",
    "                 num_blocks: int,\n",
    "                 planes_out: int,\n",
    "                 planes_in: int = 64,\n",
    "                 norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "                 stride: int = 1,\n",
    "                 dilate: bool = False,\n",
    "                 groups: int = 1,\n",
    "                 width_per_group: int = 64) -> None:\n",
    "        super(RationalResNetLayer, self).__init__()\n",
    "        self.block = block\n",
    "        self.num_blocks = num_blocks\n",
    "        self.stride = stride\n",
    "        self.dilate = dilate\n",
    "        self.norm_layer = norm_layer\n",
    "        self.planes_in = planes_in * block.expansion\n",
    "        self.planes_out = planes_out\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.dilation = 1\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilate\n",
    "        if dilate:\n",
    "            self.dilate *= stride\n",
    "            stride = 1\n",
    "\n",
    "        if stride != 1 or self.planes_in != planes_out * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.planes_in, planes_out * block.expansion, stride),\n",
    "                norm_layer(planes_out * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(planes_in=self.planes_in, planes_out=self.planes_out, stride=stride,\n",
    "                            downsample=downsample, groups=self.groups, base_width=self.base_width,\n",
    "                            dilation=previous_dilation))\n",
    "\n",
    "        self.planes_in = planes_out * block.expansion\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(block(planes_in=self.planes_in, planes_out=self.planes_out, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer, groups=self.groups, base_width=self.base_width))\n",
    "\n",
    "        self.layers_2 = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, out):\n",
    "        out = self.layers_2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RationalResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block: Type[RationalBasicBlock],\n",
    "                 layers: List[int],\n",
    "                 num_classes: int = 1000,\n",
    "                 zero_init_residual: bool = False,\n",
    "                 replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "                 norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "                 ) -> None:\n",
    "        super(RationalResNet, self).__init__()\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self._norm_layer = norm_layer\n",
    "        if replace_stride_with_dilation is None:\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        self.planes_in = 64\n",
    "\n",
    "        self.conv_layer_1 = nn.Conv2d(3, self.planes_in, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm_1 = norm_layer(self.planes_in)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.rational = Rational().cuda()\n",
    "        else:\n",
    "            self.rational = Rational().cpu()\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = RationalResNetLayer(block=block, planes_in=self.planes_in,\n",
    "                                          planes_out=64, num_blocks=layers[0], norm_layer=self._norm_layer)\n",
    "        self.layer2 = RationalResNetLayer(block=block, planes_in=self.planes_in * block.expansion,\n",
    "                                          planes_out=128, num_blocks=layers[1],\n",
    "                                          norm_layer=self._norm_layer,\n",
    "                                          stride=2, dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = RationalResNetLayer(block=block, planes_in=self.planes_in * (block.expansion * 2),\n",
    "                                          planes_out=256, num_blocks=layers[2],\n",
    "                                          norm_layer=self._norm_layer,\n",
    "                                          stride=2, dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = RationalResNetLayer(block=block, planes_in=self.planes_in * (block.expansion * 4),\n",
    "                                          planes_out=512, num_blocks=layers[3],\n",
    "                                          norm_layer=self._norm_layer,\n",
    "                                          stride=2, dilate=replace_stride_with_dilation[2])\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        # <- The following source code lines come from: https://pytorch.org/hub/pytorch_vision_resnet/,\n",
    "        # https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "                # Zero-initialize the last BN in each residual branch,\n",
    "                # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "                # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "            if zero_init_residual:\n",
    "                for m in self.modules():\n",
    "                    if isinstance(m, RationalBasicBlock):\n",
    "                        nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "        # -> The end of the block\n",
    "\n",
    "    def forward(self, out: Tensor):\n",
    "        out = self.conv_layer_1(out)\n",
    "        out = self.batch_norm_1(out)\n",
    "        out = self.rational(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _resnet(\n",
    "        arch: str,\n",
    "        block: Type[RationalBasicBlock],\n",
    "        layers: List[int],\n",
    "\n",
    "        **kwargs: Any\n",
    ") -> RationalResNet:\n",
    "    model = RationalResNet(block, layers, **kwargs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rational_resnet18(**kwargs: Any) -> RationalResNet:\n",
    "    \"\"\"ResNet-18 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
    "    \"\"\"\n",
    "    return _resnet('resnet18', RationalBasicBlock, [2, 2, 2, 2], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# rtpt = RTPT(name_initials='VS', experiment_name='DebuggingRationalResNet', max_iterations=25, iteration_start=0,\n",
    "            # update_interval=1)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.SVHN(root='./data', split='train', download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=16, drop_last=True)\n",
    "test_data_set = torchvision.datasets.SVHN(root='./data', split='test', download=True, transform=transform)\n",
    "testset, valset = torch.utils.data.random_split(test_data_set, [13016, 13016])\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=16, drop_last=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=True, num_workers=16, drop_last=True)\n",
    "\n",
    "classes = trainset.labels\n",
    "class_names_str = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "class_names = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "writer = SummaryWriter('runs/rational_resnet18_SVHN_run21')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_val_test_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    avg_epoch_time = []\n",
    "    best_acc = 0.0\n",
    "    all_train_preds = []\n",
    "    all_train_labels = []\n",
    "    all_test_labels = []\n",
    "    all_test_preds = []\n",
    "    accuracy_plot_x_vals = []\n",
    "    train_acc_plot_y_vals = []\n",
    "    val_acc_plot_y_vals = []\n",
    "    test_acc_plot_y_vals = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('*' * 10)\n",
    "        since_epoch = time.time()\n",
    "\n",
    "        # Each epoch has a training, a validation and a test phase\n",
    "        for phase in ['train', 'val', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluation mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            if phase == 'train':\n",
    "                dataloader = trainloader\n",
    "            if phase == 'val':\n",
    "                dataloader = valloader\n",
    "            if phase == 'test':\n",
    "                dataloader = testloader\n",
    "            # Iterate over data.\n",
    "            for i, data in enumerate(dataloader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        loss = loss.to(device)\n",
    "                        optimizer.step()\n",
    "                        all_train_preds.append(preds.cpu().numpy())\n",
    "                        all_train_labels.append(labels.cpu().numpy())\n",
    "\n",
    "                if phase == 'test':\n",
    "                    all_test_preds.append(preds.cpu().numpy())\n",
    "                    all_test_labels.append(labels.cpu().numpy())\n",
    "\n",
    "                # loss + accuracy\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                epoch_loss = running_loss / len(trainset)\n",
    "                writer.add_scalar('training loss', epoch_loss, epoch)\n",
    "                epoch_acc = running_corrects.double() / len(trainset)\n",
    "                writer.add_scalar('training accuracy', epoch_acc, epoch)\n",
    "                train_acc_plot_y_vals.append(epoch_acc.cpu() * 100)\n",
    "                scheduler.step()\n",
    "\n",
    "            if phase == 'val':\n",
    "                epoch_loss = running_loss / len(valset)\n",
    "                writer.add_scalar('validation loss', epoch_loss, epoch)\n",
    "                epoch_acc = running_corrects.double() / len(valset)\n",
    "                val_acc_plot_y_vals.append(epoch_acc.cpu() * 100)\n",
    "                writer.add_scalar('validation accuracy', epoch_acc, epoch)\n",
    "\n",
    "            if phase == 'test':\n",
    "                epoch_loss = running_loss / len(testset)\n",
    "                writer.add_scalar('test loss', epoch_loss, epoch)\n",
    "                epoch_acc = running_corrects.double() / len(testset)\n",
    "                test_acc_plot_y_vals.append(epoch_acc.cpu() * 100)\n",
    "                writer.add_scalar('test accuracy', epoch_acc, epoch)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "\n",
    "        accuracy_plot_x_vals.append(epoch)\n",
    "\n",
    "        cm = torch.tensor(confusion_matrix(labels.to('cpu'), preds.to('cpu')))\n",
    "        print('confusion matrix: ', cm)\n",
    "\n",
    "        time_elapsed_epoch = time.time() - since_epoch\n",
    "        avg_epoch_time.append(time_elapsed_epoch)\n",
    "        print('Epoch finished in {:.0f}m {:.0f}s'.format(time_elapsed_epoch // 60, time_elapsed_epoch % 60))\n",
    "        # rtpt._last_iteration_time_start = time_elapsed_epoch * (num_epochs - epoch)\n",
    "        # rtpt.step()\n",
    "\n",
    "    summary_plot(accuracy_plot_x_vals, train_acc_plot_y_vals, val_acc_plot_y_vals, test_acc_plot_y_vals)\n",
    "    train_labels_array = confusion_prepare(all_train_labels)\n",
    "    train_preds_array = confusion_prepare(all_train_preds)\n",
    "    cm_train = confusion_matrix(train_labels_array, train_preds_array, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    print('cm_train: ', cm_train)\n",
    "    # plot_confusion_matrix(cm_train, num_epochs, time_elapsed_epoch, 'train_1.svg')\n",
    "\n",
    "    test_labels_array = confusion_prepare(all_test_labels)\n",
    "    test_preds_array = confusion_prepare(all_test_preds)\n",
    "    cm_test = confusion_matrix(test_labels_array, test_preds_array, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    print('cm_test: ', cm_test)\n",
    "    time_elapsed_epoch = average_epoch_time(avg_epoch_time)\n",
    "    plot_confusion_matrix(cm_test, num_epochs, time_elapsed_epoch, 'test_1.svg', best_acc)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best test Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def average_epoch_time(avg_epoch_time):  # calculates average time per epoch\n",
    "    avg_epoch_int = 0.0\n",
    "    for i in range(len(avg_epoch_time)):\n",
    "        avg_epoch_int += avg_epoch_time[i]\n",
    "    return avg_epoch_int / len(avg_epoch_time)\n",
    "\n",
    "\n",
    "def confusion_prepare(pl):  # converts pred + acc arrays of arrays with tensors to array\n",
    "    pl_array = []\n",
    "    for i in range(len(pl)):\n",
    "        k = pl[i]\n",
    "        for j in range(len(k)):\n",
    "            pl_array.append(k[j])\n",
    "    return pl_array\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, num_epochs, epoch_time, title, test_acc):  # plots confusion matrix as heatmap\n",
    "    plt.subplot(132)\n",
    "    cm_1 = sns.heatmap(cm, linewidths=1, cmap='plasma')\n",
    "    props = dict(boxstyle='round', facecolor='grey', alpha=0.5)\n",
    "    text = 'num epochs: {}, '.format(num_epochs) + 'num params: {}, '.format(num_param) + \\\n",
    "           'batch size: 128, ' + 'lr: 0.01, ' + '\\n' + \\\n",
    "           'avg time per epoch: {:.0f}m {:.0f}s, '.format(epoch_time // 60, epoch_time % 60) + \\\n",
    "           'test accuracy: {:4f}, '.format(test_acc) + 'dataset: SVHN'\n",
    "    plt.text(15, 5, text, bbox=props)\n",
    "    cm_1.figure.savefig(title)\n",
    "\n",
    "\n",
    "def summary_plot(acc_x_vals, train_acc_y_vals, val_acc_y_vals, test_acc_y_vals):  # train and val accuracy plot\n",
    "    plt.figure(figsize=(40, 10))\n",
    "    plt.subplot(131)\n",
    "    plt.plot(acc_x_vals, train_acc_y_vals)\n",
    "    plt.plot(acc_x_vals, val_acc_y_vals)\n",
    "    plt.plot(acc_x_vals, test_acc_y_vals)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train Accuracy', 'Validation Accuracy', 'Test Accuracy'])\n",
    "\n",
    "    plt.savefig('test_plot.svg')\n",
    "\n",
    "\n",
    "def final_plot():\n",
    "    plt.savefig('summary_plot_rational_resnet_SVHN.svg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/viktoria/Git/thesis_stuff/LTH_for_Rational_ResNets/LTH_Models/Saved_Models/rational_resnet20_no_aug.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-19-f84b8088a5d9>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0mrational_8\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m \u001B[0mlayer_plot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-19-f84b8088a5d9>\u001B[0m in \u001B[0;36mlayer_plot\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mlayer_plot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# plots Rational Activation functions in all layers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mmodel_tr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'/home/viktoria/Git/thesis_stuff/LTH_for_Rational_ResNets/LTH_Models/Saved_Models/rational_resnet20_no_aug.pth'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0mrational_0\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_tr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrational\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mrational_1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_tr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrational\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Thesis Environment 2/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    579\u001B[0m         \u001B[0mpickle_load_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'encoding'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    580\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 581\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    582\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_is_zipfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    583\u001B[0m             \u001B[0;31m# The zipfile reader is going to advance the current file position.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Thesis Environment 2/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'w'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Thesis Environment 2/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/viktoria/Git/thesis_stuff/LTH_for_Rational_ResNets/LTH_Models/Saved_Models/rational_resnet20_no_aug.pth'"
     ]
    }
   ],
   "source": [
    "def layer_plot():  # plots Rational Activation functions in all layers\n",
    "    model_tr = torch.load('/home/viktoria/Git/thesis_stuff/LTH_for_Rational_ResNets/LTH_Models/Saved_Models/rational_resnet20_no_aug.pth')\n",
    "    rational_0 = model_tr.rational\n",
    "\n",
    "    rational_1 = model_tr.layer1.__getitem__(0).rational\n",
    "    rational_2 = model_tr.layer1.__getitem__(1).rational\n",
    "    rational_3 = model_tr.layer2.__getitem__(0).rational\n",
    "    rational_4 = model_tr.layer2.__getitem__(1).rational\n",
    "    rational_5 = model_tr.layer3.__getitem__(0).rational\n",
    "    rational_6 = model_tr.layer3.__getitem__(1).rational\n",
    "    rational_7 = model_tr.layer4.__getitem__(0).rational\n",
    "    rational_8 = model_tr.layer4.__getitem__(1).rational\n",
    "    rational_0.show()\n",
    "    rational_1.show()\n",
    "    rational_2.show()\n",
    "    rational_3.show()\n",
    "    rational_4.show()\n",
    "    rational_5.show()\n",
    "    rational_6.show()\n",
    "    rational_7.show()\n",
    "    rational_8.show()\n",
    "\n",
    "layer_plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/viktoria/Git/thesis_stuff/LTH_for_Rational_ResNets/LTH_Models/Saved_Models/rational_resnet20_no_aug.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-16-0ce743538810>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mlayer_plot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-15-77c0eb2271f8>\u001B[0m in \u001B[0;36mlayer_plot\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mlayer_plot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# plots Rational Activation functions in all layers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mmodel_tr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'/home/viktoria/Git/thesis_stuff/LTH_for_Rational_ResNets/LTH_Models/Saved_Models/rational_resnet20_no_aug.pth'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0mrational_0\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_tr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrational\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mrational_1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_tr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrational\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Thesis Environment 2/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    579\u001B[0m         \u001B[0mpickle_load_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'encoding'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    580\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 581\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    582\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_is_zipfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    583\u001B[0m             \u001B[0;31m# The zipfile reader is going to advance the current file position.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Thesis Environment 2/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'w'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Thesis Environment 2/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/viktoria/Git/thesis_stuff/LTH_for_Rational_ResNets/LTH_Models/Saved_Models/rational_resnet20_no_aug.pth'"
     ]
    }
   ],
   "source": [
    "layer_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RRN18_model = rational_resnet18()\n",
    "num_ftrs = RRN18_model.fc.in_features\n",
    "# Here the size of each output sample is set to nn.Linear(num_ftrs, len(class_names)).\n",
    "class_names = trainset.labels\n",
    "RRN18_model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "RRN18_model = RRN18_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(RRN18_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "num_param = RRN18_model.parameters().__sizeof__()\n",
    "\n",
    "RRN18_model = train_val_test_model(RRN18_model, criterion, optimizer, exp_lr_scheduler,\n",
    "                                   num_epochs=25)\n",
    "\n",
    "final_plot()\n",
    "\n",
    "torch.save(RRN18_model, './model9.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/viktoria/Git/thesis_stuff/Rational_ResNets/Saved_Models/rational_resnet20_no_aug_2.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-435ed2966dd7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     77\u001B[0m     \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 79\u001B[0;31m \u001B[0mlayer_plot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-17-435ed2966dd7>\u001B[0m in \u001B[0;36mlayer_plot\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mlayer_plot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# plots Rational Activation functions in all layers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mplot\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m     \u001B[0mmodel_tr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'/home/viktoria/Git/thesis_stuff/Rational_ResNets/Saved_Models/rational_resnet20_no_aug_2.pth'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m     \u001B[0;31m# Layer 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mrational_0_0\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_tr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mr_rational\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Thesis Environment 2/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    579\u001B[0m         \u001B[0mpickle_load_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'encoding'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    580\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 581\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    582\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_is_zipfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    583\u001B[0m             \u001B[0;31m# The zipfile reader is going to advance the current file position.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Thesis Environment 2/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'w'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Thesis Environment 2/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/viktoria/Git/thesis_stuff/Rational_ResNets/Saved_Models/rational_resnet20_no_aug_2.pth'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from rational.torch import Rational\n",
    "\n",
    "\n",
    "def layer_plot():  # plots Rational Activation functions in all layers\n",
    "    plot: plt\n",
    "    model_tr = torch.load('/home/viktoria/Git/thesis_stuff/Rational_ResNets/Saved_Models/rational_resnet20_no_aug_2.pth')\n",
    "    # Layer 0\n",
    "    rational_0_0 = model_tr.r_rational\n",
    "    rational_0_1 = model_tr.g_rational\n",
    "    rational_0_2 = model_tr.b_rational\n",
    "    rational_0_3 = model_tr.c_rational\n",
    "\n",
    "    # Layer 1\n",
    "    rational_1_0 = model_tr.layer1.__getitem__(0).r_rational\n",
    "    rational_1_1 = model_tr.layer1.__getitem__(0).g_rational\n",
    "    rational_1_2 = model_tr.layer1.__getitem__(0).b_rational\n",
    "    rational_1_3 = model_tr.layer1.__getitem__(0).c_rational\n",
    "\n",
    "    rational_2_0 = model_tr.layer1.__getitem__(1).r_rational\n",
    "    rational_2_1 = model_tr.layer1.__getitem__(1).g_rational\n",
    "    rational_2_2 = model_tr.layer1.__getitem__(1).b_rational\n",
    "    rational_2_3 = model_tr.layer1.__getitem__(1).c_rational\n",
    "\n",
    "    rational_3_0 = model_tr.layer1.__getitem__(2).r_rational\n",
    "    rational_3_1 = model_tr.layer1.__getitem__(2).g_rational\n",
    "    rational_3_2 = model_tr.layer1.__getitem__(2).b_rational\n",
    "    rational_3_3 = model_tr.layer1.__getitem__(2).c_rational\n",
    "\n",
    "    # Layer 2\n",
    "    rational_4_0 = model_tr.layer2.__getitem__(0).r_rational\n",
    "    rational_4_1 = model_tr.layer2.__getitem__(0).g_rational\n",
    "    rational_4_2 = model_tr.layer2.__getitem__(0).b_rational\n",
    "    rational_4_3 = model_tr.layer2.__getitem__(0).c_rational\n",
    "\n",
    "    rational_5_0 = model_tr.layer2.__getitem__(1).r_rational\n",
    "    rational_5_1 = model_tr.layer2.__getitem__(1).g_rational\n",
    "    rational_5_2 = model_tr.layer2.__getitem__(1).b_rational\n",
    "    rational_5_3 = model_tr.layer2.__getitem__(1).c_rational\n",
    "\n",
    "    rational_6_0 = model_tr.layer2.__getitem__(2).r_rational\n",
    "    rational_6_1 = model_tr.layer2.__getitem__(2).g_rational\n",
    "    rational_6_2 = model_tr.layer2.__getitem__(2).b_rational\n",
    "    rational_6_3 = model_tr.layer2.__getitem__(2).c_rational\n",
    "\n",
    "    # Layer 3\n",
    "    rational_7_0 = model_tr.layer3.__getitem__(0).r_rational\n",
    "    rational_7_1 = model_tr.layer3.__getitem__(0).g_rational\n",
    "    rational_7_2 = model_tr.layer3.__getitem__(0).b_rational\n",
    "    rational_7_3 = model_tr.layer3.__getitem__(0).c_rational\n",
    "\n",
    "    rational_8_0 = model_tr.layer3.__getitem__(1).r_rational\n",
    "    rational_8_1 = model_tr.layer3.__getitem__(1).g_rational\n",
    "    rational_8_2 = model_tr.layer3.__getitem__(1).b_rational\n",
    "    rational_8_3 = model_tr.layer3.__getitem__(1).c_rational\n",
    "\n",
    "    rational_9_0 = model_tr.layer3.__getitem__(2).r_rational\n",
    "    rational_9_1 = model_tr.layer3.__getitem__(2).g_rational\n",
    "    rational_9_2 = model_tr.layer3.__getitem__(2).b_rational\n",
    "    rational_9_3 = model_tr.layer3.__getitem__(2).c_rational\n",
    "\n",
    "    rational_0_0.show(display=True)\n",
    "    rational_0_1.show(display=True)\n",
    "    rational_0_2.show(display=True)\n",
    "    rational_0_3.show(display=True)\n",
    "\n",
    "    rational_9_0.show(display=True)\n",
    "    rational_9_1.show(display=True)\n",
    "    rational_9_2.show(display=True)\n",
    "    rational_9_3.show(display=True)\n",
    "\n",
    "\n",
    "    plt.legend(['Test'])\n",
    "\n",
    "    plt.savefig('resnet_plots_3.svg')\n",
    "    plt.show()\n",
    "\n",
    "layer_plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}